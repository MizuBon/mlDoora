Program Name,Code
weather,"currentVersion=""1.23.0"" #This version variable should not have a v but should contain all other characters ex Github release tag is v1.2.4 currentVersion is 1.2.4
LANG=""${LANG:-en}""
locale=$(echo ""$LANG"" | cut -c1-2)
unset configuredClient
if [[ $(echo ""$locale"" | grep -Eo ""[a-z A-Z]*"" | wc -c) != 3 ]]; then locale=""en""; fi

## This function determines which http get tool the system has installed and returns an error if there isnt one
getConfiguredClient()
{
  if command -v curl &>/dev/null; then
    configuredClient=""curl""
  elif command -v wget &>/dev/null; then
    configuredClient=""wget""
  elif command -v http &>/dev/null; then
    configuredClient=""httpie""
  elif command -v fetch &>/dev/null; then
    configuredClient=""fetch""
  else
    echo ""Error: This tool requires either curl, wget, httpie or fetch to be installed\."" >&2
    return 1
  fi
}

## Allows to call the users configured client without if statements everywhere
httpGet()
{
  case ""$configuredClient"" in
    curl)  curl -A curl -s ""$@"" ;;
    wget)  wget -qO- ""$@"" ;;
    httpie) http -b GET ""$@"" ;;
    fetch) fetch -q ""$@"" ;;
  esac
}

getIPWeather()
{
  country=$(httpGet ipinfo.io/country) > /dev/null ## grab the country
  if [[ $country == ""US"" ]]; then ## if were in the us id rather not use longitude and latitude so the output is nicer
    city=$(httpGet ipinfo.io/city) > /dev/null
    region=$(httpGet ipinfo.io/region) > /dev/null
    if [[ $(echo ""$region"" | wc -w) == 2 ]];then
      region=$(echo ""$region"" | grep -Eo ""[A-Z]*"" | tr -d ""[:space:]"")
    fi
    httpGet $locale.wttr.in/""$city"",""$region""""$1""
  else ## otherwise we are going to use longitude and latitude
    location=$(httpGet ipinfo.io/loc) > /dev/null
    httpGet $locale.wttr.in/""$location""""$1""
  fi
}

getLocationWeather()
{
  args=$(echo ""$@"" | tr "" "" + )
  httpGet $locale.wttr.in/""${args}""
}

checkInternet()
{
  httpGet github.com > /dev/null 2>&1 || { echo ""Error: no active internet connection"" >&2; return 1; } # query github with a get request
}

update()
{
  # Author: Alexander Epstein https://github.com/alexanderepstein
  # Update utility version 2.2.0
  # To test the tool enter in the defualt values that are in the examples for each variable
  repositoryName=""Bash-Snippets"" #Name of repostiory to be updated ex. Sandman-Lite
  githubUserName=""alexanderepstein"" #username that hosts the repostiory ex. alexanderepstein
  nameOfInstallFile=""install.sh"" # change this if the installer file has a different name be sure to include file extension if there is one
  latestVersion=$(httpGet https://api.github.com/repos/$githubUserName/$repositoryName/tags | grep -Eo '""name"":.*?[^\\]"",'| head -1 | grep -Eo ""[0-9.]+"" ) #always grabs the tag without the v option

  if [[ $currentVersion == """" || $repositoryName == """" || $githubUserName == """" || $nameOfInstallFile == """" ]]; then
    echo ""Error: update utility has not been configured correctly."" >&2
    exit 1
  elif [[ $latestVersion == """" ]]; then
    echo ""Error: no active internet connection"" >&2
    exit 1
  else
    if [[ ""$latestVersion"" != ""$currentVersion"" ]]; then
      echo ""Version $latestVersion available""
      echo -n ""Do you wish to update $repositoryName [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        cd ~ || { echo 'Update Failed'; exit 1; }
        if [[ -d  ~/$repositoryName ]]; then rm -r -f $repositoryName || { echo ""Permissions Error: try running the update as sudo""; exit 1; } ; fi
        echo -n ""Downloading latest version of: $repositoryName.""
        git clone -q ""https://github.com/$githubUserName/$repositoryName"" && touch .BSnippetsHiddenFile || { echo ""Failure!""; exit 1; } &
        while [ ! -f .BSnippetsHiddenFile ]; do { echo -n "".""; sleep 2; };done
        rm -f .BSnippetsHiddenFile
        echo ""Success!""
        cd $repositoryName || { echo 'Update Failed'; exit 1; }
        git checkout ""v$latestVersion"" 2> /dev/null || git checkout ""$latestVersion"" 2> /dev/null || echo ""Couldn't git checkout to stable release, updating to latest commit.""
        chmod a+x install.sh #this might be necessary in your case but wasnt in mine.
        ./$nameOfInstallFile ""update"" || exit 1
        cd ..
        rm -r -f $repositoryName || { echo ""Permissions Error: update succesfull but cannot delete temp files located at ~/$repositoryName delete this directory with sudo""; exit 1; }
      else
        exit 1
      fi
    else
      echo ""$repositoryName is already the latest version""
    fi
  fi
}

usage()
{
  cat <<EOF
Weather
Description: Provides a 3 day forecast on your current location or a specified location.
  With no flags Weather will default to your current location.
Usage: weather or weather [flag] or weather [country] or weather [city] [state]
  weather [i][M] get weather in imperial units, optional M means windspeed in m/s
  weather [m][M] get weather in metric units, optional M means windspeed in m/s
  weather [Moon] grabs the phase of the moon
  -u  Update Bash-Snippet Tools
  -h  Show the help
  -v  Get the tool version
Examples:
  weather
  weather Paris m
  weather Tokyo
  weather Moon
  weather mM
EOF
}

getConfiguredClient || exit 1

while getopts ""uvh"" opt; do
  case ""$opt"" in
    \?) echo ""Invalid option: -$OPTARG"" >&2
        exit 1
        ;;
    h)  usage
        exit 0
        ;;
    v)  echo ""Version $currentVersion""
        exit 0
        ;;
    u)  checkInternet || exit 1 # check if we have a valid internet connection if this isnt true the rest of the script will not work so stop here
        update || exit 1
        exit 0
        ;;
    :)  echo ""Option -$OPTARG requires an argument."" >&2
        exit 1
        ;;
  esac
done

if [[ $# == ""0"" ]]; then
  checkInternet || exit 1
  getIPWeather || exit 1
  exit 0
elif [[ $1 == ""help"" || $1 == "":help"" ]]; then
  usage
  exit 0
elif [[ $1 == ""update"" ]]; then
  checkInternet || exit 1
  update || exit 1
  exit 0
fi

checkInternet || exit 1
if [[ $1 == ""m"" ]]; then
  getIPWeather ""?m"" || exit 1
elif [[ ""${@: -1}"" == ""m"" ]];then
  args=$( echo ""${@:1:(($# - 1))}"" ?m | sed s/"" ""//g)
  getLocationWeather ""$args"" || exit 1
elif [[ $1 == ""M"" ]]; then
  getIPWeather ""?M"" || exit 1
elif [[ ""${@: -1}"" == ""M"" ]];then
  args=$( echo ""${@:1:(($# - 1))}"" ?M | sed s/"" ""//g)
  getLocationWeather ""$args"" || exit 1
elif [[ $1 == ""mM"" || $1 == ""Mm"" ]]; then
  getIPWeather ""?m?M"" || exit 1
elif [[ ""${@: -1}"" == ""mM"" || ""${@:-1}"" == ""Mm"" ]];then
  args=$( echo ""${@:1:(($# - 1))}"" ?m?M | sed s/"" ""//g)
  getLocationWeather ""$args"" || exit 1
elif [[ $1 == ""iM"" || $1 == ""Mi"" ]]; then
  getIPWeather ""?u?M"" || exit 1
elif [[ ""${@: -1}"" == ""iM"" || ""${@:-1}"" == ""Mi"" ]];then
  args=$( echo ""${@:1:(($# - 1))}"" ?u?M | sed s/"" ""//g)
  getLocationWeather ""$args"" || exit 1
elif [[ $1 == ""i"" ]]; then
  getIPWeather ""?u"" || exit 1
elif [[ ""${@: -1}"" == ""i"" ]];then
  args=$( echo ""${@:1:(($# - 1))}"" ?u | sed s/"" ""//g)
  getLocationWeather ""$args"" || exit 1
else
  getLocationWeather ""$@"" || exit 1
fi"
taste,"currentVersion=""1.23.0""
configuredClient=""""
configuredPython=""""
source ~/.bash_profile 2> /dev/null ## allows grabbing enviornment variable
apiKey=$TASTE_API_KEY
info=""0"" ## indicates if we want extra info
search=""0"" ## indivates that we want results on the item itself

## This function determines which http get tool the system has installed and returns an error if there isnt one
getConfiguredClient()
{
  if  command -v curl &>/dev/null; then
    configuredClient=""curl""
  elif command -v wget &>/dev/null; then
    configuredClient=""wget""
  elif command -v http &>/dev/null; then
    configuredClient=""httpie""
  elif command -v fetch &>/dev/null; then
    configuredClient=""fetch""
  else
    echo ""Error: This tool requires either curl, wget, httpie or fetch to be installed."" >&2
    return 1
  fi
}

## Allows to call the users configured client without if statements everywhere
httpGet()
{
  case ""$configuredClient"" in
    curl)  curl -A curl -s ""$@"" ;;
    wget)  wget -qO- ""$@"" ;;
    httpie) http -b GET ""$@"" ;;
    fetch) fetch -q ""$@"" ;;
  esac
}

getConfiguredPython()
{
  if command -v python3 &>/dev/null; then
    configuredPython=""python3""
  elif  command -v python2 &>/dev/null; then
    configuredPython=""python2""
  elif command -v python &>/dev/null; then
    configuredPython=""python""
  else
    echo ""Error: This tool requires python to be installed.""
    return 1
  fi
}

if [[ $(uname) != ""Darwin"" ]]; then
  python()
  {
    case ""$configuredPython"" in
      python3) python3 ""$@"" ;;
      python2) python2 ""$@"" ;;
      python)  python ""$@"" ;;
    esac
  }
fi

## Grabs an element from a a json string and then echoes it to stdout
## $1 = the JSON string
## $n+1 = the elements to be indexed
AccessJsonElement() {
  json=""$1""
  shift
  accessor=""""
  for element in ""$@""; do
      accessor=""${accessor}['$element']""
  done
  echo ""$json"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)${accessor})""
  return ""$?""
}

checkInternet()
{
  httpGet github.com > /dev/null 2>&1 || { echo ""Error: no active internet connection"" >&2; return 1; } # query github with a get request
}

update()
{
  # Author: Alexander Epstein https://github.com/alexanderepstein
  # Update utility version 2.2.0
  # To test the tool enter in the defualt values that are in the examples for each variable
  repositoryName=""Bash-Snippets"" #Name of repostiory to be updated ex. Sandman-Lite
  githubUserName=""alexanderepstein"" #username that hosts the repostiory ex. alexanderepstein
  nameOfInstallFile=""install.sh"" # change this if the installer file has a different name be sure to include file extension if there is one
  latestVersion=$(httpGet https://api.github.com/repos/$githubUserName/$repositoryName/tags | grep -Eo '""name"":.*?[^\\]"",'| head -1 | grep -Eo ""[0-9.]+"" ) #always grabs the tag without the v option

  if [[ $currentVersion == """" || $repositoryName == """" || $githubUserName == """" || $nameOfInstallFile == """" ]]; then
    echo ""Error: update utility has not been configured correctly."" >&2
    exit 1
  elif [[ $latestVersion == """" ]]; then
    echo ""Error: no active internet connection"" >&2
    exit 1
  else
    if [[ ""$latestVersion"" != ""$currentVersion"" ]]; then
      echo ""Version $latestVersion available""
      echo -n ""Do you wish to update $repositoryName [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        cd ~ || { echo 'Update Failed'; exit 1; }
        if [[ -d  ~/$repositoryName ]]; then rm -r -f $repositoryName || { echo ""Permissions Error: try running the update as sudo""; exit 1; } ; fi
        echo -n ""Downloading latest version of: $repositoryName.""
        git clone -q ""https://github.com/$githubUserName/$repositoryName"" && touch .BSnippetsHiddenFile || { echo ""Failure!""; exit 1; } &
        while [ ! -f .BSnippetsHiddenFile ]; do { echo -n "".""; sleep 2; };done
        rm -f .BSnippetsHiddenFile
        echo ""Success!""
        cd $repositoryName || { echo 'Update Failed'; exit 1; }
        git checkout ""v$latestVersion"" 2> /dev/null || git checkout ""$latestVersion"" 2> /dev/null || echo ""Couldn't git checkout to stable release, updating to latest commit.""
        chmod a+x install.sh #this might be necessary in your case but wasnt in mine.
        ./$nameOfInstallFile ""update"" || exit 1
        cd ..
        rm -r -f $repositoryName || { echo ""Permissions Error: update succesfull but cannot delete temp files located at ~/$repositoryName delete this directory with sudo""; exit 1; }
      else
        exit 1
      fi
    else
      echo ""$repositoryName is already the latest version""
    fi
  fi
}

## This function gets 3 results similar to the item of interest
getSimilar()
{
  export PYTHONIOENCODING=utf8 #necessary for python in some cases
  media=$( echo ""$@"" | tr "" "" + )
  response=$(httpGet ""https://tastedive.com/api/similar?q=$media&k=$apiKey&info=$info"")
  ## Extrapolate the information by parsing the JSON
  nameOne=$(echo ""$response"" |python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][0]['Name'])"" 2>  /dev/null || { echo ""Error: Did you search a valid item?""; return 1; } )
  typeOne=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][0]['Type'])"" 2>  /dev/null)
  nameTwo=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][1]['Name'])"" 2>  /dev/null)
  typeTwo=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][1]['Type'])"" 2>  /dev/null)
  nameThree=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][2]['Name'])"" 2>  /dev/null)
  typeThree=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][2]['Type'])"" 2>  /dev/null)
  if [[ $info == ""1"" ]];then ## if we want more detailed info we have to grab a few more fields
    wikiOne=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][0]['wTeaser'])"" 2>  /dev/null)
    wikiTwo=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][1]['wTeaser'])"" 2>  /dev/null)
    wikiThree=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][2]['wTeaser'])"" 2>  /dev/null)
    youtube=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Results'][0]['yUrl'])"" 2>  /dev/null)
  fi
}

## This function grabs all the information it can on the item of interest itself
getInfo()
{
  export PYTHONIOENCODING=utf8 #necessary for python in some cases
  media=$( echo ""$@"" | tr "" "" + )
  response=$(httpGet ""https://tastedive.com/api/similar?q=$media&k=$apiKey&info=$info"")
  name=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Info'][0]['Name'])"")
  type=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Info'][0]['Type'])"")
  if [[ $info == ""1"" ]]; then
    wiki=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Info'][0]['wTeaser'])"")
    youtube=$(echo ""$response"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Similar']['Info'][0]['yUrl'])"")
  else
    wiki=""None""
    youtube=""None""
  fi
}

printResults()
{
  if [[ $info == ""1"" ]];then
    echo ""===================================""
    echo
    echo ""$nameOne"": ""$typeOne""
    echo ""$wikiOne""
    echo
    echo
    echo ""$nameTwo"": ""$typeTwo""
    echo ""$wikiTwo""
    echo
    echo
    echo ""$nameThree"": ""$typeThree""
    echo ""$wikiThree""
    echo
    if [[ $youtube != ""None"" ]]; then echo $youtube; fi
    echo
    echo ""===================================""
  else
    echo ""===================================""
    echo ""$nameOne"": ""$typeOne""
    echo ""$nameTwo"": ""$typeTwo""
    echo ""$nameThree"": ""$typeThree""
    echo ""===================================""
  fi
}

printInfo()
{
  echo ""===================================""
  echo
  echo ""$name"": ""$type""
  echo $wiki
  echo
  if [[ $youtube != ""None"" ]]; then echo $youtube; fi
  echo ""===================================""
}

usage()
{
  cat <<EOF
Taste
Description: A recommendation engine that provides 3 similar items based on some input topic.
  Taste also has the ability to provide information on the item of interest.
  Supports: shows, books, music, artists, movies, authors, games
Usage: taste [flag] [item]
  -i  Get more information on similar items
  -s  Get information on the item itself
  -u  Update Bash-Snippet Tools
  -h  Show the help
  -v  Get the tool version
Examples:
  taste -i Kendrick Lamar
  taste Catcher in the Rye
  taste -s Red Hot Chili Peppers
EOF
}

if [[ $apiKey == """" ]]; then
  cat <<EOF
Error: API key not setup properly
To get an API key visit https://tastedive.com/account/api_access
After getting the API key run the following command: export TASTE_API_KEY=""yourAPIKeyGoesHere""
After following all the steps and issues still persist try adding export TASTE_API_KEY manually to your .bash_profile
EOF
  exit 1
fi
if [[ $(uname) != ""Darwin"" ]]; then getConfiguredPython || exit 1; fi
getConfiguredClient || exit 1


while getopts ""uvhis"" opt; do
  case ""$opt"" in
    \?) echo ""Invalid option: -$OPTARG"" >&2
        exit 1
        ;;
    h)  usage
        exit 0
        ;;
    v)  echo ""Version $currentVersion""
        exit 0
        ;;
    u)  checkInternet || exit 1
        update
        exit 0
        ;;
    i)  if [[ $search == ""0"" ]]; then
          info=""1""
        else
          echo ""Error: the options -i and -s are mutually exclusive (-s already uses -i)""
          exit 1
        fi
        ;;
    s)  if [[ $info != ""1"" ]]; then
          search=""1""
          info=""1""
        else
          echo ""Error: the options -i and -s are mutually exclusive (-s already uses -i)""
          exit 1
        fi
        ;;
    :)  echo ""Option -$OPTARG requires an argument."" >&2
        exit 1
        ;;
  esac
done

if [[ $# == 0 ]]; then
  usage
elif [[ $1 == ""update"" ]]; then
  checkInternet || exit 1
  update
elif [[ $1 == ""help"" ]]; then
  usage
else
  checkInternet || exit 1
  if [[ $search == ""0"" ]]; then
    if [[ $info == ""0"" ]]; then
      getSimilar ""$@"" || exit 1 ## exit if we return 1 (chances are movie was not found)
      printResults
    else
      getSimilar ""${@:2}"" || exit 1
      printResults
    fi
  else
    getInfo ""${@:2}"" || exit 1 ## exit if we return 1 (chances are movie was not found)
    printInfo
  fi
fi"
bashhub,"from __future__ import print_function
from time import *
import click
import traceback
import dateutil.parser
import sys
import os
import io

from .model import CommandForm
from . import rest_client
from . import bashhub_setup
from . import bashhub_globals
from .bashhub_globals import BH_FILTER, BH_HOME, BH_SAVE_COMMANDS
from .bashhub_globals import write_to_config_file
from .version import version_str
import shutil
import requests
import subprocess
from . import shell_utils
import re
from .view.status import *

from builtins import str as text


def print_version(ctx, param, value):
    if not value or ctx.resilient_parsing:
        return
    click.echo(version_str)
    ctx.exit()


CONTEXT_SETTINGS = dict(help_option_names=['-h', '--help'])


@click.group(context_settings=CONTEXT_SETTINGS)
@click.option('-V',
              '--version',
              default=False,
              is_flag=True,
              callback=print_version,
              help='Display version',
              expose_value=False,
              is_eager=True)
def bashhub():
    """"""Bashhub command line client""""""
    pass


@bashhub.command()
def version():
    """"""Display version""""""
    click.echo(version_str)


@bashhub.command()
@click.option(""-g"",
              ""--global"",
              ""is_global"",
              default=False,
              is_flag=True,
              help=""Turn off saving commands for all sessions."")
def off(is_global):
    """"""Turn off saving commands to Bashhub. Applies for this current session.""""""
    if is_global:
        write_to_config_file('save_commands', 'False')
    else:
        f = io.open(BH_HOME + '/script.bh', 'w+', encoding='utf-8')
        print(text(""export BH_SAVE_COMMANDS='False'""), file=f)


@bashhub.command()
@click.option('-l',
              ""--local"",
              help=""Turn on saving commands for only this session."",
              is_flag=True)
def on(local):
    """"""Turn on saving commands to Bashhub. Applies globally.""""""
    f = io.open(BH_HOME + '/script.bh', 'w+', encoding='utf-8')

    if local:
        print(text(""export BH_SAVE_COMMANDS='True'""), file=f)
    else:
        print(text(""unset BH_SAVE_COMMANDS""), file=f)
        write_to_config_file('save_commands', 'True')


@bashhub.command()
@click.argument('command', type=str)
@click.argument('path', type=click.Path(exists=True))
@click.argument('pid', type=int)
@click.argument('process_start_time', type=int)
@click.argument('exit_status', type=int)
def save(command, path, pid, process_start_time, exit_status):
    """"""Save a command to Bashhub""""""
    pid_start_time = unix_time_to_epoc_millis(process_start_time)
    command = command.strip()

    # Check if we have commands saving turned on
    if not bashhub_globals.BH_SAVE_COMMANDS:
        return

    # Check if we should ignore this command.
    if ""#ignore"" in command:
        return

    # Check if we should filter this command.
    bh_filter = bashhub_globals.BH_FILTER
    if bh_filter and re.findall(bh_filter, command):
        return

    # Check that we have an auth token.
    if bashhub_globals.BH_AUTH() == """":
        print(""No auth token found. Run 'bashhub setup' to login."")
        return

    command = CommandForm(command, path, exit_status, pid, pid_start_time)
    rest_client.save_command(command)


@bashhub.command()
def setup():
    """"""Run Bashhub user and system setup""""""
    bashhub_setup.main()


@bashhub.command()
def status():
    """"""Stats for this session and user""""""
    # Get our user and session information from our context
    (ppid, start_time) = shell_utils.get_session_information()
    status_view = rest_client.get_status_view(ppid, start_time)
    if status_view:
        click.echo(build_status_view(status_view))


@bashhub.command()
@click.pass_context
def help(ctx):
    """"""Show this message and exit""""""
    click.echo(ctx.parent.get_help())

# Dynamic help text containing the BH_FILTER variable.
filtered_text = ""BH_FILTER={0}"".format(
    BH_FILTER) if BH_FILTER else ""BH_FILTER \
is unset.""

filter_help_text = """"""Check if a command is filtered from bashhub. Filtering
is configured via a regex exported as BH_FILTER.
\n
{0}"""""".format(filtered_text)


@bashhub.command(help=filter_help_text)
@click.argument('command', type=str)
@click.option('-r',
              '--regex',
              default=BH_FILTER,
              help='Regex to filter against')
def filter(command, regex):

    # Check if the regex we receive is valid
    if not bashhub_globals.is_valid_regex(regex):
        click.secho(""Regex {0} is invalid"".format(regex), fg='red')
        return

    v = re.findall(regex, command)
    click.echo(filtered_text)
    if v and regex:
        matched = [str(s) for s in set(v)]
        output = click.style(""{0} \nIs Filtered. Matched "".format(command),
                             fg='yellow') + click.style(
                                 str(matched), fg='red')
        click.echo(output)
    else:
        click.echo(""{0} \nIs Unfiltered"".format(command))


@bashhub.command()
@click.argument('version', type=str, default='')
def update(version):
    """"""Update your Bashhub installation""""""

    if version != '':
        github = ""https://github.com/rcaloras/bashhub-client/archive/{0}.tar.gz"".format(
            version)
        response = requests.get(github)
        if response.status_code is not 200:
            click.echo(""Invalid version number {0}"".format(version))
            sys.exit(1)

    query_param = '?version={0}'.format(version) if version else ''
    url = 'https://bashhub.com/setup' + query_param
    response = requests.get(url, stream=True)
    filename = 'update-bashhub.sh'
    with open(filename, 'wb') as out_file:
        shutil.copyfileobj(response.raw, out_file)

    shell_command = ""bash -e {0} {1}"".format(filename, version)
    subprocess.call(shell_command, shell=True)
    os.remove(filename)


@bashhub.group()
def util():
    """"""Misc utils used by Bashhub""""""
    pass


@util.command()
def update_system_info():
    """"""Updates system info for Bashhub""""""
    result = bashhub_setup.update_system_info()
    # Exit code based on if our update call was successful
    sys.exit(0) if result != None else sys.exit(1)


@util.command()
@click.argument('date_string', type=str)
def parsedate(date_string):
    """"""date string to seconds since the unix epoch""""""
    try:
        date = dateutil.parser.parse(date_string)
        unix_time = int(mktime(date.timetuple()))
        click.echo(unix_time)
    except Exception as e:
        # Should really log an error here
        click.echo(0)


def unix_time_to_epoc_millis(unix_time):
    return int(unix_time) * 1000


def main():
    try:
        bashhub()
    except Exception as e:
        formatted = traceback.format_exc(e)
        click.echo(""Oops, looks like an exception occured: "" + str(e))
        sys.exit(1)"
bocker,"set -o errexit -o nounset -o pipefail; shopt -s nullglob
btrfs_path='/var/bocker' && cgroups='cpu,cpuacct,memory';
[[ $# -gt 0 ]] && while [ ""${1:0:2}"" == '--' ]; do OPTION=${1:2}; [[ $OPTION =~ = ]] && declare ""BOCKER_${OPTION/=*/}=${OPTION/*=/}"" || declare ""BOCKER_${OPTION}=x""; shift; done

function bocker_check() {
	btrfs subvolume list ""$btrfs_path"" | grep -qw ""$1"" && echo 0 || echo 1
}

function bocker_init() { #HELP Create an image from a directory:\nBOCKER init <directory>
	uuid=""img_$(shuf -i 42002-42254 -n 1)""
	if [[ -d ""$1"" ]]; then
		[[ ""$(bocker_check ""$uuid"")"" == 0 ]] && bocker_run ""$@""
		btrfs subvolume create ""$btrfs_path/$uuid"" > /dev/null
		cp -rf --reflink=auto ""$1""/* ""$btrfs_path/$uuid"" > /dev/null
		[[ ! -f ""$btrfs_path/$uuid""/img.source ]] && echo ""$1"" > ""$btrfs_path/$uuid""/img.source
		echo ""Created: $uuid""
	else
		echo ""No directory named '$1' exists""
	fi
}

function bocker_pull() { #HELP Pull an image from Docker Hub:\nBOCKER pull <name> <tag>
	token=""$(curl -sL -o /dev/null -D- -H 'X-Docker-Token: true' ""https://index.docker.io/v1/repositories/$1/images"" | tr -d '\r' | awk -F ': *' '$1 == ""X-Docker-Token"" { print $2 }')""
	registry='https://registry-1.docker.io/v1'
	id=""$(curl -sL -H ""Authorization: Token $token"" ""$registry/repositories/$1/tags/$2"" | sed 's/""//g')""
	[[ ""${#id}"" -ne 64 ]] && echo ""No image named '$1:$2' exists"" && exit 1
	ancestry=""$(curl -sL -H ""Authorization: Token $token"" ""$registry/images/$id/ancestry"")""
	IFS=',' && ancestry=(${ancestry//[\[\] \""]/}) && IFS=' \n\t'; tmp_uuid=""$(uuidgen)"" && mkdir /tmp/""$tmp_uuid""
	for id in ""${ancestry[@]}""; do
		curl -#L -H ""Authorization: Token $token"" ""$registry/images/$id/layer"" -o /tmp/""$tmp_uuid""/layer.tar
		tar xf /tmp/""$tmp_uuid""/layer.tar -C /tmp/""$tmp_uuid"" && rm /tmp/""$tmp_uuid""/layer.tar
	done
	echo ""$1:$2"" > /tmp/""$tmp_uuid""/img.source
	bocker_init /tmp/""$tmp_uuid"" && rm -rf /tmp/""$tmp_uuid""
}

function bocker_rm() { #HELP Delete an image or container:\nBOCKER rm <image_id or container_id>
	[[ ""$(bocker_check ""$1"")"" == 1 ]] && echo ""No container named '$1' exists"" && exit 1
	btrfs subvolume delete ""$btrfs_path/$1"" > /dev/null
	cgdelete -g ""$cgroups:/$1"" &> /dev/null || true
	echo ""Removed: $1""
}

function bocker_images() { #HELP List images:\nBOCKER images
	echo -e ""IMAGE_ID\t\tSOURCE""
	for img in ""$btrfs_path""/img_*; do
		img=$(basename ""$img"")
		echo -e ""$img\t\t$(cat ""$btrfs_path/$img/img.source"")""
	done
}

function bocker_ps() { #HELP List containers:\nBOCKER ps
	echo -e ""CONTAINER_ID\t\tCOMMAND""
	for ps in ""$btrfs_path""/ps_*; do
		ps=$(basename ""$ps"")
		echo -e ""$ps\t\t$(cat ""$btrfs_path/$ps/$ps.cmd"")""
	done
}

function bocker_run() { #HELP Create a container:\nBOCKER run <image_id> <command>
	uuid=""ps_$(shuf -i 42002-42254 -n 1)""
	[[ ""$(bocker_check ""$1"")"" == 1 ]] && echo ""No image named '$1' exists"" && exit 1
	[[ ""$(bocker_check ""$uuid"")"" == 0 ]] && echo ""UUID conflict, retrying..."" && bocker_run ""$@"" && return
	cmd=""${@:2}"" && ip=""$(echo ""${uuid: -3}"" | sed 's/0//g')"" && mac=""${uuid: -3:1}:${uuid: -2}""
	ip link add dev veth0_""$uuid"" type veth peer name veth1_""$uuid""
	ip link set dev veth0_""$uuid"" up
	ip link set veth0_""$uuid"" master bridge0
	ip netns add netns_""$uuid""
	ip link set veth1_""$uuid"" netns netns_""$uuid""
	ip netns exec netns_""$uuid"" ip link set dev lo up
	ip netns exec netns_""$uuid"" ip link set veth1_""$uuid"" address 02:42:ac:11:00""$mac""
	ip netns exec netns_""$uuid"" ip addr add 10.0.0.""$ip""/24 dev veth1_""$uuid""
	ip netns exec netns_""$uuid"" ip link set dev veth1_""$uuid"" up
	ip netns exec netns_""$uuid"" ip route add default via 10.0.0.1
	btrfs subvolume snapshot ""$btrfs_path/$1"" ""$btrfs_path/$uuid"" > /dev/null
	echo 'nameserver 8.8.8.8' > ""$btrfs_path/$uuid""/etc/resolv.conf
	echo ""$cmd"" > ""$btrfs_path/$uuid/$uuid.cmd""
	cgcreate -g ""$cgroups:/$uuid""
	: ""${BOCKER_CPU_SHARE:=512}"" && cgset -r cpu.shares=""$BOCKER_CPU_SHARE"" ""$uuid""
	: ""${BOCKER_MEM_LIMIT:=512}"" && cgset -r memory.limit_in_bytes=""$((BOCKER_MEM_LIMIT * 1000000))"" ""$uuid""
	cgexec -g ""$cgroups:$uuid"" \
		ip netns exec netns_""$uuid"" \
		unshare -fmuip --mount-proc \
		chroot ""$btrfs_path/$uuid"" \
		/bin/sh -c ""/bin/mount -t proc proc /proc && $cmd"" \
		2>&1 | tee ""$btrfs_path/$uuid/$uuid.log"" || true
	ip link del dev veth0_""$uuid""
	ip netns del netns_""$uuid""
}

function bocker_exec() { #HELP Execute a command in a running container:\nBOCKER exec <container_id> <command>
	[[ ""$(bocker_check ""$1"")"" == 1 ]] && echo ""No container named '$1' exists"" && exit 1
	cid=""$(ps o ppid,pid | grep ""^$(ps o pid,cmd | grep -E ""^\ *[0-9]+ unshare.*$1"" | awk '{print $1}')"" | awk '{print $2}')""
	[[ ! ""$cid"" =~ ^\ *[0-9]+$ ]] && echo ""Container '$1' exists but is not running"" && exit 1
	nsenter -t ""$cid"" -m -u -i -n -p chroot ""$btrfs_path/$1"" ""${@:2}""
}

function bocker_logs() { #HELP View logs from a container:\nBOCKER logs <container_id>
	[[ ""$(bocker_check ""$1"")"" == 1 ]] && echo ""No container named '$1' exists"" && exit 1
	cat ""$btrfs_path/$1/$1.log""
}

function bocker_commit() { #HELP Commit a container to an image:\nBOCKER commit <container_id> <image_id>
	[[ ""$(bocker_check ""$1"")"" == 1 ]] && echo ""No container named '$1' exists"" && exit 1
	[[ ""$(bocker_check ""$2"")"" == 1 ]] && echo ""No image named '$2' exists"" && exit 1
	bocker_rm ""$2"" && btrfs subvolume snapshot ""$btrfs_path/$1"" ""$btrfs_path/$2"" > /dev/null
	echo ""Created: $2""
}

function bocker_help() { #HELP Display this message:\nBOCKER help
	sed -n ""s/^.*#HELP\\s//p;"" < ""$1"" | sed ""s/\\\\n/\n\t/g;s/$/\n/;s!BOCKER!${1/!/\\!}!g""
}

[[ -z ""${1-}"" ]] && bocker_help ""$0""
case $1 in
	pull|init|rm|images|ps|run|exec|logs|commit) bocker_""$1"" ""${@:2}"" ;;
	*) bocker_help ""$0"" ;;
esac"
ngincat,"echo|read|{(read t;g=$(echo $t|cut -d' ' -f2)
while read|grep :;do :;done;[[ -e .$g &&! $g = *..* ]]||exit
printf ""HTTP/1.1 200 OK\nContent-Length: $(stat -c%s .$g)\n\n""
cat .$g)|nc -l -p $1;}>/dev/fd/0;$0 $1"
bashblog,"#!/usr/bin/env bash

# BashBlog, a simple blog system written in a single bash script
# (C) Carlos Fenollosa <carlos.fenollosa@gmail.com>, 2011-2016 and contributors
# https://github.com/carlesfe/bashblog/contributors
# Check out README.md for more details

# Global variables
# It is recommended to perform a 'rebuild' after changing any of this in the code

# Config file. Any settings ""key=value"" written there will override the
# global_variables defaults. Useful to avoid editing bb.sh and having to deal
# with merges in VCS
global_config="".config""

# This function will load all the variables defined here. They might be overridden
# by the 'global_config' file contents
global_variables() {
    global_software_name=""BashBlog""
    global_software_version=""2.10""

    # Blog title
    global_title=""My fancy blog""
    # The typical subtitle for each blog
    global_description=""A blog about turtles and carrots""
    # The public base URL for this blog
    global_url=""http://example.com/blog""

    # Your name
    global_author=""John Smith""
    # You can use twitter or facebook or anything for global_author_url
    global_author_url=""http://twitter.com/example"" 
    # Your email
    global_email=""john@smith.com""

    # CC by-nc-nd is a good starting point, you can change this to ""&copy;"" for Copyright
    global_license=""CC by-nc-nd""

    # If you have a Google Analytics ID (UA-XXXXX) and wish to use the standard
    # embedding code, put it on global_analytics
    # If you have custom analytics code (i.e. non-google) or want to use the Universal
    # code, leave global_analytics empty and specify a global_analytics_file
    global_analytics=""""
    global_analytics_file=""""

    # Leave this empty (i.e. """") if you don't want to use feedburner, 
    # or change it to your own URL
    global_feedburner=""""

    # Change this to your username if you want to use twitter for comments
    global_twitter_username=""""
    # Default image for the Twitter cards. Use an absolute URL
    global_twitter_card_image=""""
    # Set this to false for a Twitter button with share count. The cookieless version
    # is just a link.
    global_twitter_cookieless=""true""
    # Default search page, where tweets more than a week old are hidden
    global_twitter_search=""twitter""

    # Change this to your disqus username to use disqus for comments
    global_disqus_username=""""


    # Blog generated files
    # index page of blog (it is usually good to use ""index.html"" here)
    index_file=""index.html""
    number_of_index_articles=""8""
    # global archive
    archive_index=""all_posts.html""
    tags_index=""all_tags.html""

    # Non blogpost files. Bashblog will ignore these. Useful for static pages and custom content
    # Add them as a bash array, e.g. non_blogpost_files=(""news.html"" ""test.html"")
    non_blogpost_files=()

    # feed file (rss in this case)
    blog_feed=""feed.rss""
    number_of_feed_articles=""10""
    # ""cut"" blog entry when putting it to index page. Leave blank for full articles in front page
    # i.e. include only up to first '<hr>', or '----' in markdown
    cut_do=""cut""
    # When cutting, cut also tags? If ""no"", tags will appear in index page for cut articles
    cut_tags=""yes""
    # Regexp matching the HTML line where to do the cut
    # note that slash is regexp separator so you need to prepend it with backslash
    cut_line='<hr ?\/?>'
    # save markdown file when posting with ""bb post -m"". Leave blank to discard it.
    save_markdown=""yes""
    # prefix for tags/categories files
    # please make sure that no other html file starts with this prefix
    prefix_tags=""tag_""
    # personalized header and footer (only if you know what you're doing)
    # DO NOT name them .header.html, .footer.html or they will be overwritten
    # leave blank to generate them, recommended
    header_file=""""
    footer_file=""""
    # extra content to add just after we open the <body> tag
    # and before the actual blog content
    body_begin_file=""""
    # extra content to add just before we close </body>
    body_end_file=""""
    # extra content to ONLY on the index page AFTER `body_begin_file` contents
    # and before the actual content
    body_begin_file_index=""""
    # CSS files to include on every page, f.ex. css_include=('main.css' 'blog.css')
    # leave empty to use generated
    css_include=()
    # HTML files to exclude from index, f.ex. post_exclude=('imprint.html 'aboutme.html')
    html_exclude=()

    # Localization and i18n
    # ""Comments?"" (used in twitter link after every post)
    template_comments=""Comments?""
    # ""Read more..."" (link under cut article on index page)
    template_read_more=""Read more...""
    # ""View more posts"" (used on bottom of index page as link to archive)
    template_archive=""View more posts""
    # ""All posts"" (title of archive page)
    template_archive_title=""All posts""
    # ""All tags""
    template_tags_title=""All tags""
    # ""posts"" (on ""All tags"" page, text at the end of each tag line, like ""2. Music - 15 posts"")
    template_tags_posts=""posts""
    template_tags_posts_2_4=""posts""  # Some slavic languages use a different plural form for 2-4 items
    template_tags_posts_singular=""post""
    # ""Posts tagged"" (text on a title of a page with index of one tag, like ""My Blog - Posts tagged ""Music"""")
    template_tag_title=""Posts tagged""
    # ""Tags:"" (beginning of line in HTML file with list of all tags for this article)
    template_tags_line_header=""Tags:""
    # ""Back to the index page"" (used on archive page, it is link to blog index)
    template_archive_index_page=""Back to the index page""
    # ""Subscribe"" (used on bottom of index page, it is link to RSS feed)
    template_subscribe=""Subscribe""
    # ""Subscribe to this page..."" (used as text for browser feed button that is embedded to html)
    template_subscribe_browser_button=""Subscribe to this page...""
    # ""Tweet"" (used as twitter text button for posting to twitter)
    template_twitter_button=""Tweet""
    template_twitter_comment=""&lt;Type your comment here but please leave the URL so that other people can follow the comments&gt;""
    
    # The locale to use for the dates displayed on screen
    date_format=""%B %d, %Y""
    date_locale=""C""
    date_inpost=""bashblog_timestamp""
    # Don't change these dates
    date_format_full=""%a, %d %b %Y %H:%M:%S %z""
    date_format_timestamp=""%Y%m%d%H%M.%S""
    date_allposts_header=""%B %Y""

    # Perform the post title -> filename conversion
    # Experts only. You may need to tune the locales too
    # Leave empty for no conversion, which is not recommended
    # This default filter respects backwards compatibility
    convert_filename=""iconv -f utf-8 -t ascii//translit | sed 's/^-*//' | tr [:upper:] [:lower:] | tr ' ' '-' | tr -dc '[:alnum:]-'""

    # URL where you can view the post while it's being edited
    # same as global_url by default
    # You can change it to path on your computer, if you write posts locally
    # before copying them to the server
    preview_url=""""

    # Markdown location. Trying to autodetect by default.
    # The invocation must support the signature 'markdown_bin in.md > out.html'
    [[ -f Markdown.pl ]] && markdown_bin=./Markdown.pl || markdown_bin=$(which Markdown.pl 2>/dev/null || which markdown 2>/dev/null)
}

# Check for the validity of some variables
# DO NOT EDIT THIS FUNCTION unless you know what you're doing
global_variables_check() {
    [[ $header_file == .header.html ]] &&
        echo ""Please check your configuration. '.header.html' is not a valid value for the setting 'header_file'"" &&
        exit
    [[ $footer_file == .footer.html ]] &&
        echo ""Please check your configuration. '.footer.html' is not a valid value for the setting 'footer_file'"" &&
        exit
}


# Test if the markdown script is working correctly
test_markdown() {
    [[ -n $markdown_bin ]] &&
        (
        [[ $(""$markdown_bin"" <<< $'line 1\n\nline 2') == $'<p>line 1</p>\n\n<p>line 2</p>' ]] ||
        [[ $(""$markdown_bin"" <<< $'line 1\n\nline 2') == $'<p>line 1</p>\n<p>line 2</p>' ]]
        )
}


# Parse a Markdown file into HTML and return the generated file
markdown() {
    out=${1%.md}.html
    while [[ -f $out ]]; do out=${out%.html}.$RANDOM.html; done
    $markdown_bin ""$1"" > ""$out""
    echo ""$out""
}


# Prints the required google analytics code
google_analytics() {
    [[ -z $global_analytics && -z $global_analytics_file ]]  && return

    if [[ -z $global_analytics_file ]]; then
        echo ""<script type=\""text/javascript\"">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', '${global_analytics}']);
        _gaq.push(['_trackPageview']);

        (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();

        </script>""
    else
        cat ""$global_analytics_file""
    fi
}

# Prints the required code for disqus comments
disqus_body() {
    [[ -z $global_disqus_username ]] && return

    echo '<div id=""disqus_thread""></div>
            <script type=""text/javascript"">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
               var disqus_shortname = '""'$global_disqus_username'""'; // required: replace example with your forum shortname

            /* * * DONT EDIT BELOW THIS LINE * * */
            (function() {
            var dsq = document.createElement(""script""); dsq.type = ""text/javascript""; dsq.async = true;
            dsq.src = ""//"" + disqus_shortname + "".disqus.com/embed.js"";
            (document.getElementsByTagName(""head"")[0] || document.getElementsByTagName(""body"")[0]).appendChild(dsq);
            })();
            </script>
            <noscript>Please enable JavaScript to view the <a href=""http://disqus.com/?ref_noscript"">comments powered by Disqus.</a></noscript>
            <a href=""http://disqus.com"" class=""dsq-brlink"">comments powered by <span class=""logo-disqus"">Disqus</span></a>'
}

# Prints the required code for disqus in the footer
disqus_footer() {
    [[ -z $global_disqus_username ]] && return
    echo '<script type=""text/javascript"">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = '""'$global_disqus_username'""'; // required: replace example with your forum shortname

        /* * * DONT EDIT BELOW THIS LINE * * */
        (function () {
        var s = document.createElement(""script""); s.async = true;
        s.type = ""text/javascript"";
        s.src = ""//"" + disqus_shortname + "".disqus.com/count.js"";
        (document.getElementsByTagName(""HEAD"")[0] || document.getElementsByTagName(""BODY"")[0]).appendChild(s);
    }());
    </script>'
}

# Reads HTML file from stdin, prints its content to stdout
# $1    where to start (""text"" or ""entry"")
# $2    where to stop (""text"" or ""entry"")
# $3    ""cut"" to remove text from <hr /> to <!-- text end -->
#       note that this does not remove <hr /> line itself,
#       so you can see if text was cut or not
get_html_file_content() {
    awk ""/<!-- $1 begin -->/, /<!-- $2 end -->/{
        if (!/<!-- $1 begin -->/ && !/<!-- $2 end -->/) print
        if (\""$3\"" == \""cut\"" && /$cut_line/){
            if (\""$2\"" == \""text\"") exit # no need to read further
            while (getline > 0 && !/<!-- text end -->/) {
                if (\""$cut_tags\"" == \""no\"" && /^<p>$template_tags_line_header/ ) print 
            }
        }
    }""
}

# Edit an existing, published .html file while keeping its original timestamp
# Please note that this function does not automatically republish anything, as
# it is usually called from 'main'.
#
# Note that it edits HTML file, even if you wrote the post as markdown originally
# Note that if you edit title then filename might also change
#
# $1 	the file to edit
# $2	(optional) edit mode:
#	""keep"" to keep old filename
#	""full"" to edit full HTML, and not only text part (keeps old filename)
#	leave empty for default behavior (edit only text part and change name)
edit() {
    [[ ! -f ""${1%%.*}.html"" ]] && echo ""Can't edit post ""${1%%.*}.html"", did you mean to use \""bb.sh post <draft_file>\""?"" && exit -1
    # Original post timestamp
    edit_timestamp=$(LC_ALL=C date -r ""${1%%.*}.html"" +""$date_format_full"" )
    touch_timestamp=$(LC_ALL=C date -r ""${1%%.*}.html"" +""$date_format_timestamp"")
    tags_before=$(tags_in_post ""${1%%.*}.html"")
    if [[ $2 == full ]]; then
        $EDITOR ""$1""
        filename=$1
    else
        if [[ ${1##*.} == md ]]; then
            test_markdown
            if (($? != 0)); then
                echo ""Markdown is not working, please edit HTML file directly.""
                exit
            fi
            # editing markdown file
            $EDITOR ""$1""
            TMPFILE=$(markdown ""$1"")
            filename=${1%%.*}.html
        else
            # Create the content file
            TMPFILE=$(basename ""$1"").$RANDOM.html
            # Title
            get_post_title ""$1"" > ""$TMPFILE""
            # Post text with plaintext tags
            get_html_file_content 'text' 'text' <""$1"" | sed ""/^<p>$template_tags_line_header/s|<a href='$prefix_tags\([^']*\).html'>\\1</a>|\\1|g"" >> ""$TMPFILE""
            $EDITOR ""$TMPFILE""
            filename=$1
        fi
        rm ""$filename""
        if [[ $2 == keep ]]; then
            parse_file ""$TMPFILE"" ""$edit_timestamp"" ""$filename""
        else
            parse_file ""$TMPFILE"" ""$edit_timestamp"" # this command sets $filename as the html processed file
            [[ ${1##*.} == md ]] && mv ""$1"" ""${filename%%.*}.md"" 2>/dev/null
        fi
        rm ""$TMPFILE""
    fi
    touch -t ""$touch_timestamp"" ""$filename""
    touch -t ""$touch_timestamp"" ""$1""
    chmod 644 ""$filename""
    echo ""Posted $filename""
    tags_after=$(tags_in_post ""$filename"")
    relevant_tags=$(echo ""$tags_before $tags_after"" | tr ',' ' ' | tr ' ' '\n' | sort -u | tr '\n' ' ')
    if [[ ! -z $relevant_tags ]]; then
        relevant_posts=""$(posts_with_tags $relevant_tags) $filename""
        rebuild_tags ""$relevant_posts"" ""$relevant_tags""
    fi
}

# Create a Twitter summary (twitter ""card"") for the post
#
# $1 the post file
# $2 the title
twitter_card() {
    [[ -z $global_twitter_username ]] && return
    
    echo ""<meta name='twitter:card' content='summary' />""
    echo ""<meta name='twitter:site' content='@$global_twitter_username' />""
    echo ""<meta name='twitter:title' content='$2' />"" # Twitter truncates at 70 char
    description=$(grep -v ""^<p>$template_tags_line_header"" ""$1"" | sed -e 's/<[^>]*>//g' | tr '\n' ' ' | sed ""s/\""/'/g"" | head -c 250) 
    echo ""<meta name='twitter:description' content=\""$description\"" />""

    # For the image we try to locate the first image in the article
    image=$(sed -n '2,$ d; s/.*<img.*src=""\([^""]*\)"".*/\1/p' ""$1"") 

    # If none, then we try a global setting image
    [[ -z $image ]] && [[ -n $global_twitter_card_image ]] && image=$global_twitter_card_image

    # If none, return
    [[ -z $image ]] && return

    # Final housekeeping
    [[ $image =~ ^https?:// ]] || image=$global_url/$image # Check that URL is absolute
    echo ""<meta name='twitter:image' content='$image' />""
}

# Adds the code needed by the twitter button
#
# $1 the post URL
twitter() {
    [[ -z $global_twitter_username ]] && return

    if [[ -z $global_disqus_username ]]; then
        if [[ $global_twitter_cookieless == true ]]; then 
            id=$RANDOM

            search_engine=""https://twitter.com/search?q=""

            echo ""<p id='twitter'><a href='http://twitter.com/intent/tweet?url=$1&text=$template_twitter_comment&via=$global_twitter_username'>$template_comments $template_twitter_button</a> ""
            echo ""<a href='$search_engine""""$1'><span id='count-$id'></span></a>&nbsp;</p>""
            return;
        else 
            echo ""<p id='twitter'>$template_comments&nbsp;""; 
        fi
    else
        echo ""<p id='twitter'><a href=\""$1#disqus_thread\"">$template_comments</a> &nbsp;""
    fi  

    echo ""<a href=\""https://twitter.com/share\"" class=\""twitter-share-button\"" data-text=\""$template_twitter_comment\"" data-url=\""$1\""""
    echo "" data-via=\""$global_twitter_username\""""
    echo "">$template_twitter_button</a>	<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=\""//platform.twitter.com/widgets.js\"";fjs.parentNode.insertBefore(js,fjs);}}(document,\""script\"",\""twitter-wjs\"");</script>""
    echo ""</p>""
}

# Check if the file is a 'boilerplate' (i.e. not a post)
# The return values are designed to be used like this inside a loop:
# is_boilerplate_file <file> && continue
#
# $1 the file
#
# Return 0 (bash return value 'true') if the input file is an index, feed, etc
# or 1 (bash return value 'false') if it is a blogpost
is_boilerplate_file() {
    name=${1#./}
    # First check against user-defined non-blogpost pages
    for item in ""${non_blogpost_files[@]}""; do
        [[ ""$name"" == ""$item"" ]] && return 0
    done

    case $name in
    ( ""$index_file"" | ""$archive_index"" | ""$tags_index"" | ""$footer_file"" | ""$header_file"" | ""$global_analytics_file"" | ""$prefix_tags""* )
        return 0 ;;
    ( * ) # Check for excluded
        for excl in ""${html_exclude[@]}""; do
            [[ $name == ""$excl"" ]] && return 0
        done
        return 1 ;;
    esac
}

# Adds all the bells and whistles to format the html page
# Every blog post is marked with a <!-- entry begin --> and <!-- entry end -->
# which is parsed afterwards in the other functions. There is also a marker
# <!-- text begin --> to determine just the beginning of the text body of the post
#
# $1     a file with the body of the content
# $2     the output file
# $3     ""yes"" if we want to generate the index.html,
#        ""no"" to insert new blog posts
# $4     title for the html header
# $5     original blog timestamp
# $6     post author
create_html_page() {
    content=$1
    filename=$2
    index=$3
    title=$4
    timestamp=$5
    author=$6

    # Create the actual blog post
    # html, head
    {
        cat "".header.html""
        echo ""<title>$title</title>""
        google_analytics
        twitter_card ""$content"" ""$title""
        echo ""</head><body>""
        # stuff to add before the actual body content
        [[ -n $body_begin_file ]] && cat ""$body_begin_file""
        [[ $filename = $index_file* ]] && [[ -n $body_begin_file_index ]] && cat ""$body_begin_file_index""
        # body divs
        echo '<div id=""divbodyholder"">'
        echo '<div class=""headerholder""><div class=""header"">'
        # blog title
        echo '<div id=""title"">'
        cat .title.html
        echo '</div></div></div>' # title, header, headerholder
        echo '<div id=""divbody""><div class=""content"">'

        file_url=${filename#./}
        file_url=${file_url%.rebuilt} # Get the correct URL when rebuilding
        # one blog entry
        if [[ $index == no ]]; then
            echo '<!-- entry begin -->' # marks the beginning of the whole post
            echo ""<h3><a class=\""ablack\"" href=\""$file_url\"">""
            # remove possible <p>'s on the title because of markdown conversion
            title=${title//<p>/}
            title=${title//<\/p>/}
            echo ""$title""
            echo '</a></h3>'
            if [[ -z $timestamp ]]; then
                echo ""<!-- $date_inpost: #$(LC_ALL=$date_locale date +""$date_format_timestamp"")# -->""
            else
                echo ""<!-- $date_inpost: #$(LC_ALL=$date_locale date +""$date_format_timestamp"" --date=""$timestamp"")# -->""
            fi
            if [[ -z $timestamp ]]; then
                echo -n ""<div class=\""subtitle\"">$(LC_ALL=$date_locale date +""$date_format"")""
            else
                echo -n ""<div class=\""subtitle\"">$(LC_ALL=$date_locale date +""$date_format"" --date=""$timestamp"")""
            fi
            [[ -n $author ]] && echo -e "" &mdash; \n$author""
            echo ""</div>""
            echo '<!-- text begin -->' # This marks the text body, after the title, date...
        fi
        cat ""$content"" # Actual content
        if [[ $index == no ]]; then
            echo -e '\n<!-- text end -->'

            twitter ""$global_url/$file_url""

            echo '<!-- entry end -->' # absolute end of the post
        fi

        echo '</div>' # content

        # Add disqus commments except for index and all_posts pages
        [[ $index == no ]] && disqus_body

        # page footer
        cat .footer.html
        # close divs
        echo '</div></div>' # divbody and divbodyholder 
        disqus_footer
        [[ -n $body_end_file ]] && cat ""$body_end_file""
        echo '</body></html>'
    } > ""$filename""
}

# Parse the plain text file into an html file
#
# $1    source file name
# $2    (optional) timestamp for the file
# $3    (optional) destination file name
# note that although timestamp is optional, something must be provided at its
# place if destination file name is provided, i.e:
# parse_file source.txt """" destination.html
parse_file() {
    # Read for the title and check that the filename is ok
    title=""""
    while IFS='' read -r line; do
        if [[ -z $title ]]; then
            # remove extra <p> and </p> added by markdown
            title=$(echo ""$line"" | sed 's/<\/*p>//g')
            if [[ -n $3 ]]; then
                filename=$3
            else
                filename=$title
                [[ -n $convert_filename ]] &&
                    filename=$(echo ""$title"" | eval ""$convert_filename"")
                [[ -n $filename ]] || 
                    filename=$RANDOM # don't allow empty filenames

                filename=$filename.html

                # Check for duplicate file names
                while [[ -f $filename ]]; do
                    filename=${filename%.html}$RANDOM.html
                done
            fi
            content=$filename.tmp
        # Parse possible tags
        elif [[ $line == ""<p>$template_tags_line_header""* ]]; then
            tags=$(echo ""$line"" | cut -d "":"" -f 2- | sed -e 's/<\/p>//g' -e 's/^ *//' -e 's/ *$//' -e 's/, /,/g')
            IFS=, read -r -a array <<< ""$tags""

            echo -n ""<p>$template_tags_line_header "" >> ""$content""
            for item in ""${array[@]}""; do
                echo -n ""<a href='$prefix_tags$item.html'>$item</a>, ""
            done | sed 's/, $/<\/p>/g' >> ""$content""
        else
            echo ""$line"" >> ""$content""
        fi
    done < ""$1""

    # Create the actual html page
    create_html_page ""$content"" ""$filename"" no ""$title"" ""$2"" ""$global_author""
    rm ""$content""
}

# Manages the creation of the text file and the parsing to html file
# also the drafts
write_entry() {
    test_markdown && fmt=md || fmt=html
    f=$2
    [[ $2 == -html ]] && fmt=html && f=$3

    if [[ -n $f ]]; then
        TMPFILE=$f
        if [[ ! -f $TMPFILE ]]; then
            echo ""The file doesn't exist""
            delete_includes
            exit
        fi
        # guess format from TMPFILE
        extension=${TMPFILE##*.}
        [[ $extension == md || $extension == html ]] && fmt=$extension
        # but let user override it (`bb.sh post -html file.md`)
        [[ $2 == -html ]] && fmt=html
        # Test if Markdown is working before re-posting a .md file
        if [[ $extension == md ]]; then
            test_markdown
            if (($? != 0)); then
                echo ""Markdown is not working, please edit HTML file directly.""
                exit
            fi
        fi
    else
        TMPFILE=.entry-$RANDOM.$fmt
        echo -e ""Title on this line\n"" >> ""$TMPFILE""

        [[ $fmt == html ]] && cat << EOF >> ""$TMPFILE""
<p>The rest of the text file is an <b>html</b> blog post. The process will continue as soon
as you exit your editor.</p>

<p>$template_tags_line_header keep-this-tag-format, tags-are-optional, example</p>
EOF
        [[ $fmt == md ]] && cat << EOF >> ""$TMPFILE""
The rest of the text file is a **Markdown** blog post. The process will continue
as soon as you exit your editor.

$template_tags_line_header keep-this-tag-format, tags-are-optional, beware-with-underscores-in-markdown, example
EOF
    fi
    chmod 600 ""$TMPFILE""

    post_status=""E""
    filename=""""
    while [[ $post_status != ""p"" && $post_status != ""P"" ]]; do
        [[ -n $filename ]] && rm ""$filename"" # Delete the generated html file, if any
        $EDITOR ""$TMPFILE""
        if [[ $fmt == md ]]; then
            html_from_md=$(markdown ""$TMPFILE"")
            parse_file ""$html_from_md""
            rm ""$html_from_md""
        else
            parse_file ""$TMPFILE"" # this command sets $filename as the html processed file
        fi

        chmod 644 ""$filename""
        [[ -n $preview_url ]] || preview_url=$global_url
        echo ""To preview the entry, open $preview_url/$filename in your browser""

        echo -n ""[P]ost this entry, [E]dit again, [D]raft for later? (p/E/d) ""
        read -r post_status
        if [[ $post_status == d || $post_status == D ]]; then
            mkdir -p ""drafts/""
            chmod 700 ""drafts/""

            title=$(head -n 1 $TMPFILE)
            [[ -n $convert_filename ]] && title=$(echo ""$title"" | eval ""$convert_filename"")
            [[ -n $title ]] || title=$RANDOM

            draft=drafts/$title.$fmt
            mv ""$TMPFILE"" ""$draft""
            chmod 600 ""$draft""
            rm ""$filename""
            delete_includes
            echo ""Saved your draft as '$draft'""
            exit
        fi
    done

    if [[ $fmt == md && -n $save_markdown ]]; then
        mv ""$TMPFILE"" ""${filename%%.*}.md""
    else
        rm ""$TMPFILE""
    fi
    chmod 644 ""$filename""
    echo ""Posted $filename""
    relevant_tags=$(tags_in_post $filename)
    if [[ -n $relevant_tags ]]; then
        relevant_posts=""$(posts_with_tags $relevant_tags) $filename""
        rebuild_tags ""$relevant_posts"" ""$relevant_tags""
    fi
}

# Create an index page with all the posts
all_posts() {
    echo -n ""Creating an index page with all the posts ""
    contentfile=$archive_index.$RANDOM
    while [[ -f $contentfile ]]; do
        contentfile=$archive_index.$RANDOM
    done

    {
        echo ""<h3>$template_archive_title</h3>""
        prev_month=""""
        while IFS='' read -r i; do
            is_boilerplate_file ""$i"" && continue
            echo -n ""."" 1>&3
            # Month headers
            month=$(LC_ALL=$date_locale date -r ""$i"" +""$date_allposts_header"")
            if [[ $month != ""$prev_month"" ]]; then
                [[ -n $prev_month ]] && echo ""</ul>""  # Don't close ul before first header
                echo ""<h4 class='allposts_header'>$month</h4>""
                echo ""<ul>""
                prev_month=$month
            fi
            # Title
            title=$(get_post_title ""$i"")
            echo -n ""<li><a href=\""$i\"">$title</a> &mdash;""
            # Date
            date=$(LC_ALL=$date_locale date -r ""$i"" +""$date_format"")
            echo "" $date</li>""
        done < <(ls -t ./*.html)
        echo """" 1>&3
        echo ""</ul>""
        echo ""<div id=\""all_posts\""><a href=\""./$index_file\"">$template_archive_index_page</a></div>""
    } 3>&1 >""$contentfile""

    create_html_page ""$contentfile"" ""$archive_index.tmp"" yes ""$global_title &mdash; $template_archive_title"" ""$global_author""
    mv ""$archive_index.tmp"" ""$archive_index""
    chmod 644 ""$archive_index""
    rm ""$contentfile""
}

# Create an index page with all the tags
all_tags() {
    echo -n ""Creating an index page with all the tags ""
    contentfile=$tags_index.$RANDOM
    while [[ -f $contentfile ]]; do
        contentfile=$tags_index.$RANDOM
    done

    {
        echo ""<h3>$template_tags_title</h3>""
        echo ""<ul>""
        for i in $prefix_tags*.html; do
            [[ -f ""$i"" ]] || break
            echo -n ""."" 1>&3
            nposts=$(grep -c ""<\!-- text begin -->"" ""$i"")
            tagname=${i#""$prefix_tags""}
            tagname=${tagname%.html}
            case $nposts in
                1) word=$template_tags_posts_singular;;
                2|3|4) word=$template_tags_posts_2_4;;
                *) word=$template_tags_posts;;
            esac
            echo ""<li><a href=\""$i\"">$tagname</a> &mdash; $nposts $word</li>""
        done
        echo """" 1>&3
        echo ""</ul>""
        echo ""<div id=\""all_posts\""><a href=\""./$index_file\"">$template_archive_index_page</a></div>""
    } 3>&1 > ""$contentfile""

    create_html_page ""$contentfile"" ""$tags_index.tmp"" yes ""$global_title &mdash; $template_tags_title"" ""$global_author""
    mv ""$tags_index.tmp"" ""$tags_index""
    chmod 644 ""$tags_index""
    rm ""$contentfile""
}

# Generate the index.html with the content of the latest posts
rebuild_index() {
    echo -n ""Rebuilding the index ""
    newindexfile=$index_file.$RANDOM
    contentfile=$newindexfile.content
    while [[ -f $newindexfile ]]; do 
        newindexfile=$index_file.$RANDOM
        contentfile=$newindexfile.content
    done

    # Create the content file
    {
        n=0
        while IFS='' read -r i; do
            is_boilerplate_file ""$i"" && continue;
            if ((n >= number_of_index_articles)); then break; fi
            if [[ -n $cut_do ]]; then
                get_html_file_content 'entry' 'entry' 'cut' <""$i"" | awk ""/$cut_line/ { print \""<p class=\\\""readmore\\\""><a href=\\\""$i\\\"">$template_read_more</a></p>\"" ; next } 1""
            else
                get_html_file_content 'entry' 'entry' <""$i""
            fi
            echo -n ""."" 1>&3
            n=$(( n + 1 ))
        done < <(ls -t ./*.html) # sort by date, newest first

        feed=$blog_feed
        if [[ -n $global_feedburner ]]; then feed=$global_feedburner; fi
        echo ""<div id=\""all_posts\""><a href=\""$archive_index\"">$template_archive</a> &mdash; <a href=\""$tags_index\"">$template_tags_title</a> &mdash; <a href=\""$feed\"">$template_subscribe</a></div>""
    } 3>&1 >""$contentfile""

    echo """"

    create_html_page ""$contentfile"" ""$newindexfile"" yes ""$global_title"" ""$global_author""
    rm ""$contentfile""
    mv ""$newindexfile"" ""$index_file""
    chmod 644 ""$index_file""
}

# Finds all tags referenced in one post.
# Accepts either filename as first argument, or post content at stdin
# Prints one line with space-separated tags to stdout
tags_in_post() {
    sed -n ""/^<p>$template_tags_line_header/{s/^<p>$template_tags_line_header//;s/<[^>]*>//g;s/[ ,]\+/ /g;p;}"" ""$1"" | tr ', ' ' '
}

# Finds all posts referenced in a number of tags.
# Arguments are tags
# Prints one line with space-separated tags to stdout
posts_with_tags() {
    (($# < 1)) && return
    set -- ""${@/#/$prefix_tags}""
    set -- ""${@/%/.html}""
    sed -n '/^<h3><a class=""ablack"" href=""[^""]*"">/{s/.*href=""\([^""]*\)"">.*/\1/;p;}' ""$@"" 2> /dev/null
}

# Rebuilds tag_*.html files
# if no arguments given, rebuilds all of them
# if arguments given, they should have this format:
# ""FILE1 [FILE2 [...]]"" ""TAG1 [TAG2 [...]]""
# where FILEn are files with posts which should be used for rebuilding tags,
# and TAGn are names of tags which should be rebuilt.
# example:
# rebuild_tags ""one_post.html another_article.html"" ""example-tag another-tag""
# mind the quotes!
rebuild_tags() {
    if (($# < 2)); then
        # will process all files and tags
        files=$(ls -t ./*.html)
        all_tags=yes
    else
        # will process only given files and tags
        files=$(printf '%s\n' $1 | sort -u)
        files=$(ls -t $files)
        tags=$2
    fi
    echo -n ""Rebuilding tag pages ""
    n=0
    if [[ -n $all_tags ]]; then
        rm ./""$prefix_tags""*.html &> /dev/null
    else
        for i in $tags; do
            rm ""./$prefix_tags$i.html"" &> /dev/null
        done
    fi
    # First we will process all files and create temporal tag files
    # with just the content of the posts
    tmpfile=tmp.$RANDOM
    while [[ -f $tmpfile ]]; do tmpfile=tmp.$RANDOM; done
    while IFS='' read -r i; do
        is_boilerplate_file ""$i"" && continue;
        echo -n "".""
        if [[ -n $cut_do ]]; then
            get_html_file_content 'entry' 'entry' 'cut' <""$i"" | awk ""/$cut_line/ { print \""<p class=\\\""readmore\\\""><a href=\\\""$i\\\"">$template_read_more</a></p>\"" ; next } 1""
        else
            get_html_file_content 'entry' 'entry' <""$i""
        fi >""$tmpfile""
        for tag in $(tags_in_post ""$i""); do
            if [[ -n $all_tags || "" $tags "" == *"" $tag ""* ]]; then
                cat ""$tmpfile"" >> ""$prefix_tags$tag"".tmp.html
            fi
        done
    done <<< ""$files""
    rm ""$tmpfile""
    # Now generate the tag files with headers, footers, etc
    while IFS='' read -r i; do
        tagname=${i#./""$prefix_tags""}
        tagname=${tagname%.tmp.html}
        create_html_page ""$i"" ""$prefix_tags$tagname.html"" yes ""$global_title &mdash; $template_tag_title \""$tagname\"""" ""$global_author""
        rm ""$i""
    done < <(ls -t ./""$prefix_tags""*.tmp.html 2>/dev/null)
    echo
}

# Return the post title
#
# $1 the html file
get_post_title() {
    awk '/<h3><a class=""ablack"" href="".+"">/, /<\/a><\/h3>/{if (!/<h3><a class=""ablack"" href="".+"">/ && !/<\/a><\/h3>/) print}' ""$1""
}

# Return the post author
#
# $1 the html file
get_post_author() { 
    awk '/<div class=""subtitle"">.+/, /<!-- text begin -->/{if (!/<div class=""subtitle"">.+/ && !/<!-- text begin -->/) print}' ""$1"" | sed 's/<\/div>//g'
}

# Displays a list of the tags
#
# $2 if ""-n"", tags will be sorted by number of posts
list_tags() {
    if [[ $2 == -n ]]; then do_sort=1; else do_sort=0; fi

    ls ./$prefix_tags*.html &> /dev/null
    (($? != 0)) && echo ""No posts yet. Use 'bb.sh post' to create one"" && return

    lines=""""
    for i in $prefix_tags*.html; do
        [[ -f ""$i"" ]] || break
        nposts=$(grep -c ""<\!-- text begin -->"" ""$i"")
        tagname=${i#""$prefix_tags""}
        tagname=${tagname#.html}
        ((nposts > 1)) && word=$template_tags_posts || word=$template_tags_posts_singular
        line=""$tagname # $nposts # $word""
        lines+=$line\\n
    done

    if (( do_sort == 1 )); then
        echo -e ""$lines"" | column -t -s ""#"" | sort -nrk 2
    else
        echo -e ""$lines"" | column -t -s ""#"" 
    fi
}

# Displays a list of the posts
list_posts() {
    ls ./*.html &> /dev/null
    (($? != 0)) && echo ""No posts yet. Use 'bb.sh post' to create one"" && return

    lines=""""
    n=1
    while IFS='' read -r i; do
        is_boilerplate_file ""$i"" && continue
        line=""$n # $(get_post_title ""$i"") # $(LC_ALL=$date_locale date -r ""$i"" +""$date_format"")""
        lines+=$line\\n
        n=$(( n + 1 ))
    done < <(ls -t ./*.html)

    echo -e ""$lines"" | column -t -s ""#""
}

# Generate the feed file
make_rss() {
    echo -n ""Making RSS ""

    rssfile=$blog_feed.$RANDOM
    while [[ -f $rssfile ]]; do rssfile=$blog_feed.$RANDOM; done

    {
        pubdate=$(LC_ALL=C date +""$date_format_full"")
        echo '<?xml version=""1.0"" encoding=""UTF-8"" ?>' 
        echo '<rss version=""2.0"" xmlns:atom=""http://www.w3.org/2005/Atom"" xmlns:dc=""http://purl.org/dc/elements/1.1/"">' 
        echo ""<channel><title>$global_title</title><link>$global_url/$index_file</link>""
        echo ""<description>$global_description</description><language>en</language>""
        echo ""<lastBuildDate>$pubdate</lastBuildDate>""
        echo ""<pubDate>$pubdate</pubDate>""
        echo ""<atom:link href=\""$global_url/$blog_feed\"" rel=\""self\"" type=\""application/rss+xml\"" />""
    
        n=0
        while IFS='' read -r i; do
            is_boilerplate_file ""$i"" && continue
            ((n >= number_of_feed_articles)) && break # max 10 items
            echo -n ""."" 1>&3
            echo '<item><title>' 
            get_post_title ""$i""
            echo '</title><description><![CDATA[' 
            get_html_file_content 'text' 'entry' $cut_do <""$i""
            echo ""]]></description><link>$global_url/${i#./}</link>"" 
            echo ""<guid>$global_url/$i</guid>"" 
            echo ""<dc:creator>$(get_post_author ""$i"")</dc:creator>"" 
            echo ""<pubDate>$(LC_ALL=C date -r ""$i"" +""$date_format_full"")</pubDate></item>""
    
            n=$(( n + 1 ))
        done < <(ls -t ./*.html)
    
        echo '</channel></rss>'
    } 3>&1 >""$rssfile""
    echo """"

    mv ""$rssfile"" ""$blog_feed""
    chmod 644 ""$blog_feed""
}

# generate headers, footers, etc
create_includes() {
    {
        echo ""<h1 class=\""nomargin\""><a class=\""ablack\"" href=\""$global_url/$index_file\"">$global_title</a></h1>"" 
        echo ""<div id=\""description\"">$global_description</div>""
    } > "".title.html""

    if [[ -f $header_file ]]; then cp ""$header_file"" .header.html
    else {
        echo '<!DOCTYPE html PUBLIC ""-//W3C//DTD XHTML 1.0 Strict//EN"" ""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"">'
        echo '<html xmlns=""http://www.w3.org/1999/xhtml""><head>'
        echo '<meta http-equiv=""Content-type"" content=""text/html;charset=UTF-8"" />'
        echo '<meta name=""viewport"" content=""width=device-width, initial-scale=1.0"" />'
        printf '<link rel=""stylesheet"" href=""%s"" type=""text/css"" />\n' ""${css_include[@]}""
        if [[ -z $global_feedburner ]]; then
            echo ""<link rel=\""alternate\"" type=\""application/rss+xml\"" title=\""$template_subscribe_browser_button\"" href=\""$blog_feed\"" />""
        else 
            echo ""<link rel=\""alternate\"" type=\""application/rss+xml\"" title=\""$template_subscribe_browser_button\"" href=\""$global_feedburner\"" />""
        fi
        } > "".header.html""
    fi

    if [[ -f $footer_file ]]; then cp ""$footer_file"" .footer.html
    else {
        protected_mail=${global_email//@/&#64;}
        protected_mail=${protected_mail//./&#46;}
        echo ""<div id=\""footer\"">$global_license <a href=\""$global_author_url\"">$global_author</a> &mdash; <a href=\""mailto:$protected_mail\"">$protected_mail</a><br/>""
        echo 'Generated with <a href=""https://github.com/cfenollosa/bashblog"">bashblog</a>, a single bash script to easily create blogs like this one</div>'
        } >> "".footer.html""
    fi
}

# Delete the temporarily generated include files
delete_includes() {
    rm "".title.html"" "".footer.html"" "".header.html""
}

# Create the css file from scratch
create_css() {
    # To avoid overwriting manual changes. However it is recommended that
    # this function is modified if the user changes the blog.css file
    (( ${#css_include[@]} > 0 )) && return || css_include=('main.css' 'blog.css')
    if [[ ! -f blog.css ]]; then 
        # blog.css directives will be loaded after main.css and thus will prevail
        echo '#title{font-size: x-large;}
        a.ablack{color:black !important;}
        li{margin-bottom:8px;}
        ul,ol{margin-left:24px;margin-right:24px;}
        #all_posts{margin-top:24px;text-align:center;}
        .subtitle{font-size:small;margin:12px 0px;}
        .content p{margin-left:24px;margin-right:24px;}
        h1{margin-bottom:12px !important;}
        #description{font-size:large;margin-bottom:12px;}
        h3{margin-top:42px;margin-bottom:8px;}
        h4{margin-left:24px;margin-right:24px;}
        img{max-width:100%;}
        #twitter{line-height:20px;vertical-align:top;text-align:right;font-style:italic;color:#333;margin-top:24px;font-size:14px;}' > blog.css
    fi

    # If there is a style.css from the parent page (i.e. some landing page)
    # then use it. This directive is here for compatibility with my own
    # home page. Feel free to edit it out, though it doesn't hurt
    if [[ -f ../style.css ]] && [[ ! -f main.css ]]; then
        ln -s ""../style.css"" ""main.css"" 
    elif [[ ! -f main.css ]]; then
        echo 'body{font-family:Georgia,""Times New Roman"",Times,serif;margin:0;padding:0;background-color:#F3F3F3;}
        #divbodyholder{padding:5px;background-color:#DDD;width:100%;max-width:874px;margin:24px auto;}
        #divbody{border:solid 1px #ccc;background-color:#fff;padding:0px 48px 24px 48px;top:0;}
        .headerholder{background-color:#f9f9f9;border-top:solid 1px #ccc;border-left:solid 1px #ccc;border-right:solid 1px #ccc;}
        .header{width:100%;max-width:800px;margin:0px auto;padding-top:24px;padding-bottom:8px;}
        .content{margin-bottom:5%;}
        .nomargin{margin:0;}
        .description{margin-top:10px;border-top:solid 1px #666;padding:10px 0;}
        h3{font-size:20pt;width:100%;font-weight:bold;margin-top:32px;margin-bottom:0;}
        .clear{clear:both;}
        #footer{padding-top:10px;border-top:solid 1px #666;color:#333333;text-align:center;font-size:small;font-family:""Courier New"",""Courier"",monospace;}
        a{text-decoration:none;color:#003366 !important;}
        a:visited{text-decoration:none;color:#336699 !important;}
        blockquote{background-color:#f9f9f9;border-left:solid 4px #e9e9e9;margin-left:12px;padding:12px 12px 12px 24px;}
        blockquote img{margin:12px 0px;}
        blockquote iframe{margin:12px 0px;}' > main.css
    fi
}

# Regenerates all the single post entries, keeping the post content but modifying
# the title, html structure, etc
rebuild_all_entries() {
    echo -n ""Rebuilding all entries ""

    for i in ./*.html; do
        is_boilerplate_file ""$i"" && continue;
        contentfile=.tmp.$RANDOM
        while [[ -f $contentfile ]]; do contentfile=.tmp.$RANDOM; done

        echo -n "".""
        # Get the title and entry, and rebuild the html structure from scratch (divs, title, description...)
        title=$(get_post_title ""$i"")

        get_html_file_content 'text' 'text' <""$i"" >> ""$contentfile""

        # Read timestamp from post, if present, and sync file timestamp
        timestamp=$(awk '/<!-- '$date_inpost': .+ -->/ { print }' ""$i"" | cut -d '#' -f 2)
        [[ -n $timestamp ]] && touch -t ""$timestamp"" ""$i""
        # Read timestamp from file in correct format for 'create_html_page'
        timestamp=$(LC_ALL=C date -r ""$i"" +""$date_format_full"")

        create_html_page ""$contentfile"" ""$i.rebuilt"" no ""$title"" ""$timestamp"" ""$(get_post_author ""$i"")""
        # keep the original timestamp!
        timestamp=$(LC_ALL=C date -r ""$i"" +""$date_format_timestamp"")
        mv ""$i.rebuilt"" ""$i""
        chmod 644 ""$i""
        touch -t ""$timestamp"" ""$i""
        rm ""$contentfile""
    done
    echo """"
}

# Displays the help
usage() {
    echo ""$global_software_name v$global_software_version""
    echo ""Usage: $0 command [filename]""
    echo """"
    echo ""Commands:""
    echo ""    post [-html] [filename] insert a new blog post, or the filename of a draft to continue editing it""
    echo ""                            it tries to use markdown by default, and falls back to HTML if it's not available.""
    echo ""                            use '-html' to override it and edit the post as HTML even when markdown is available""
    echo ""    edit [-n|-f] [filename] edit an already published .html or .md file. **NEVER** edit manually a published .html file,""
    echo ""                            always use this function as it keeps internal data and rebuilds the blog""
    echo ""                            use '-n' to give the file a new name, if title was changed""
    echo ""                            use '-f' to edit full html file, instead of just text part (also preserves name)""
    echo ""    delete [filename]       deletes the post and rebuilds the blog""
    echo ""    rebuild                 regenerates all the pages and posts, preserving the content of the entries""
    echo ""    reset                   deletes everything except this script. Use with a lot of caution and back up first!""
    echo ""    list                    list all posts""
    echo ""    tags [-n]               list all tags in alphabetical order""
    echo ""                            use '-n' to sort list by number of posts""
    echo """"
    echo ""For more information please open $0 in a code editor and read the header and comments""
}

# Delete all generated content, leaving only this script
reset() {
    echo ""Are you sure you want to delete all blog entries? Please write \""Yes, I am!\"" ""
    read -r line
    if [[ $line == ""Yes, I am!"" ]]; then
        rm .*.html ./*.html ./*.css ./*.rss &> /dev/null
        echo
        echo ""Deleted all posts, stylesheets and feeds.""
        echo ""Kept your old '.backup.tar.gz' just in case, please delete it manually if needed.""
    else
        echo ""Phew! You dodged a bullet there. Nothing was modified.""
    fi
}

# Detects if GNU date is installed
date_version_detect() {
	date --version >/dev/null 2>&1
	if (($? != 0));  then
		# date utility is BSD. Test if gdate is installed 
		if gdate --version >/dev/null 2>&1 ; then
            date() {
                gdate ""$@""
            }
		else
            # BSD date
            date() {
                if [[ $1 == -r ]]; then
                    # Fall back to using stat for 'date -r'
                    format=${3//+/}
                    stat -f ""%Sm"" -t ""$format"" ""$2""
                elif [[ $2 == --date* ]]; then
                    # convert between dates using BSD date syntax
                    command date -j -f ""$date_format_full"" ""${2#--date=}"" ""$1"" 
                else
                    # acceptable format for BSD date
                    command date -j ""$@""
                fi
            }
        fi
    fi    
}

# Main function
# Encapsulated on its own function for readability purposes
#
# $1     command to run
# $2     file name of a draft to continue editing (optional)
do_main() {
    # Detect if using BSD date or GNU date
    date_version_detect
    # Load default configuration, then override settings with the config file
    global_variables
    [[ -f $global_config ]] && source ""$global_config"" &> /dev/null 
    global_variables_check

    # Check for $EDITOR
    [[ -z $EDITOR ]] && 
        echo ""Please set your \$EDITOR environment variable. For example, to use nano, add the line 'export EDITOR=nano' to your \$HOME/.bashrc file"" && exit

    # Check for validity of argument
    [[ $1 != ""reset"" && $1 != ""post"" && $1 != ""rebuild"" && $1 != ""list"" && $1 != ""edit"" && $1 != ""delete"" && $1 != ""tags"" ]] && 
        usage && exit

    [[ $1 == list ]] &&
        list_posts && exit

    [[ $1 == tags ]] &&
        list_tags ""$@"" && exit

    if [[ $1 == edit ]]; then
        if (($# < 2)) || [[ ! -f ${!#} ]]; then
            echo ""Please enter a valid .md or .html file to edit""
            exit
        fi
    fi

    # Test for existing html files
    if ls ./*.html &> /dev/null; then
        # We're going to back up just in case
        tar -c -z -f "".backup.tar.gz"" -- *.html &&
            chmod 600 "".backup.tar.gz""
    elif [[ $1 == rebuild ]]; then
        echo ""Can't find any html files, nothing to rebuild""
        exit
    fi

    # Keep first backup of this day containing yesterday's version of the blog
    [[ ! -f .yesterday.tar.gz || $(date -r .yesterday.tar.gz +'%d') != ""$(date +'%d')"" ]] &&
        cp .backup.tar.gz .yesterday.tar.gz &> /dev/null

    [[ $1 == reset ]] &&
        reset && exit

    create_css
    create_includes
    [[ $1 == post ]] && write_entry ""$@""
    [[ $1 == rebuild ]] && rebuild_all_entries && rebuild_tags
    [[ $1 == delete ]] && rm ""$2"" &> /dev/null && rebuild_tags
    if [[ $1 == edit ]]; then
        if [[ $2 == -n ]]; then
            edit ""$3""
        elif [[ $2 == -f ]]; then
            edit ""$3"" full
        else
            edit ""$2"" keep
        fi
    fi
    rebuild_index
    all_posts
    all_tags
    make_rss
    delete_includes
}


#
# MAIN
# Do not change anything here. If you want to modify the code, edit do_main()
#
do_main ""$@""

# vim: set shiftwidth=4 tabstop=4 expandtab:
"
cheapci,"#!/bin/bash

# Simple CI

set -o pipefail
set -o nounset

# Defaults
FORCE=0
VERBOSE=0
REPO=""""
EMAIL=""""
NAME=""ci""
TEST_DIR="".""
TEST_COMMAND=""./test.sh""
MAIL_CMD=""mail""
MAIL_CMD_ATTACH_FLAG=""-A""
MAIL_CMD_RECIPIENTS_FLAG=""-t""
MAIL_CMD_SUBJECT_FLAG=""-s""
PRE_SCRIPT=""/bin/true""
POST_SCRIPT=""/bin/true""
TIMEOUT_S=86400

PAGER=${PAGER:-more}

function show_help() {
	cat > /dev/stdout << END
${0} -r <repo> -l <local_checkout> [-q <pre-script>] [-w <post-script>]
   [-m <email>] [-a <mail command>] [-t <mail command attach flag>]
   [-s <mail command subject flag] [-e <recipients flag>] [-n name] [-d <dir>] 
   [-c <command>] [-f] [-v] [-h]
REQUIRED ARGS:
-r - git repository, eg https://github.com/myname/myproj (required)
-l - local checkout of code (that gets updated to determine whether a run is needed) (required)
OPTIONAL ARGS:
-q - script to run just before actually performing test (default ${PRE_SCRIPT})
-w - script to run just after actually performing test (default ${POST_SCRIPT})
-m - email address to send to using ""mail"" command (default logs to stdout)
-a - mail command to use (default=${MAIL_CMD})
-n - name for ci (unique, must be a valid directory name), eg myproj (default=${NAME})
-d - directory within repository to navigate to (default=${TEST_DIR})
-c - test command to run from -d directory (default=${TEST_COMMAND})
-t - attach argument flag for mail command (default=${MAIL_CMD_ATTACH_FLAG}, empty string means no-attach)
-s - subject flag for mail command (default=${MAIL_CMD_RECIPIENTS_FLAG})
-e - recipients flag (default=${MAIL_CMD_RECIPIENTS_FLAG}, empty string means no flag needed)
-f - force a run even if repo has no updates (default off)
-v - verbose logging (default off)
-i - timeout in seconds (default 86400, ie one day, does KILL one hour after that)
-h - show help
EXAMPLES
- ""Clone -r https://github.com/ianmiell/shutit.git if a git pull on /space/git/shutit indicates there's been an update.
  Then navigate to test, run ./test.sh and mail ian.miell@gmail.com if there are any issues""
  ./cheapci -r https://github.com/ianmiell/shutit.git -l /space/git/shutit -d test -c ./test.sh -m ian.miell@gmail.com
- ""Run this continuously in a crontab.""
  Crontab line:
  * * * * * cd /path/to/cheapci && ./cheapci -r https://github.com/ianmiell/shutit.git -l /space/git/shutit -d test -c ./test.sh -m ian.miell@gmail.com
END
}


while getopts ""h?vfm:n:d:r:l:c:a:q:w:t:e:s:"" opt
do
	case ""${opt}"" in
	h|\?)
		show_help
		exit 0
		;;
	v) VERBOSE=1 ;;
	f) FORCE=1 ;;
	r) REPO=${OPTARG} ;;
	m) EMAIL=${OPTARG} ;;
	n) NAME=${OPTARG} ;;
	d) TEST_DIR=${OPTARG} ;;
	l) LOCAL_CHECKOUT=${OPTARG} ;;
	c) TEST_COMMAND=${OPTARG} ;;
	q) PRE_SCRIPT=${OPTARG} ;;
	w) POST_SCRIPT=${OPTARG} ;;
	a) MAIL_CMD=${OPTARG} ;;
	t) MAIL_CMD_ATTACH_FLAG=${OPTARG} ;;
	e) MAIL_CMD_RECIPIENTS_FLAG=${OPTARG} ;;
	s) MAIL_CMD_SUBJECT_FLAG=${OPTARG} ;;
	i) TIMEOUT_S=${OPTARG} ;;
	esac
done

shift ""$((OPTIND-1))""

if [[ ${REPO} = """" ]]
then
	show_help
	exit 1
fi


# To force a run even if no updates.

if [[ ${VERBOSE} -gt 0 ]]
then
	set -x
fi

BUILD_DIR_BASE=""/tmp/${NAME}""
BUILD_DIR=""${BUILD_DIR_BASE}/${NAME}_builddir""
mkdir -p ""${BUILD_DIR}""
LOG_FILE=""${BUILD_DIR}/${NAME}_build_${RANDOM}.log.txt""
BUILD_LOG_FILE=""${BUILD_DIR}/${NAME}_build.log.txt""
LOCK_FILE=""${BUILD_DIR}/${NAME}_ci.lck""

function cleanup() {
	rm -rf ""${BUILD_DIR}""
	rm -f ""${LOCK_FILE}""
	# get rid of /tmp detritus, leaving anything accessed 2 days ago+
	find ""${BUILD_DIR_BASE}""/* -type d -atime +1 -exec rm {} -rf +
	echo ""cleanup done""
}

function send_mail() {
	msg=${1}
	if [[ ${LOG_FILE} != """" ]] && [[ ${MAIL_CMD_ATTACH_FLAG} != """" ]]
	then
		log_file_arg=(${MAIL_CMD_ATTACH_FLAG} ${LOG_FILE})
	fi
	if [[ ${EMAIL} != """" ]] && [[ ${MAIL_CMD} != """" ]]
	then
		echo ""${msg}"" | ${MAIL_CMD} ""${MAIL_CMD_SUBJECT_FLAG}"" ""${msg}"" ""${log_file_arg[@]}"" ""${MAIL_CMD_RECIPIENTS_FLAG}"" ""${EMAIL}""
	else
		echo ""${msg}""
	fi
}

date 2>&1 | tee -a ""${BUILD_LOG_FILE}""

# Lockfile
if [[ -a ${LOCK_FILE} ]]
then
	echo ""Already running"" | tee -a ""${BUILD_LOG_FILE}""
	exit 
fi

trap cleanup TERM INT QUIT EXIT

touch ""${LOCK_FILE}""
# Fetch changes
pushd ""${LOCAL_CHECKOUT}""
git fetch origin master 2>&1 | tee -a ""${BUILD_LOG_FILE}""
# See if there are any incoming changes
updates=$(git log HEAD..origin/master --oneline | wc -l)
echo ""Updates: ${updates}"" | tee -a ""${BUILD_LOG_FILE}""
if [[ ${updates} -gt 0 ]] || [[ ${FORCE} -gt 0 ]]
then
	touch ""${LOG_FILE}""
	pushd ""${LOCAL_CHECKOUT}""
	echo ""Pulling"" | tee -a ""${LOG_FILE}""
	git pull origin master 2>&1 | tee -a ""${LOG_FILE}""
	popd
	# This won't exist in a bit so no point pushd'ing
	pushd ""${BUILD_DIR}""
	# Clone to NAME
	git clone ""${REPO}"" ""${NAME}""
	popd
	${PRE_SCRIPT} 2>&1 | tee -a ""${LOG_FILE}""
	EXIT_CODE=""${?}""
        if [[ ${EXIT_CODE} -ne 0 ]]
	then
		msg=""ANGRY ${NAME} on $(hostname)""
	fi
	pushd ""${BUILD_DIR}""/""${NAME}""/""${TEST_DIR}""
	timeout ""${TIMEOUT_S}"" ""${TEST_COMMAND}"" 2>&1 | tee -a ""${LOG_FILE}""
	EXIT_CODE=$?
	popd
        if [[ ${EXIT_CODE} -ne 0 ]]
	then
		if [[ ${EXIT_CODE} -eq 124 ]]
		then
			msg=""ANGRY (TIMEOUT) ${NAME} on $(hostname)""
		else
			msg=""ANGRY ${NAME} on $(hostname)""
		fi
	else
		msg=""HAPPY ${NAME} on $(hostname)""
	fi
	${POST_SCRIPT} 2>&1 | tee -a ""${LOG_FILE}""
	EXIT_CODE=$?
        if [[ ${EXIT_CODE} -ne 0 ]]
	then
		msg=""ANGRY ${NAME} on $(hostname)""
	fi
	send_mail ""${msg}""
fi"
bash2048,"declare -ia board    # array that keeps track of game status
declare -i pieces    # number of pieces present on board
declare -i score=0   # score variable
declare -i flag_skip # flag that prevents doing more than one operation on
                     # single field in one step
declare -i moves     # stores number of possible moves to determine if player lost 
                     # the game
declare ESC=$'\e'    # escape byte
declare header=""Bash 2048 v1.1 (https://github.com/mydzor/bash2048)""

declare -i start_time=$(date +%s)

#default config
declare -i board_size=4
declare -i target=2048
declare -i reload_flag=0
declare config_dir=""$HOME/.bash2048""

#for colorizing numbers
declare -a colors
colors[2]=33         # yellow text
colors[4]=32         # green text
colors[8]=34         # blue text
colors[16]=36        # cyan text
colors[32]=35        # purple text
colors[64]=""33m\033[7""        # yellow background
colors[128]=""32m\033[7""       # green background
colors[256]=""34m\033[7""       # blue background
colors[512]=""36m\033[7""       # cyan background
colors[1024]=""35m\033[7""      # purple background
colors[2048]=""31m\033[7""      # red background (won with default target)

exec 3>/dev/null     # no logging by default

trap ""end_game 0 1"" INT #handle INT signal

#simplified replacement of seq command
function _seq {
  local cur=1
  local max
  local inc=1
  case $# in
    1) let max=$1;;
    2) let cur=$1
       let max=$2;;
    3) let cur=$1
       let inc=$2
       let max=$3;;
  esac
  while test $max -ge $cur; do
    printf ""$cur ""
    let cur+=inc
  done
}

# print currect status of the game, last added pieces are marked red
function print_board {
  clear
  printf ""$header pieces=$pieces target=$target score=$score\n""
  printf ""Board status:\n"" >&3
  printf ""\n""
  printf '/------'
  for l in $(_seq 1 $index_max); do
    printf '+------'
  done
  printf '\\\n'
  for l in $(_seq 0 $index_max); do
    printf '|'
    for m in $(_seq 0 $index_max); do
      if let ${board[l*$board_size+m]}; then
        if let '(last_added==(l*board_size+m))|(first_round==(l*board_size+m))'; then
          printf '\033[1m\033[31m %4d \033[0m|' ${board[l*$board_size+m]}
        else
          printf ""\033[1m\033[${colors[${board[l*$board_size+m]}]}m %4d\033[0m |"" ${board[l*$board_size+m]}
        fi
        printf "" %4d |"" ${board[l*$board_size+m]} >&3
      else
        printf '      |'
        printf '      |' >&3
      fi
    done
    let l==$index_max || {
      printf '\n|------'
      for l in $(_seq 1 $index_max); do
        printf '+------'
      done
      printf '|\n'
      printf '\n' >&3
    }
  done
  printf '\n\\------'
  for l in $(_seq 1 $index_max); do
    printf '+------'
  done
  printf '/\n'
}

# Generate new piece on the board
# inputs:
#         $board  - original state of the game board
#         $pieces - original number of pieces
# outputs:
#         $board  - new state of the game board
#         $pieces - new number of pieces
function generate_piece {
  while true; do
    let pos=RANDOM%fields_total
    let board[$pos] || {
      let value=RANDOM%10?2:4
      board[$pos]=$value
      last_added=$pos
      printf ""Generated new piece with value $value at position [$pos]\n"" >&3
      break;
    }
  done
  let pieces++
}

# perform push operation between two pieces
# inputs:
#         $1 - push position, for horizontal push this is row, for vertical column
#         $2 - recipient piece, this will hold result if moving or joining
#         $3 - originator piece, after moving or joining this will be left empty
#         $4 - direction of push, can be either ""up"", ""down"", ""left"" or ""right""
#         $5 - if anything is passed, do not perform the push, only update number 
#              of valid moves
#         $board - original state of the game board
# outputs:
#         $change    - indicates if the board was changed this round
#         $flag_skip - indicates that recipient piece cannot be modified further
#         $board     - new state of the game board
function push_pieces {
  case $4 in
    ""up"")
      let ""first=$2*$board_size+$1""
      let ""second=($2+$3)*$board_size+$1""
      ;;
    ""down"")
      let ""first=(index_max-$2)*$board_size+$1""
      let ""second=(index_max-$2-$3)*$board_size+$1""
      ;;
    ""left"")
      let ""first=$1*$board_size+$2""
      let ""second=$1*$board_size+($2+$3)""
      ;;
    ""right"")
      let ""first=$1*$board_size+(index_max-$2)""
      let ""second=$1*$board_size+(index_max-$2-$3)""
      ;;
  esac
  let ${board[$first]} || { 
    let ${board[$second]} && {
      if test -z $5; then
        board[$first]=${board[$second]}
        let board[$second]=0
        let change=1
        printf ""move piece with value ${board[$first]} from [$second] to [$first]\n"" >&3
      else
        let moves++
      fi
      return
    }
    return
  }
  let ${board[$second]} && let flag_skip=1
  let ""${board[$first]}==${board[second]}"" && { 
    if test -z $5; then
      let board[$first]*=2
      let ""board[$first]==$target"" && end_game 1
      let board[$second]=0
      let pieces-=1
      let change=1
      let score+=${board[$first]}
      printf ""joined piece from [$second] with [$first], new value=${board[$first]}\n"" >&3
    else
      let moves++
    fi
  }
}

function apply_push {
  printf ""\n\ninput: $1 key\n"" >&3
  for i in $(_seq 0 $index_max); do
    for j in $(_seq 0 $index_max); do
      flag_skip=0
      let increment_max=index_max-j
      for k in $(_seq 1 $increment_max); do
        let flag_skip && break
        push_pieces $i $j $k $1 $2
      done 
    done
  done
}

function check_moves {
  let moves=0
  apply_push up fake
  apply_push down fake
  apply_push left fake
  apply_push right fake
}

function key_react {
  let change=0
  read -d '' -sn 1
  test ""$REPLY"" = ""$ESC"" && {
    read -d '' -sn 1 -t1
    test ""$REPLY"" = ""["" && {
      read -d '' -sn 1 -t1
      case $REPLY in
        A) apply_push up;;
        B) apply_push down;;
        C) apply_push right;;
        D) apply_push left;;
      esac
    }
  } || {
    case $REPLY in
      k) apply_push up;;
      j) apply_push down;;
      l) apply_push right;;
      h) apply_push left;;

      w) apply_push up;;
      s) apply_push down;;
      d) apply_push right;;
      a) apply_push left;;
    esac
  }
}

function save_game {
  rm -rf ""$config_dir""
  mkdir ""$config_dir""
  echo ""${board[@]}"" > ""$config_dir/board""
  echo ""$board_size"" > ""$config_dir/board_size""
  echo ""$pieces"" > ""$config_dir/pieces""
  echo ""$target"" > ""$config_dir/target""
#  echo ""$log_file"" > ""$config_dir/log_file""
  echo ""$score"" > ""$config_dir/score""
  echo ""$first_round"" > ""$config_dir/first_round""
}

function reload_game {
  printf ""Loading saved game...\n"" >&3

  if test ! -d ""$config_dir""; then
    return
  fi
  board=(`cat ""$config_dir/board""`)
  board_size=(`cat ""$config_dir/board_size""`)
  board=(`cat ""$config_dir/board""`)
  pieces=(`cat ""$config_dir/pieces""`)
  first_round=(`cat ""$config_dir/first_round""`)
  target=(`cat ""$config_dir/target""`)
  score=(`cat ""$config_dir/score""`)

  fields_total=board_size*board_size
  index_max=board_size-1
}

function end_game {
  # count game duration
  end_time=$(date +%s) 
  let total_time=end_time-start_time
  
  print_board
  printf ""Your score: $score\n""
  
  printf ""This game lasted ""

  `date --version > /dev/null 2>&1`
  if [[ ""$?"" -eq 0 ]]; then
      date -u -d @${total_time} +%T
  else
      date -u -r ${total_time} +%T
  fi
  
  stty echo
  let $1 && {
    printf ""Congratulations you have achieved $target\n""
    exit 0
  }
  let test -z $2 && {
    read -n1 -p ""Do you want to overwrite saved game? [y|N]: ""
    test ""$REPLY"" = ""Y"" || test ""$REPLY"" = ""y"" && {
      save_game
      printf ""\nGame saved. Use -r option next to load this game.\n""
      exit 0
    }
    test ""$REPLY"" = """" && {
      printf ""\nGame not saved.\n""
      exit 0
    }
  }
  printf ""\nYou have lost, better luck next time.\033[0m\n""
  exit 0
}

function help {
  cat <<END_HELP
Usage: $1 [-b INTEGER] [-t INTEGER] [-l FILE] [-r] [-h]
  -b			specify game board size (sizes 3-9 allowed)
  -t			specify target score to win (needs to be power of 2)
  -l			log debug info into specified file
  -r			reload the previous game
  -h			this help
END_HELP
}


#parse commandline options
while getopts ""b:t:l:rh"" opt; do
  case $opt in
    b ) board_size=""$OPTARG""
      let '(board_size>=3)&(board_size<=9)' || {
        printf ""Invalid board size, please choose size between 3 and 9\n""
        exit -1 
      };;
    t ) target=""$OPTARG""
      printf ""obase=2;$target\n"" | bc | grep -e '^1[^1]*$'
      let $? && {
        printf ""Invalid target, has to be power of two\n""
        exit -1 
      };;
    r ) reload_flag=""1"";;
    h ) help $0
        exit 0;;
    l ) exec 3>$OPTARG;;
    \?) printf ""Invalid option: -""$opt"", try $0 -h\n"" >&2
            exit 1;;
    : ) printf ""Option -""$opt"" requires an argument, try $0 -h\n"" >&2
            exit 1;;
  esac
done

#init board
let fields_total=board_size*board_size
let index_max=board_size-1
for i in $(_seq 0 $fields_total); do board[$i]=""0""; done
let pieces=0
generate_piece
first_round=$last_added
generate_piece

#load saved game if flag is set
if test $reload_flag = ""1""; then
  reload_game
fi

while true; do
  print_board
  key_react
  let change && generate_piece
  first_round=-1
  let pieces==fields_total && {
   check_moves
   let moves==0 && end_game 0 #lose the game
  }
done"
port80-oneliner," $ clear;while x=0; do clear;date;echo """";echo ""  [Count] | [IP ADDR]"";echo ""-------------------"";netstat -np|grep :80|grep -v LISTEN|awk '{print $5}'|cut -d: -f1|uniq -c; sleep 5;done"
oh-my-git,"function enrich {
    local flag=$1
    local symbol=$2

    local color_on=${3:-$omg_default_color_on}

    if [[ $flag != true && $omg_use_color_off == false ]]; then symbol=' '; fi
    if [[ $flag == true ]]; then local color=$color_on; else local color=$omg_default_color_off; fi    

    echo -n ""${prompt}${color}${symbol}${reset} ""
}

function get_current_action () {
    local info=""$(git rev-parse --git-dir 2>/dev/null)""
    if [ -n ""$info"" ]; then
        local action
        if [ -f ""$info/rebase-merge/interactive"" ]
        then
            action=${is_rebasing_interactively:-""rebase -i""}
        elif [ -d ""$info/rebase-merge"" ]
        then
            action=${is_rebasing_merge:-""rebase -m""}
        else
            if [ -d ""$info/rebase-apply"" ]
            then
                if [ -f ""$info/rebase-apply/rebasing"" ]
                then
                    action=${is_rebasing:-""rebase""}
                elif [ -f ""$info/rebase-apply/applying"" ]
                then
                    action=${is_applying_mailbox_patches:-""am""}
                else
                    action=${is_rebasing_mailbox_patches:-""am/rebase""}
                fi
            elif [ -f ""$info/MERGE_HEAD"" ]
            then
                action=${is_merging:-""merge""}
            elif [ -f ""$info/CHERRY_PICK_HEAD"" ]
            then
                action=${is_cherry_picking:-""cherry-pick""}
            elif [ -f ""$info/BISECT_LOG"" ]
            then
                action=${is_bisecting:-""bisect""}
            fi
        fi

        if [[ -n $action ]]; then printf ""%s"" ""${1-}$action${2-}""; fi
    fi
}

function build_prompt {
    local enabled=`git config --get oh-my-git.enabled`
    if [[ ${enabled} == false ]]; then
        echo ""${PSORG}""
        exit;
    fi

    local prompt=""""
    
    # Git info
    local current_commit_hash=$(git rev-parse HEAD 2> /dev/null)
    if [[ -n $current_commit_hash ]]; then local is_a_git_repo=true; fi
    
    if [[ $is_a_git_repo == true ]]; then
        local current_branch=$(git rev-parse --abbrev-ref HEAD 2> /dev/null)
        if [[ $current_branch == 'HEAD' ]]; then local detached=true; fi

        local number_of_logs=""$(git log --pretty=oneline -n1 2> /dev/null | wc -l)""
        if [[ $number_of_logs -eq 0 ]]; then
            local just_init=true
        else
            local upstream=$(git rev-parse --symbolic-full-name --abbrev-ref @{upstream} 2> /dev/null)
            if [[ -n ""${upstream}"" && ""${upstream}"" != ""@{upstream}"" ]]; then local has_upstream=true; fi

            local git_status=""$(git status --porcelain 2> /dev/null)""
            local action=""$(get_current_action)""

            if [[ $git_status =~ ($'\n'|^).M ]]; then local has_modifications=true; fi
            if [[ $git_status =~ ($'\n'|^)M ]]; then local has_modifications_cached=true; fi
            if [[ $git_status =~ ($'\n'|^)A ]]; then local has_adds=true; fi
            if [[ $git_status =~ ($'\n'|^).D ]]; then local has_deletions=true; fi
            if [[ $git_status =~ ($'\n'|^)D ]]; then local has_deletions_cached=true; fi
            if [[ $git_status =~ ($'\n'|^)[MAD] && ! $git_status =~ ($'\n'|^).[MAD\?] ]]; then local ready_to_commit=true; fi

            local number_of_untracked_files=$(\grep -c ""^??"" <<< ""${git_status}"")
            if [[ $number_of_untracked_files -gt 0 ]]; then local has_untracked_files=true; fi
        
            local tag_at_current_commit=$(git describe --exact-match --tags $current_commit_hash 2> /dev/null)
            if [[ -n $tag_at_current_commit ]]; then local is_on_a_tag=true; fi
        
            if [[ $has_upstream == true ]]; then
                local commits_diff=""$(git log --pretty=oneline --topo-order --left-right ${current_commit_hash}...${upstream} 2> /dev/null)""
                local commits_ahead=$(\grep -c ""^<"" <<< ""$commits_diff"")
                local commits_behind=$(\grep -c ""^>"" <<< ""$commits_diff"")
            fi

            if [[ $commits_ahead -gt 0 && $commits_behind -gt 0 ]]; then local has_diverged=true; fi
            if [[ $has_diverged == false && $commits_ahead -gt 0 ]]; then local should_push=true; fi
        
            local will_rebase=$(git config --get branch.${current_branch}.rebase 2> /dev/null)
        
            local number_of_stashes=""$(git stash list -n1 2> /dev/null | wc -l)""
            if [[ $number_of_stashes -gt 0 ]]; then local has_stashes=true; fi
        fi
    fi
    
    echo ""$(custom_build_prompt ${enabled:-true} ${current_commit_hash:-""""} ${is_a_git_repo:-false} ${current_branch:-""""} ${detached:-false} ${just_init:-false} ${has_upstream:-false} ${has_modifications:-false} ${has_modifications_cached:-false} ${has_adds:-false} ${has_deletions:-false} ${has_deletions_cached:-false} ${has_untracked_files:-false} ${ready_to_commit:-false} ${tag_at_current_commit:-""""} ${is_on_a_tag:-false} ${has_upstream:-false} ${commits_ahead:-false} ${commits_behind:-false} ${has_diverged:-false} ${should_push:-false} ${will_rebase:-false} ${has_stashes:-false} ${action})""
    
}

function_exists() {
    declare -f -F $1 > /dev/null
    return $?
}

function eval_prompt_callback_if_present {
        function_exists omg_prompt_callback && echo ""$(omg_prompt_callback)""
}"
git-prompt,"[[ $- != *i* ]]  &&  return

        # bash version check
        if [[ -z ${BASH_VERSION}  ||  ""${BASH_VERSINFO[0]}"" -lt  4 ]]; then
                echo ""git-prompt requires bash-v4 or newer,  git-prompt is not enabled.""
                return
        fi

        # clear vars from previous invocation
        unset dir_color rc_color user_id_color root_id_color init_vcs_color clean_vcs_color
        unset modified_vcs_color added_vcs_color addmoded_vcs_color untracked_vcs_color op_vcs_color detached_vcs_color hex_vcs_color
        unset rawhex_len

        # work around for conflict with vte.sh
        unset VTE_VERSION

###################################################################   CONFIG

        #####  read config file if any.


        conf=git-prompt.conf;                   [[ -r $conf ]]  && . $conf
        conf=/etc/git-prompt.conf;              [[ -r $conf ]]  && . $conf
        conf=~/.git-prompt.conf;                [[ -r $conf ]]  && . $conf
        conf=~/.config/git-prompt.conf;         [[ -r $conf ]]  && . $conf
        unset conf


        #####  set defaults if not set

        git_module=${git_module:-on}
        svn_module=${svn_module:-off}
        hg_module=${hg_module:-on}
        vim_module=${vim_module:-on}
        virtualenv_module=${virtualenv_module:-on}
        error_bell=${error_bell:-off}
        cwd_cmd=${cwd_cmd:-\\w}


        #### dir, rc, root color
        cols=`tput colors`                              # in emacs shell-mode tput colors returns -1
        if [[ -n ""$cols"" && $cols -ge 8 ]];  then       #  if terminal supports colors
                dir_color=${dir_color:-CYAN}
                rc_color=${rc_color:-red}
                virtualenv_color=${virtualenv_color:-green}
                user_id_color=${user_id_color:-blue}
                root_id_color=${root_id_color:-magenta}
        else                                            #  only B/W
                dir_color=${dir_color:-bw_bold}
                rc_color=${rc_color:-bw_bold}
        fi
        unset cols

	#### prompt character, for root/non-root
	prompt_char=${prompt_char:-'>'}
	root_prompt_char=${root_prompt_char:-'>'}

        #### vcs colors
                 init_vcs_color=${init_vcs_color:-WHITE}        # initial
                clean_vcs_color=${clean_vcs_color:-blue}        # nothing to commit (working directory clean)
             modified_vcs_color=${modified_vcs_color:-red}      # Changed but not updated:
                added_vcs_color=${added_vcs_color:-green}       # Changes to be committed:
             addmoded_vcs_color=${addmoded_vcs_color:-yellow}
            untracked_vcs_color=${untracked_vcs_color:-BLUE}    # Untracked files:
                   op_vcs_color=${op_vcs_color:-MAGENTA}
             detached_vcs_color=${detached_vcs_color:-RED}

                  hex_vcs_color=${hex_vcs_color:-BLACK}         # gray


        max_file_list_length=${max_file_list_length:-100}
        short_hostname=${short_hostname:-off}
        upcase_hostname=${upcase_hostname:-on}
        count_only=${count_only:-off}
        rawhex_len=${rawhex_len:-5}

        aj_max=20


#####################################################################  post config

        ################# make PARSE_VCS_STATUS
        unset PARSE_VCS_STATUS
        [[ $git_module = ""on"" ]]   &&   type git >&/dev/null   &&   PARSE_VCS_STATUS+=""parse_git_status""
        [[ $svn_module = ""on"" ]]   &&   type svn >&/dev/null   &&   PARSE_VCS_STATUS+=""${PARSE_VCS_STATUS+||}parse_svn_status""
        [[ $hg_module  = ""on"" ]]   &&   type hg  >&/dev/null   &&   PARSE_VCS_STATUS+=""${PARSE_VCS_STATUS+||}parse_hg_status""
                                                                    PARSE_VCS_STATUS+=""${PARSE_VCS_STATUS+||}return""
        ################# terminfo colors-16
        #
        #       black?    0 8
        #       red       1 9
        #       green     2 10
        #       yellow    3 11
        #       blue      4 12
        #       magenta   5 13
        #       cyan      6 14
        #       white     7 15
        #
        #       terminfo setaf/setab - sets ansi foreground/background
        #       terminfo sgr0 - resets all attributes
        #       terminfo colors - number of colors
        #
        #################  Colors-256
        #  To use foreground and background colors:
        #       Set the foreground color to index N:    \033[38;5;${N}m
        #       Set the background color to index M:    \033[48;5;${M}m
        # To make vim aware of a present 256 color extension, you can either set
        # the $TERM environment variable to xterm-256color or use vim's -T option
        # to set the terminal. I'm using an alias in my bashrc to do this. At the
        # moment I only know of two color schemes which is made for multi-color
        # terminals like urxvt (88 colors) or xterm: inkpot and desert256,

        ### if term support colors,  then use color prompt, else bold

              black='\['`tput sgr0; tput setaf 0`'\]'
                red='\['`tput sgr0; tput setaf 1`'\]'
              green='\['`tput sgr0; tput setaf 2`'\]'
             yellow='\['`tput sgr0; tput setaf 3`'\]'
               blue='\['`tput sgr0; tput setaf 4`'\]'
            magenta='\['`tput sgr0; tput setaf 5`'\]'
               cyan='\['`tput sgr0; tput setaf 6`'\]'
              white='\['`tput sgr0; tput setaf 7`'\]'

              BLACK='\['`tput setaf 0; tput bold`'\]'
                RED='\['`tput setaf 1; tput bold`'\]'
              GREEN='\['`tput setaf 2; tput bold`'\]'
             YELLOW='\['`tput setaf 3; tput bold`'\]'
               BLUE='\['`tput setaf 4; tput bold`'\]'
            MAGENTA='\['`tput setaf 5; tput bold`'\]'
               CYAN='\['`tput setaf 6; tput bold`'\]'
              WHITE='\['`tput setaf 7; tput bold`'\]'

                dim='\['`tput sgr0; tput setaf p1`'\]'  # half-bright

            bw_bold='\['`tput bold`'\]'

        on=''
        off=': '
        bell=""\[`eval ${!error_bell} tput bel`\]""
        colors_reset='\['`tput sgr0`'\]'

        # replace symbolic colors names to raw treminfo strings
                 init_vcs_color=${!init_vcs_color}
             modified_vcs_color=${!modified_vcs_color}
            untracked_vcs_color=${!untracked_vcs_color}
                clean_vcs_color=${!clean_vcs_color}
                added_vcs_color=${!added_vcs_color}
                   op_vcs_color=${!op_vcs_color}
             addmoded_vcs_color=${!addmoded_vcs_color}
             detached_vcs_color=${!detached_vcs_color}
                  hex_vcs_color=${!hex_vcs_color}

        unset PROMPT_COMMAND

        #######  work around for MC bug.
        #######  specifically exclude emacs, want full when running inside emacs
        if   [[ -z ""$TERM""   ||  (""$TERM"" = ""dumb"" && -z ""$INSIDE_EMACS"")  ||  -n ""$MC_SID"" ]];   then
                unset PROMPT_COMMAND
                PS1=""\w$prompt_char ""
                return 0
        fi

        ####################################################################  MARKERS
        if [[ ""$LC_CTYPE $LC_ALL"" =~ ""UTF"" && $TERM != ""linux"" ]];  then
                elipses_marker=""""
        else
                elipses_marker=""...""
        fi

        export who_where


cwd_truncate() {
        # based on:   https://www.blog.montgomerie.net/pwd-in-the-title-bar-or-a-regex-adventure-in-bash

        # arg1: max path lenght
        # returns abbrivated $PWD  in public ""cwd"" var

        cwd=""${PWD/$HOME/\~}""             # substitute  ""~""

        case $1 in
                full)
                        return
                        ;;
                last)
                        cwd=""${PWD##/*/}""
                        [[ ""$PWD"" == ""$HOME"" ]]  &&  cwd=""~""
                        return
                        ;;
                *)
                        ;;
        esac

        # split path into:  head='~/',  truncateble middle,  last_dir

        local cwd_max_length=$1
        
        if  [[ ""$cwd"" =~ '(~?/)(.*/)([^/]*)$' ]] ;  then  # only valid if path have more than 1 dir
                local path_head=${BASH_REMATCH[1]}
                local path_middle=${BASH_REMATCH[2]}
                local path_last_dir=${BASH_REMATCH[3]}

                local cwd_middle_max=$(( $cwd_max_length - ${#path_last_dir} ))
                [[ $cwd_middle_max < 0  ]]  &&  cwd_middle_max=0


		# trunc middle if over limit
                if   [[ ${#path_middle}   -gt   $(( $cwd_middle_max + ${#elipses_marker} + 5 )) ]];   then

			# truncate
			middle_tail=${path_middle:${#path_middle}-${cwd_middle_max}}

			# trunc on dir boundary (trunc 1st, probably tuncated dir)
			[[ $middle_tail =~ '[^/]*/(.*)$' ]]
			middle_tail=${BASH_REMATCH[1]}

			# use truncated only if we cut at least 4 chars
			if [[ $((  ${#path_middle} - ${#middle_tail}))  -gt 4  ]];  then
				cwd=$path_head$elipses_marker$middle_tail$path_last_dir
			fi
                fi
        fi
        return
 }


set_shell_label() {

        xterm_label() {
                local args=""$*""
                echo  -n ""]2;${args:0:200}"" ;    # FIXME: replace hardcodes with terminfo codes
        }

        screen_label() {
                # FIXME: run this only if screen is in xterm (how to test for this?)
                xterm_label  ""$plain_who_where $@""

                # FIXME $STY not inherited though ""su -""
                [ ""$STY"" ] && screen -S $STY -X title ""$*""
        }
        if [[ -n ""$STY"" ]]; then
                screen_label ""$*""
        else
                case $TERM in

                        screen*)
                                screen_label ""$*""
                                ;;

                        xterm* | rxvt* | gnome-* | konsole | eterm | wterm )
                                # is there a capability which we can to test
                                # for ""set term title-bar"" and its escapes?
                                xterm_label  ""$plain_who_where $@""
                                ;;

                        *)
                                ;;
                esac
        fi
 }

    export -f set_shell_label

###################################################### ID (user name)
        id=`id -un`
        id=${id#$default_user}

########################################################### TTY
        tty=`tty`
        tty=`echo $tty | sed ""s:/dev/pts/:p:; s:/dev/tty::"" `           # RH tty devs
        tty=`echo $tty | sed ""s:/dev/vc/:vc:"" `                         # gentoo tty devs

        if [[ ""$TERM"" = ""screen"" ]] ;  then

                #       [ ""$WINDOW"" = """" ] && WINDOW=""?""
                #
                #               # if under screen then make tty name look like s1-p2
                #               # tty=""${WINDOW:+s}$WINDOW${WINDOW:+-}$tty""
                #       tty=""${WINDOW:+s}$WINDOW""  # replace tty name with screen number
                tty=""$WINDOW""  # replace tty name with screen number
        fi

        # we don't need tty name under X11
        case $TERM in
                xterm* | rxvt* | gnome-terminal | konsole | eterm* | wterm | cygwin)  unset tty ;;
                *);;
        esac

        dir_color=${!dir_color}
        rc_color=${!rc_color}
        virtualenv_color=${!virtualenv_color}
        user_id_color=${!user_id_color}
        root_id_color=${!root_id_color}

        ########################################################### HOST
        ### we don't display home host/domain  $SSH_* set by SSHD or keychain

        # How to find out if session is local or remote? Working with ""su -"", ssh-agent, and so on ?

        ## is sshd our parent?
        # if    { for ((pid=$$; $pid != 1 ; pid=`ps h -o pid --ppid $pid`)); do ps h -o command -p $pid; done | grep -q sshd && echo == REMOTE ==; }
        #then

        host=${HOSTNAME}
        if [[ $short_hostname = ""on"" ]]; then
			if [[ ""$(uname)"" =~ ""CYGWIN"" ]]; then
				host=`hostname`
			else
				host=`hostname -s`
			fi
        fi
        host=${host#$default_host}
        uphost=`echo ${host} | tr a-z-. A-Z_`
        if [[ $upcase_hostname = ""on"" ]]; then
                host=${uphost}
        fi

        host_color=${uphost}_host_color
        host_color=${!host_color}
        if [[ -z $host_color && -x /usr/bin/cksum ]] ;  then
                cksum_color_no=`echo $uphost | cksum  | awk '{print $1%6}'`
                color_index=(green yellow blue magenta cyan white)              # FIXME:  bw,  color-256
                host_color=${color_index[cksum_color_no]}
        fi

        host_color=${!host_color}

        # we might already have short host name
        host=${host%.$default_domain}

#################################################################### WHO_WHERE
        #  [[user@]host[-tty]]

        if [[ -n $id  || -n $host ]] ;   then
                [[ -n $id  &&  -n $host ]]  &&  at='@'  || at=''
                color_who_where=""${id}${host:+$host_color$at$host}${tty:+ $tty}""
                plain_who_where=""${id}$at$host""

                # add trailing "" ""
                color_who_where=""$color_who_where ""
                plain_who_where=""$plain_who_where ""

                # if root then make it root_color
                if [ ""$id"" == ""root"" ]  ; then
                        user_id_color=$root_id_color
                        prompt_char=""$root_prompt_char""
                fi
                color_who_where=""$user_id_color$color_who_where$colors_reset""
        else
                color_who_where=''
        fi


parse_svn_status() {

        [[   -d .svn  ]] || return 1

        vcs=svn

        ### get rev
        eval `
            svn info |
                sed -n ""
                    s@^URL[^/]*//@repo_dir=@p
                    s/^Revision: /rev=/p
                ""
        `
        ### get status

        unset status modified added clean init added mixed untracked op detached
        eval `svn status 2>/dev/null |
                sed -n '
                    s/^A...    \([^.].*\)/modified=modified;             modified_files[${#modified_files[@]}]=\""\1\"";/p
                    s/^M...    \([^.].*\)/modified=modified;             modified_files[${#modified_files[@]}]=\""\1\"";/p
                    s/^\?...    \([^.].*\)/untracked=untracked;  untracked_files[${#untracked_files[@]}]=\""\1\"";/p
                '
        `
        # TODO branch detection if standard repo layout

        [[  -z $modified ]]   &&  [[ -z $untracked ]]  &&  clean=clean
        vcs_info=svn:r$rev
 }

parse_hg_status() {

        # 
        hg_root=`hg root 2>/dev/null` || return 1

        vcs=hg

        ### get status
        unset status modified added clean init added mixed untracked op detached

        eval `hg status 2>/dev/null |
                sed -n '
                        s/^M \([^.].*\)/modified=modified; modified_files[${#modified_files[@]}]=\""\1\"";/p
                        s/^A \([^.].*\)/added=added; added_files[${#added_files[@]}]=\""\1\"";/p
                        s/^R \([^.].*\)/added=added;/p
                        s/^! \([^.].*\)/modified=modified;/p
                        s/^? \([^.].*\)/untracked=untracked; untracked_files[${#untracked_files[@]}]=\\""\1\\"";/p
        '`

        branch=`hg branch 2> /dev/null`

        [[ -f $hg_root/.hg/bookmarks.current ]] && bookmark=`cat ""$hg_root/.hg/bookmarks.current""`

        [[ -z $modified ]]   &&   [[ -z $untracked ]]   &&   [[ -z $added ]]   &&   clean=clean
        vcs_info=${branch/default/D}
        if [[ ""$bookmark"" ]] ;  then
                vcs_info+=/$bookmark
        fi
 }



parse_git_status() {

        # TODO add status: LOCKED (.git/index.lock)

        git_dir=`[[ $git_module = ""on"" ]]  &&  git rev-parse --git-dir 2> /dev/null`
        #git_dir=`eval \$$git_module  git rev-parse --git-dir 2> /dev/null`
        #git_dir=` git rev-parse --git-dir 2> /dev/null`

        [[  -n ${git_dir/./} ]]   ||   return  1
        [[  -f ${git_dir}/git-prompt-ignored ]]   &&   return  1

        vcs=git

        ##########################################################   GIT STATUS
	added_files=()
	modified_files=()
	untracked_files=()
        [[ $rawhex_len -gt 0 ]]  && freshness=""$dim=""

        unset branch status modified added clean init added mixed untracked op detached

        # work around for VTE bug (hang on printf)
        unset VTE_VERSION

	# info not in porcelain status
        eval "" $(
                LANG=C git status 2>/dev/null |
                    sed -n '
                        s/^\(# \)*On branch /branch=/p
                        s/^nothing to commi.*/clean=clean/p
                        s/^\(# \)*Initial commi.*/init=init/p
                        s/^\(# \)*Your branch is ahead of \(.\).\+\1 by [[:digit:]]\+ commit.*/freshness=${WHITE}/p
                        s/^\(# \)*Your branch is behind \(.\).\+\1 by [[:digit:]]\+ commit.*/freshness=${YELLOW}/p
                        s/^\(# \)*Your branch and \(.\).\+\1 have diverged.*/freshness=${YELLOW}/p
                    '
        )""

	# porcelain file list
                                        # TODO:  sed-less -- http://tldp.org/LDP/abs/html/arrays.html  -- Example 27-5

                                        # git bug:  (was reported to git@vger.kernel.org )
                                        # echo 1 > ""with space""
                                        # git status --porcelain
                                        # ?? with space                   <------------ NO QOUTES
                                        # git add with\ space
                                        # git status --porcelain
                                        # A  ""with space""                 <------------- WITH QOUTES

        eval "" $(
                LANG=C git status --porcelain 2>/dev/null |
                        sed -n '
                                s,^[MARC]. \([^\""][^/]*/\?\).*,         added=added;           [[ \"" ${added_files[@]} \""      =~ \"" \1 \"" ]]   || added_files[${#added_files[@]}]=\""\1\"",p
                                s,^[MARC]. \""\([^/]\+/\?\).*\""$,        added=added;           [[ \"" ${added_files[@]} \""      =~ \"" \1 \"" ]]   || added_files[${#added_files[@]}]=\""\1\"",p
                                s,^.[MAU] \([^\""][^/]*/\?\).*,          modified=modified;     [[ \"" ${modified_files[@]} \""   =~ \"" \1 \"" ]]   || modified_files[${#modified_files[@]}]=\""\1\"",p
                                s,^.[MAU] \""\([^/]\+/\?\).*\""$,         modified=modified;     [[ \"" ${modified_files[@]} \""   =~ \"" \1 \"" ]]   || modified_files[${#modified_files[@]}]=\""\1\"",p
                                s,^?? \([^\""][^/]*/\?\).*,              untracked=untracked;   [[ \"" ${untracked_files[@]} \""  =~ \"" \1 \"" ]]   || untracked_files[${#untracked_files[@]}]=\""\1\"",p
                                s,^?? \""\([^/]\+/\?\).*\""$,             untracked=untracked;   [[ \"" ${untracked_files[@]} \""  =~ \"" \1 \"" ]]   || untracked_files[${#untracked_files[@]}]=\""\1\"",p
                        '   # |tee /dev/tty
        )""

        if  ! grep -q ""^ref:"" ""$git_dir/HEAD""  2>/dev/null;   then
                detached=detached
        fi


        #################  GET GIT OP

        unset op

        if [[ -d ""$git_dir/.dotest"" ]] ;  then

                if [[ -f ""$git_dir/.dotest/rebasing"" ]] ;  then
                        op=""rebase""

                elif [[ -f ""$git_dir/.dotest/applying"" ]] ; then
                        op=""am""

                else
                        op=""am/rebase""

                fi

        elif  [[ -f ""$git_dir/.dotest-merge/interactive"" ]] ;  then
                op=""rebase -i""
                # ??? branch=""$(cat ""$git_dir/.dotest-merge/head-name"")""

        elif  [[ -d ""$git_dir/.dotest-merge"" ]] ;  then
                op=""rebase -m""
                # ??? branch=""$(cat ""$git_dir/.dotest-merge/head-name"")""

        # lvv: not always works. Should  ./.dotest  be used instead?
        elif  [[ -f ""$git_dir/MERGE_HEAD"" ]] ;  then
                op=""merge""
                # ??? branch=""$(git symbolic-ref HEAD 2>/dev/null)""

        elif  [[ -f ""$git_dir/index.lock"" ]] ;  then
                op=""locked""

        else
                [[  -f ""$git_dir/BISECT_LOG""  ]]   &&  op=""bisect""
                # ??? branch=""$(git symbolic-ref HEAD 2>/dev/null)"" || \
                #    branch=""$(git describe --exact-match HEAD 2>/dev/null)"" || \
                #    branch=""$(cut -c1-7 ""$git_dir/HEAD"")...""
        fi


        ####  GET GIT HEX-REVISION
        if  [[ $rawhex_len -gt 0 ]] ;  then
                rawhex=`git rev-parse HEAD 2>/dev/null`
                rawhex=${rawhex/HEAD/}
                rawhex=""$hex_vcs_color${rawhex:0:$rawhex_len}""
        else
                rawhex=""""
        fi

        #### branch
        branch=${branch/#master/M}

                        # another method of above:
                        # branch=$(git symbolic-ref -q HEAD || { echo -n ""detached:"" ; git name-rev --name-only HEAD 2>/dev/null; } )
                        # branch=${branch#refs/heads/}

        ### compose vcs_info

        if [[ $init ]];  then
                vcs_info=${white}init

        else
                if [[ ""$detached"" ]] ;  then
                        branch=""<detached:`git name-rev --name-only HEAD 2>/dev/null`""


                elif   [[ ""$op"" ]];  then
                        branch=""$op:$branch""
                        if [[ ""$op"" == ""merge"" ]] ;  then
                            branch+=""<--$(git name-rev --name-only $(<$git_dir/MERGE_HEAD))""
                        fi
                        #branch=""<$branch>""
                fi
                vcs_info=""$branch$freshness$rawhex""

        fi
 }


parse_vcs_status() {

        unset   file_list modified_files untracked_files added_files
        unset   vcs vcs_info
        unset   status modified untracked added init detached
        unset   file_list modified_files untracked_files added_files

        [[ $vcs_ignore_dir_list =~ $PWD ]] && return

        eval   $PARSE_VCS_STATUS


        ### status:  choose primary (for branch color)
        unset status
        status=${op:+op}
        status=${status:-$detached}
        status=${status:-$clean}
        status=${status:-$modified}
        status=${status:-$added}
        status=${status:-$untracked}
        status=${status:-$init}
                                # at least one should be set
                                : ${status?prompt internal error: git status}
        eval vcs_color=""\${${status}_vcs_color}""
                                # no def:  vcs_color=${vcs_color:-$WHITE}    # default


        ### VIM

        if  [[ $vim_module = ""on"" ]] ;  then
                # equivalent to vim_glob=`ls .*.vim`  but without running ls
                unset vim_glob vim_file vim_files
                old_nullglob=`shopt -p nullglob`
                    shopt -s nullglob
                    vim_glob=`echo .*.sw?`
                eval $old_nullglob

                if [[ $vim_glob ]];  then
                    set $vim_glob
                    #vim_file=${vim_glob#.}
                    if [[ $# > 1 ]] ; then
                            vim_files=""*""
                    else
                            vim_file=${1#.}
                            vim_file=${vim_file/.sw?/}
                            [[ .${vim_file}.swp -nt $vim_file ]]  && vim_files=$vim_file
                    fi
                    # if swap is newer,  then this is unsaved vim session
                    # [temoto custom] if swap is older, then it must be deleted, so show all swaps.
                fi
        fi


        ### file list
        unset file_list
        if [[ $count_only = ""on"" ]] ; then
                [[ ${added_files[0]}     ]]  &&  file_list+="" ""${added_vcs_color}+${#added_files[@]}
                [[ ${modified_files[0]}  ]]  &&  file_list+="" ""${modified_vcs_color}*${#modified_files[@]}
                [[ ${untracked_files[0]} ]]  &&  file_list+="" ""${untracked_vcs_color}?${#untracked_files[@]}
        else
                [[ ${added_files[0]}     ]]  &&  file_list+="" ""$added_vcs_color${added_files[@]}
                [[ ${modified_files[0]}  ]]  &&  file_list+="" ""$modified_vcs_color${modified_files[@]}
                [[ ${untracked_files[0]} ]]  &&  file_list+="" ""$untracked_vcs_color${untracked_files[@]}
        fi
        [[ ${vim_files}          ]]  &&  file_list+="" ""${MAGENTA}vim:${vim_files}

        if [[ ${#file_list} -gt $max_file_list_length ]]  ;  then
                file_list=${file_list:0:$max_file_list_length}
                if [[ $max_file_list_length -gt 0 ]]  ;  then
                        file_list=""${file_list% *} $elipses_marker""
                fi
        fi


        head_local=""$vcs_color(${vcs_info}$vcs_color${file_list}$vcs_color)""

        ### fringes
        head_local=""${head_local+$vcs_color$head_local }""
        #above_local=""${head_local+$vcs_color$head_local\n}""
        #tail_local=""${tail_local+$vcs_color $tail_local}${dir_color}""
 }

parse_virtualenv_status() {
    unset virtualenv

    [[ $virtualenv_module = ""on"" ]] || return 1

    if [[ -n ""$VIRTUAL_ENV"" ]] ; then
	virtualenv=`basename $VIRTUAL_ENV`
	rc=""$rc $virtualenv_color<$virtualenv> ""
    fi
 }

disable_set_shell_label() {
        trap - DEBUG  >& /dev/null
 }

# show currently executed command in label
enable_set_shell_label() {
        disable_set_shell_label
	# check for BASH_SOURCE being empty, no point running set_shell_label on every line of .bashrc
        trap '[[ -z ""$BASH_SOURCE"" && ($BASH_COMMAND != prompt_command_function) ]] &&
	     set_shell_label $BASH_COMMAND' DEBUG  >& /dev/null
 }

declare -ft disable_set_shell_label
declare -ft enable_set_shell_label

# autojump (see http://wiki.github.com/joelthelion/autojump)

# TODO reverse the line order of a file
#awk ' { line[NR] = $0 }
#      END  { for (i=NR;i>0;i--)
#             print line[i] }' listlogs

j (){
        : ${1? usage: j dir-beginning}
        # go in ring buffer starting from current index.  cd to first matching dir
        for (( i=(aj_idx-1)%aj_max;   i != aj_idx%aj_max;  i=(--i+aj_max)%aj_max )) ; do
                if [[ ${aj_dir_list[$i]} =~ ^.*/$1[^/]*$ ]] ; then
                        cd ""${aj_dir_list[$i]}""
                        return
                fi
        done
        echo '?'
 }

alias jumpstart='echo ${aj_dir_list[@]}'

###################################################################### PROMPT_COMMAND

prompt_command_function() {
        rc=""$?""

        if [[ ""$rc"" == ""0"" ]]; then
                rc=""""
        else
                rc=""$rc_color$rc$colors_reset$bell ""
        fi

        cwd=${PWD/$HOME/\~}                     # substitute  ""~""
        set_shell_label ""${cwd##[/~]*/}/""       # default label - path last dir

	parse_virtualenv_status
        parse_vcs_status

        # autojump
        if [[ ${aj_dir_list[aj_idx%aj_max]} != $PWD ]] ; then
              aj_dir_list[++aj_idx%aj_max]=""$PWD""
        fi

        # if cwd_cmd have back-slash, then assign it value to cwd
        # else eval cwd_cmd,  cwd should have path after exection
        eval ""${cwd_cmd/\\/cwd=\\\\}""

        PS1=""$colors_reset$rc$head_local$color_who_where$dir_color$cwd$tail_local$dir_color$prompt_char $colors_reset""

        unset head_local tail_local pwd
 }

        PROMPT_COMMAND=prompt_command_function

        enable_set_shell_label

        unset rc id tty modified_files file_list"
calculator,"echo ""Enter two numbers: ""
read a
read b

#input type of operation

echo ""Enter your choice: ""
echo ""1. Addition""
echo ""2. Substraction""
echo ""3. Multiplication""
echo ""4. Division""
read ch

#Acting on the user input

case $ch in
   1) res=`echo $a + $b | bc`
   ;;
   2) res=`echo $a - $b | bc`
   ;;
   3) res=`echo $a \* $b | bc`
   ;;
   4) res=`echo ""scale=2; $a / $b"" | bc`
   ;;
esac

#Printing result
echo ""Result: $res""
"
special-pattern,"#!/bin/bash

MAX_NO=0

echo -n ""Enter Number between (5 to 9) : ""
read MAX_NO

if ! [ $MAX_NO -ge 5 -a $MAX_NO -le 9 ]; then
	echo ""WTF... I ask to enter number between 5 and 9, Try Again""
	exit 1
fi

clear

for ((i = 1; i <= MAX_NO; i++)); do
	for ((s = MAX_NO; s >= i; s--)); do
		echo -n "" ""
	done
	for ((j = 1; j <= i; j++)); do
		echo -n "" .""
	done
	echo """"
done
###### Second stage ######################
for ((i = MAX_NO; i >= 1; i--)); do
	for ((s = i; s <= MAX_NO; s++)); do
		echo -n "" ""
	done
	for ((j = 1; j <= i; j++)); do
		echo -n "" .""
	done
	echo """"
done

echo -e ""\n\n\t\t\t Whenever you need help, Tecmint.com is always there"""
Anti-DDOS,"#!/bin/sh

#########################################################
#                 ANTI-DDOS BASH SCRIPT                 #
######################################################### 
#                       CONTACT                         #
#########################################################
#              DEVELOPER : SMAL TADELEN              #                       
#           GMAIL : ismailtasdelen@protonmail.com       #
# Linkedin : https://www.linkedin.com/in/ismailtasdelen #
#           Telegram : https://t.me/ismailtasdelen      #
#########################################################

# For debugging use iptables -v.
IPTABLES=""/sbin/iptables""
IP6TABLES=""/sbin/ip6tables""
MODPROBE=""/sbin/modprobe""
RMMOD=""/sbin/rmmod""
ARP=""/usr/sbin/arp""
SSHPORT=""22""

# Logging options.
#------------------------------------------------------------------------------
LOG=""LOG --log-level debug --log-tcp-sequence --log-tcp-options""
LOG=""$LOG --log-ip-options""

# Defaults for rate limiting
#------------------------------------------------------------------------------
RLIMIT=""-m limit --limit 3/s --limit-burst 8""

# Unprivileged ports.
#------------------------------------------------------------------------------
PHIGH=""1024:65535""
PSSH=""1000:1023""

# Load required kernel modules
#------------------------------------------------------------------------------
""$MODPROBE"" ip_conntrack_ftp
""$MODPROBE"" ip_conntrack_irc

# Mitigate ARP spoofing/poisoning and similar attacks.
#------------------------------------------------------------------------------
# Hardcode static ARP cache entries here
# $ARP -s IP-ADDRESS MAC-ADDRESS

# Kernel configuration.
#------------------------------------------------------------------------------

# Disable IP forwarding.
# On => Off = (reset)
echo 1 > /proc/sys/net/ipv4/ip_forward
echo 0 > /proc/sys/net/ipv4/ip_forward

# Enable IP spoofing protection
for i in /proc/sys/net/ipv4/conf/*/rp_filter; do echo 1 > ""$i""; done

# Protect against SYN flood attacks
echo 1 > /proc/sys/net/ipv4/tcp_syncookies

# Ignore all incoming ICMP echo requests
echo 0 > /proc/sys/net/ipv4/icmp_echo_ignore_all

# Ignore ICMP echo requests to broadcast
echo 1 > /proc/sys/net/ipv4/icmp_echo_ignore_broadcasts

# Log packets with impossible addresses.
for i in /proc/sys/net/ipv4/conf/*/log_martians; do echo 1 > ""$i""; done

# Don't log invalid responses to broadcast
echo 1 > /proc/sys/net/ipv4/icmp_ignore_bogus_error_responses

# Don't accept or send ICMP redirects.
for i in /proc/sys/net/ipv4/conf/*/accept_redirects; do echo 0 > ""$i""; done
for i in /proc/sys/net/ipv4/conf/*/send_redirects; do echo 0 > ""$i""; done

# Don't accept source routed packets.
for i in /proc/sys/net/ipv4/conf/*/accept_source_route; do echo 0 > ""$i""; done

# Disable multicast routing
for i in /proc/sys/net/ipv4/conf/*/mc_forwarding; do echo 0 > ""$i""; done

# Disable proxy_arp.
for i in /proc/sys/net/ipv4/conf/*/proxy_arp; do echo 0 > ""$i""; done

# Enable secure redirects, i.e. only accept ICMP redirects for gateways
# Helps against MITM attacks.
for i in /proc/sys/net/ipv4/conf/*/secure_redirects; do echo 1 > ""$i""; done

# Disable bootp_relay
for i in /proc/sys/net/ipv4/conf/*/bootp_relay; do echo 0 > ""$i""; done

# Default policies.
#------------------------------------------------------------------------------

# Drop everything by default.
""$IPTABLES"" -P INPUT DROP
""$IPTABLES"" -P FORWARD DROP
""$IPTABLES"" -P OUTPUT DROP

# Set the nat/mangle/raw tables' chains to ACCEPT
""$IPTABLES"" -t nat -P PREROUTING ACCEPT
""$IPTABLES"" -t nat -P OUTPUT ACCEPT
""$IPTABLES"" -t nat -P POSTROUTING ACCEPT

""$IPTABLES"" -t mangle -P PREROUTING ACCEPT
""$IPTABLES"" -t mangle -P INPUT ACCEPT
""$IPTABLES"" -t mangle -P FORWARD ACCEPT
""$IPTABLES"" -t mangle -P OUTPUT ACCEPT
""$IPTABLES"" -t mangle -P POSTROUTING ACCEPT

# Cleanup.
#------------------------------------------------------------------------------

# Delete all
""$IPTABLES"" -F
""$IPTABLES"" -t nat -F
""$IPTABLES"" -t mangle -F

# Delete all
""$IPTABLES"" -X
""$IPTABLES"" -t nat -X
""$IPTABLES"" -t mangle -X

# Zero all packets and counters.
""$IPTABLES"" -Z
""$IPTABLES"" -t nat -Z
""$IPTABLES"" -t mangle -Z

# Completely disable IPv6.
#------------------------------------------------------------------------------

# Block all IPv6 traffic
# If the ip6tables command is available, try to block all IPv6 traffic.
if test -x ""$IP6TABLES""; then
# Set the default policies
# drop everything
""$IP6TABLES"" -P INPUT DROP 2>/dev/null
""$IP6TABLES"" -P FORWARD DROP 2>/dev/null
""$IP6TABLES"" -P OUTPUT DROP 2>/dev/null

# The mangle table can pass everything
""$IP6TABLES"" -t mangle -P PREROUTING ACCEPT 2>/dev/null
""$IP6TABLES"" -t mangle -P INPUT ACCEPT 2>/dev/null
""$IP6TABLES"" -t mangle -P FORWARD ACCEPT 2>/dev/null
""$IP6TABLES"" -t mangle -P OUTPUT ACCEPT 2>/dev/null
""$IP6TABLES"" -t mangle -P POSTROUTING ACCEPT 2>/dev/null

# Delete all rules.
""$IP6TABLES"" -F 2>/dev/null
""$IP6TABLES"" -t mangle -F 2>/dev/null

# Delete all chains.
""$IP6TABLES"" -X 2>/dev/null
""$IP6TABLES"" -t mangle -X 2>/dev/null

# Zero all packets and counters.
""$IP6TABLES"" -Z 2>/dev/null
""$IP6TABLES"" -t mangle -Z 2>/dev/null
fi

# Custom user-defined chains.
#------------------------------------------------------------------------------

# LOG packets, then ACCEPT.
""$IPTABLES"" -N ACCEPTLOG
""$IPTABLES"" -A ACCEPTLOG -j ""$LOG"" ""$RLIMIT"" --log-prefix ""ACCEPT ""
""$IPTABLES"" -A ACCEPTLOG -j ACCEPT

# LOG packets, then DROP.
""$IPTABLES"" -N DROPLOG
""$IPTABLES"" -A DROPLOG -j ""$LOG"" ""$RLIMIT"" --log-prefix ""DROP ""
""$IPTABLES"" -A DROPLOG -j DROP

# LOG packets, then REJECT.
# TCP packets are rejected with a TCP reset.
""$IPTABLES"" -N REJECTLOG
""$IPTABLES"" -A REJECTLOG -j ""$LOG"" ""$RLIMIT"" --log-prefix ""REJECT ""
""$IPTABLES"" -A REJECTLOG -p tcp -j REJECT --reject-with tcp-reset
""$IPTABLES"" -A REJECTLOG -j REJECT

# Only allows RELATED ICMP types
# (destination-unreachable, time-exceeded, and parameter-problem).
# TODO: Rate-limit this traffic?
# TODO: Allow fragmentation-needed?
# TODO: Test.
""$IPTABLES"" -N RELATED_ICMP
""$IPTABLES"" -A RELATED_ICMP -p icmp --icmp-type destination-unreachable -j ACCEPT
""$IPTABLES"" -A RELATED_ICMP -p icmp --icmp-type time-exceeded -j ACCEPT
""$IPTABLES"" -A RELATED_ICMP -p icmp --icmp-type parameter-problem -j ACCEPT
""$IPTABLES"" -A RELATED_ICMP -j DROPLOG

# Make It Even Harder To Multi-PING
""$IPTABLES""  -A INPUT -p icmp -m limit --limit 1/s --limit-burst 2 -j ACCEPT
""$IPTABLES""  -A INPUT -p icmp -m limit --limit 1/s --limit-burst 2 -j LOG --log-prefix PING-DROP:
""$IPTABLES""  -A INPUT -p icmp -j DROP
""$IPTABLES""  -A OUTPUT -p icmp -j ACCEPT

# Only allow the minimally required/recommended parts of ICMP. Block the rest.
#------------------------------------------------------------------------------

# TODO: This section needs a lot of testing!

# First, drop all fragmented ICMP packets (almost always malicious).
""$IPTABLES"" -A INPUT -p icmp --fragment -j DROPLOG
""$IPTABLES"" -A OUTPUT -p icmp --fragment -j DROPLOG
""$IPTABLES"" -A FORWARD -p icmp --fragment -j DROPLOG

# Allow all ESTABLISHED ICMP traffic.
""$IPTABLES"" -A INPUT -p icmp -m state --state ESTABLISHED -j ACCEPT ""$RLIMIT""
""$IPTABLES"" -A OUTPUT -p icmp -m state --state ESTABLISHED -j ACCEPT ""$RLIMIT""

# Allow some parts of the RELATED ICMP traffic, block the rest.
""$IPTABLES"" -A INPUT -p icmp -m state --state RELATED -j RELATED_ICMP ""$RLIMIT""
""$IPTABLES"" -A OUTPUT -p icmp -m state --state RELATED -j RELATED_ICMP ""$RLIMIT""

# Allow incoming ICMP echo requests (ping), but only rate-limited.
""$IPTABLES"" -A INPUT -p icmp --icmp-type echo-request -j ACCEPT ""$RLIMIT""

# Allow outgoing ICMP echo requests (ping), but only rate-limited.
""$IPTABLES"" -A OUTPUT -p icmp --icmp-type echo-request -j ACCEPT ""$RLIMIT""

# Drop any other ICMP traffic.
""$IPTABLES"" -A INPUT -p icmp -j DROPLOG
""$IPTABLES"" -A OUTPUT -p icmp -j DROPLOG
""$IPTABLES"" -A FORWARD -p icmp -j DROPLOG

# Selectively allow certain special types of traffic.
#------------------------------------------------------------------------------

# Allow loopback interface to do anything.
""$IPTABLES"" -A INPUT -i lo -j ACCEPT
""$IPTABLES"" -A OUTPUT -o lo -j ACCEPT

# Allow incoming connections related to existing allowed connections.
""$IPTABLES"" -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

# Allow outgoing connections EXCEPT invalid
""$IPTABLES"" -A OUTPUT -m state --state NEW,ESTABLISHED,RELATED -j ACCEPT

# Miscellaneous.
#------------------------------------------------------------------------------

# We don't care about Milkosoft, Drop SMB/CIFS/etc..
""$IPTABLES"" -A INPUT -p tcp -m multiport --dports 135,137,138,139,445,1433,1434 -j DROP
""$IPTABLES"" -A INPUT -p udp -m multiport --dports 135,137,138,139,445,1433,1434 -j DROP

# Explicitly drop invalid incoming traffic
""$IPTABLES"" -A INPUT -m state --state INVALID -j DROP

# Drop invalid outgoing traffic, too.
""$IPTABLES"" -A OUTPUT -m state --state INVALID -j DROP

# If we would use NAT, INVALID packets would pass - BLOCK them anyways
""$IPTABLES"" -A FORWARD -m state --state INVALID -j DROP

# PORT Scanners (stealth also)
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --tcp-flags ALL ALL -j DROP
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --tcp-flags ALL NONE -j DROP

# TODO: Some more anti-spoofing rules? For example:
# ""$IPTABLES"" -A INPUT -p tcp --tcp-flags ALL FIN,URG,PSH -j DROP
# ""$IPTABLES"" -A INPUT -p tcp --tcp-flags SYN,RST SYN,RST -j DROP
# ""$IPTABLES"" -A INPUT -p tcp --tcp-flags SYN,FIN SYN,FIN -j DROP
""$IPTABLES"" -N SYN_FLOOD
""$IPTABLES"" -A INPUT -p tcp --syn -j SYN_FLOOD
""$IPTABLES"" -A SYN_FLOOD -m limit --limit 2/s --limit-burst 6 -j RETURN
""$IPTABLES"" -A SYN_FLOOD -j DROP

# TODO: Block known-bad IPs (see http://www.dshield.org/top10.php).
# ""$IPTABLES"" -A INPUT -s INSERT-BAD-IP-HERE -j DROPLOG

# Drop any traffic from IANA-reserved IPs.
#------------------------------------------------------------------------------

""$IPTABLES"" -A INPUT -s 0.0.0.0/7 -j DROP
""$IPTABLES"" -A INPUT -s 2.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 5.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 7.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 10.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 23.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 27.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 31.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 36.0.0.0/7 -j DROP
""$IPTABLES"" -A INPUT -s 39.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 42.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 49.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 50.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 77.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 78.0.0.0/7 -j DROP
""$IPTABLES"" -A INPUT -s 92.0.0.0/6 -j DROP
""$IPTABLES"" -A INPUT -s 96.0.0.0/4 -j DROP
""$IPTABLES"" -A INPUT -s 112.0.0.0/5 -j DROP
""$IPTABLES"" -A INPUT -s 120.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 169.254.0.0/16 -j DROP
""$IPTABLES"" -A INPUT -s 172.16.0.0/12 -j DROP
""$IPTABLES"" -A INPUT -s 173.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 174.0.0.0/7 -j DROP
""$IPTABLES"" -A INPUT -s 176.0.0.0/5 -j DROP
""$IPTABLES"" -A INPUT -s 184.0.0.0/6 -j DROP
""$IPTABLES"" -A INPUT -s 192.0.2.0/24 -j DROP
""$IPTABLES"" -A INPUT -s 197.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 198.18.0.0/15 -j DROP
""$IPTABLES"" -A INPUT -s 223.0.0.0/8 -j DROP
""$IPTABLES"" -A INPUT -s 224.0.0.0/3 -j DROP

# Selectively allow certain outbound connections, block the rest.
#------------------------------------------------------------------------------

# Allow outgoing DNS requests. Few things will work without this.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p udp --dport 53 -j ACCEPT
""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 53 -j ACCEPT

# Allow outgoing HTTP requests. Unencrypted, use with care.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 80 -j ACCEPT

# Allow outgoing HTTPS requests.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 443 -j ACCEPT

# Allow outgoing SMTPS requests. Do NOT allow unencrypted SMTP!
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 465 -j ACCEPT

# Allow outgoing ""submission"" (RFC 2476) requests.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 587 -j ACCEPT

# Allow outgoing POP3S requests.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 995 -j ACCEPT

# Allow outgoing SSH requests.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport ""$SSHPORT"" -j ACCEPT

# Allow outgoing FTP requests. Unencrypted, use with care.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 21 -j ACCEPT

# Allow outgoing NNTP requests. Unencrypted, use with care.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 119 -j ACCEPT

# Allow outgoing NTP requests. Unencrypted, use with care.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p udp --dport 123 -j ACCEPT

# Allow outgoing IRC requests. Unencrypted, use with care.
# Note: This usually needs the ip_conntrack_irc kernel module.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 6667 -j ACCEPT

# Allow outgoing requests to various proxies. Unencrypted, use with care.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 8080 -j ACCEPT
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 8090 -j ACCEPT

# Allow outgoing DHCP requests. Unencrypted, use with care.
# TODO: This is completely untested, I have no idea whether it works!
# TODO: I think this can be tightened a bit more.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p udp --sport 67:68 --dport 67:68 -j ACCEPT

# Allow outgoing CVS requests. Unencrypted, use with care.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 2401 -j ACCEPT

# Allow outgoing MySQL requests. Unencrypted, use with care.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 3306 -j ACCEPT

# Allow outgoing SVN requests. Unencrypted, use with care.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 3690 -j ACCEPT

# Allow outgoing PLESK requests. Unencrypted, use with care.
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 8443 -j ACCEPT

# Allow outgoing Tor (http://tor.eff.org) requests.
# Note: Do _not_ use unencrypted protocols over Tor (sniffing is possible)!
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 9001 -j ACCEPT
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 9002 -j ACCEPT
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 9030 -j ACCEPT
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 9031 -j ACCEPT
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 9090 -j ACCEPT
# ""$IPTABLES"" -A OUTPUT -m state --state NEW -p tcp --dport 9091 -j ACCEPT

# Allow outgoing OpenVPN requests.
""$IPTABLES"" -A OUTPUT -m state --state NEW -p udp --dport 1194 -j ACCEPT

# TODO: ICQ, MSN, GTalk, Skype, Yahoo, etc...

# Selectively allow certain inbound connections, block the rest.
#------------------------------------------------------------------------------

# Allow incoming DNS requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p udp --dport 53 -j ACCEPT
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 53 -j ACCEPT

# Allow incoming HTTP requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 80 -j ACCEPT

# Allow incoming HTTPS requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 443 -j ACCEPT

# Allow incoming POP3 requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 110 -j ACCEPT

# Allow incoming IMAP4 requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 143 -j ACCEPT

# Allow incoming POP3S requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 995 -j ACCEPT

# Allow incoming SMTP requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 25 -j ACCEPT

# Allow incoming SSH requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport ""$SSHPORT"" -j ACCEPT

# Allow incoming FTP requests.
""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 21 -j ACCEPT

# Allow incoming NNTP requests.
# ""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 119 -j ACCEPT

# Allow incoming MySQL requests.
# ""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 3306 -j ACCEPT

# Allow incoming PLESK requests.
# ""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 8843 -j ACCEPT

# Allow incoming BitTorrent requests.
# TODO: Are these already handled by ACCEPTing established/related traffic?
# ""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 6881 -j ACCEPT
# ""$IPTABLES"" -A INPUT -m state --state NEW -p udp --dport 6881 -j ACCEPT

# Allow incoming nc requests.
# ""$IPTABLES"" -A INPUT -m state --state NEW -p tcp --dport 2030 -j ACCEPT
# ""$IPTABLES"" -A INPUT -m state --state NEW -p udp --dport 2030 -j ACCEPT

# Explicitly log and reject everything else.
#------------------------------------------------------------------------------

# Use REJECT instead of REJECTLOG if you don't need/want logging.
""$IPTABLES"" -A INPUT -j REJECTLOG
""$IPTABLES"" -A OUTPUT -j REJECTLOG
""$IPTABLES"" -A FORWARD -j REJECTLOG

#------------------------------------------------------------------------------
# Testing the firewall.
#------------------------------------------------------------------------------

# You should check/test that the firewall really works, using
# iptables -vnL, nmap, ping, telnet, ...

# Appending rules : Lets add some more IPv6 rules to our firewall.

sudo ip6tables -A INPUT -p tcp --dport ""$SSHPORT"" -s HOST_IPV6_IP -j ACCEPT
sudo ip6tables -A INPUT -p tcp --dport 80 -j ACCEPT
sudo ip6tables -A INPUT -p tcp --dport 21 -j ACCEPT
sudo ip6tables -A INPUT -p tcp --dport 25 -j ACCEPT

# To see the IPv6 rules with line numbers, type the following command:

sudo ip6tables -L -n --line-numbers

# Deleting rules

sudo ip6tables -D INPUT -p tcp --dport 21 -j ACCEPT

# Exit gracefully.
#------------------------------------------------------------------------------

exit 0"
bashcheck,"#!/bin/bash

warn() {
	if [ ""$scary"" == ""1"" ]; then
		echo -e ""\033[91mVulnerable to $1\033[39m""
	else
		echo -e ""\033[93mFound non-exploitable $1\033[39m""
	fi
}

good() {
	echo -e ""\033[92mNot vulnerable to $1\033[39m""
}

tmpdir=`mktemp -d -t tmp.XXXXXXXX`

[ -n ""$1"" ] && bash=$(which $1) || bash=$(which bash)
echo -e ""\033[95mTesting $bash ...""
$bash -c 'echo ""Bash version $BASH_VERSION""'
echo -e ""\033[39m""

#r=`a=""() { echo x;}"" $bash -c a 2>/dev/null`
if [ -n ""$(env 'a'=""() { echo x;}"" $bash -c a 2>/dev/null)"" ]; then
	echo -e ""\033[91mVariable function parser active, maybe vulnerable to unknown parser bugs\033[39m""
	scary=1
elif [ -n ""$(env 'BASH_FUNC_a%%'=""() { echo x;}"" $bash -c a 2>/dev/null)"" ]; then
	echo -e ""\033[92mVariable function parser pre/suffixed [%%, upstream], bugs not exploitable\033[39m""
	scary=0
elif [ -n ""$(env 'BASH_FUNC_a()'=""() { echo x;}"" $bash -c a 2>/dev/null)"" ]; then
	echo -e ""\033[92mVariable function parser pre/suffixed [(), redhat], bugs not exploitable\033[39m""
	scary=0
elif [ -n ""$(env '__BASH_FUNC<a>()'=""() { echo x;}"" $bash -c a 2>/dev/null)"" ]; then
	echo -e ""\033[92mVariable function parser pre/suffixed [__BASH_FUNC<..>(), apple], bugs not exploitable\033[39m""
	scary=0
else
	echo -e ""\033[92mVariable function parser inactive, bugs not exploitable\033[39m""
	scary=0
fi


r=`env x=""() { :; }; echo x"" $bash -c """" 2>/dev/null`
if [ -n ""$r"" ]; then
	warn ""CVE-2014-6271 (original shellshock)""
else
	good ""CVE-2014-6271 (original shellshock)""
fi

pushd $tmpdir > /dev/null
env x='() { function a a>\' $bash -c echo 2>/dev/null > /dev/null
if [ -e echo ]; then
	warn ""CVE-2014-7169 (taviso bug)""
else
	good ""CVE-2014-7169 (taviso bug)""
fi
popd > /dev/null

$($bash -c ""true $(printf '<<EOF %.0s' {1..80})"" 2>$tmpdir/bashcheck.tmp)
ret=$?
grep AddressSanitizer $tmpdir/bashcheck.tmp > /dev/null
if [ $? == 0 ] || [ $ret == 139 ]; then
	warn ""CVE-2014-7186 (redir_stack bug)""
else
	good ""CVE-2014-7186 (redir_stack bug)""
fi


$bash -c ""`for i in {1..200}; do echo -n ""for x$i in; do :;""; done; for i in {1..200}; do echo -n ""done;"";done`"" 2>/dev/null
if [ $? != 0 ]; then
	warn ""CVE-2014-7187 (nested loops off by one)""
else
	echo -e ""\033[96mTest for CVE-2014-7187 not reliable without address sanitizer\033[39m""
fi
$($bash -c ""f(){ x(){ _;};x(){ _;}<<a;}"" 2>/dev/null)
if [ $? != 0 ]; then
	warn ""CVE-2014-6277 (lcamtuf bug #1)""
else
	good ""CVE-2014-6277 (lcamtuf bug #1)""
fi
if [ -n ""$(env x='() { _;}>_[$($())] { echo x;}' $bash -c : 2>/dev/null)"" ]; then
	warn ""CVE-2014-6278 (lcamtuf bug #2)""
elif [ -n ""$(env BASH_FUNC_x%%='() { _;}>_[$($())] { echo x;}' $bash -c : 2>/dev/null)"" ]; then
	warn ""CVE-2014-6278 (lcamtuf bug #2)""
elif [ -n ""$(env 'BASH_FUNC_x()'='() { _;}>_[$($())] { echo x;}' $bash -c : 2>/dev/null)"" ]; then
	warn ""CVE-2014-6278 (lcamtuf bug #2)""
else
	good ""CVE-2014-6278 (lcamtuf bug #2)""
fi
rm -rf $tmpdir"
clock,"if [ $# != 1 ]; then
    echo Usage:
    echo $0 list
    echo or
    echo $0 TIMEZONE
    exit 2
fi

unameOut=$(uname -s)
case ""${unameOut}"" in
  Linux*)  machine=Linux;;
  Darwin*) machine=Mac;;
  *)       echo ""${unameOut} is not supported""; exit 1
esac

if [ $1 == ""list"" ]; then
  case ""${unameOut}"" in
    Linux*)  timedatectl list-timezones; exit 0;;
    Darwin*) sudo systemsetup -listtimezones | less; exit 0;;
  esac
fi

case ""${unameOut}"" in
  Linux*)  TZ_LIST=$(timedatectl list-timezones --no-pager);;
  Darwin*) TZ_LIST=$(sudo systemsetup -listtimezones);;
esac

if [[ $TZ_LIST == *""$1""* ]]; then
    TZ=$1 date
    exit 0
fi

echo Invalid timezone specified!
echo Please use ""$0 list"" to see what timezones are available.
exit 1"
ticktick,"#!/usr/bin/env bash

ARGV=$@
GREP=grep
EGREP=egrep

# Support {{ 
# // The following code is to make sure
# // that this runs on various platforms as suggested.
# See https://github.com/kristopolous/TickTick/issues/26
if [[ `uname` == ""SunOS"" ]]; then
  GREP=ggrep
  EGREP=gegrep
fi
# }} End support

__tick_error() {
  echo ""TICKTICK PARSING ERROR: ""$1
}

# This is from https://github.com/dominictarr/JSON.sh
# See LICENSE for more info. {{{
__tick_json_tokenize() {
  local ESCAPE='(\\[^u[:cntrl:]]|\\u[0-9a-fA-F]{4})'
  local CHAR='[^[:cntrl:]""\\]'
  local STRING=""\""$CHAR*($ESCAPE$CHAR*)*\""""
  local VARIABLE=""\\\$[A-Za-z0-9_]*""
  local NUMBER='-?(0|[1-9][0-9]*)([.][0-9]*)?([eE][+-]?[0-9]*)?'
  local KEYWORD='null|false|true'
  local SPACE='[[:space:]]+'
  $EGREP -ao ""$STRING|$VARIABLE|$NUMBER|$KEYWORD|$SPACE|."" --color=never | $EGREP -v ""^$SPACE$""  # eat whitespace
}

__tick_json_parse_array() {
  local index=0
  local ary=''

  read -r Token

  case ""$Token"" in
    ']') ;;
    *)
      while :
      do
        __tick_json_parse_value ""$1"" ""`printf ""%012d"" $index`""

        (( index++ ))
        ary+=""$Value"" 

        read -r Token
        case ""$Token"" in
          ']') break ;;
          ',') ary+=_ ;;
          *) 
            __tick_error ""Array syntax malformed""
            break ;;
        esac
        read -r Token
      done
      ;;
  esac
}

__tick_json_parse_object() {
  local key
  local obj=''
  read -r Token

  case ""$Token"" in
    '}') ;;
    *)
      while :
      do
        # The key, it should be valid
        case ""$Token"" in
          '""'*'""'|\$[A-Za-z0-9_]*) key=$Token ;;
          # If we get here then we aren't on a valid key
          *) 
            __tick_error ""Object without a Key""
            break
            ;;
        esac

        # A colon
        read -r Token

        # The value
        read -r Token
        __tick_json_parse_value ""$1"" ""$key""
        obj+=""$key:$Value""        

        read -r Token
        case ""$Token"" in
          '}') break ;;
          ',') obj+=_ ;;
        esac
        read -r Token
      done
    ;;
  esac
}

__tick_json_sanitize_value() {
  value=""""
  IFS=
  while read -r -n 1 token; do
    case ""$token"" in
      [\-\\\""\;,=\(\)\[\]{}.\':\ ]) 
        value+=`printf ""%d"" \'$token` 
        ;;
      *)
        value+=""$token""
        ;;
    esac
  done
  echo $value
}

__tick_json_parse_value() {
  local start=${1/%\""/}
  local end=${2/#\""/}

  local jpath=""${start:+${start}_}$end""
  local prej=${jpath/#\""/}
  prej=${prej/%\""/}

  prej=""`echo $prej | __tick_json_sanitize_value`""
  [[ ""$prej"" ]] && prej=""_$prej""

  case ""$Token"" in
    '{') __tick_json_parse_object ""$jpath"" ;;
    '[') __tick_json_parse_array  ""$jpath"" ;;

    *) 
      Value=$Token 
      Path=""$Prefix$prej""
      Path=${Path/#_/}
      echo __tick_data_${Path// /}=$Value 
      ;;
  esac
}

__tick_json_parse() {
  read -r Token
  __tick_json_parse_value
  read -r Token
}
# }}} End of code from github

# Since the JSON parser is just json parser, and we have a runtime
# and assignments built on to this, along with javascript like referencing
# there is a two-pass system, just because it was easier to code.
#
# This one separates out the valid JSON from the runtime library support
# and little fo' language that this is coded in.
__tick_fun_tokenize_expression() {
  CHAR='[0-9]*[A-Za-z_$][0-9]*'
  FUNCTION=""(push|pop|shift|items|delete|length)[[:space:]]*\(""
  NUMBER='[0-9]*'
  STRING=""$CHAR($CHAR)*""
  PAREN=""[()]""
  QUOTE=""[\""\'\\]""
  SPACE='[[:space:]]+'
  $EGREP -ao ""$FUNCTION|$STRING|$QUOTE|$PAREN|$NUMBER|$SPACE|."" --color=never |\
    sed ""s/^/S/g;s/$/E/g"" # Make sure spaces are respected
}

__tick_fun_parse_expression() {
  
  quoteToken=""""
  backslash=0

  while read -r token; do
    token=${token#S}
    token=${token%E}

    if [[ $done ]]; then
      suffix+=""$token""
    else
      if [[ -z $quoteToken ]]; then
        case ""$token"" in
          #
          # The ( makes sure that you can do key.push = 1, not that you would, but
          # avoiding having reserved words lowers the barrier to entry.  Try doing
          # say function debugger() {} in javascript and then run it in firefox. That's
          # a fun one.
          #
          # So, it's probably better to be as lenient as possible when dealing with
          # syntax like this.
          #
          'push('|'pop('|'shift('|'items('|'delete('|'length(') function=$token ;;
          ')') 
            function=${function/%(/}

            # For a rational of the method below see: 
            # https://github.com/kristopolous/TickTick/wiki/Function-Logic
            case $function in
              items) echo '${!__tick_data_'""$Prefix""'*}' ;;
              delete) echo 'unset __tick_data_'${Prefix/%_/} ;;
              pop) echo '""$( __tick_runtime_last ${!__tick_data_'""$Prefix""'*} )""; __tick_runtime_pop ${!__tick_data_'""$Prefix""'*}' ;;
              shift) echo '`__tick_runtime_first ${!__tick_data_'""$Prefix""'*}`; __tick_runtime_shift ${!__tick_data_'""$Prefix""'*}' ;;
              length) echo '`__tick_runtime_length ${!__tick_data_'""$Prefix""'*}`' ;;
              *) echo ""__tick_runtime_$function \""$arguments\"" __tick_data_$Prefix ""'${!__tick_data_'""$Prefix""'*}'
            esac
            unset function

            return
            ;;

          [0-9]*[A-Za-z]*[0-9]*) [[ -n ""$function"" ]] && arguments+=""$token"" || Prefix+=""$token"" ;;
          [0-9]*) Prefix+=`printf ""%012d"" $token` ;;
          '['|.) Prefix+=_ ;;

          [\""\'])
            quoteToken=$token
            ;;
            
          [\[\]]) ;;
          =) done=1 ;;
          # Only respect a space if its in the args.
          ' ') [[ -n ""$function"" ]] && arguments+=""$token"" ;;
          *) [[ -n ""$function"" ]] && arguments+=""$token"" || Prefix+=""$token"" ;;
        esac
      else
        case ""$token"" in
          \\)
            if (( backslash < 0 )); then
              backslash=2 
            fi
            # The other tokenizer preserves the backslashes, so we will too. 
            Prefix+=""$token"" 
            ;;

          $quoteToken)
            if (( backslash < 0 )); then
              quoteToken=""""
            else
              Prefix+=""$token"" 
            fi
            ;;
          *) Prefix+=$(echo ""$token"" | __tick_json_sanitize_value) ;;
        esac
        (( backslash -- ))
      fi
    fi
  done

  if [[ ""$suffix"" ]]; then
    echo ""$suffix"" | __tick_json_tokenize | __tick_json_parse
  else
    Prefix=""`echo $Prefix | __tick_json_sanitize_value`""
    echo '${__tick_data_'$Prefix'}'
  fi
}

__tick_fun_parse_tickcount_reset() {
  # If the tick count is 1 then the backtick we encountered was a 
  # shell code escape. These ticks need to be preserved for the script.
  if (( ticks == 1 )); then
    code+='`'
  fi

  # This resets the backtick counter so that `some shell code` doesn't
  # trip up the tokenizer
  ticks=0
}

# The purpose of this function is to separate out the Bash code from the
# special ""tick tick"" code.  We do this by hijacking the IFS and reading
# in a single character at a time
__tick_fun_parse() {
  IFS=

  # code oscillates between being bash or tick tick blocks.
  code=''

  # By using -n, we are given that a newline will be an empty token. We
  # can certainly test for that.
  while read -r -n 1 token; do
    case ""$token"" in
      '`') 

        # To make sure that we find two sequential backticks, we reset the counter
        # if it's not a backtick.
        if (( ++ticks == 2 )); then

          # Whether we are in the stanza or not is controlled by a different
          # variable
          if (( tickFlag == 1 )); then
            tickFlag=0
            [[ ""$code"" ]] && echo -n ""`echo $code | __tick_fun_tokenize_expression | __tick_fun_parse_expression`""
          else
            tickFlag=1
            echo -n ""$code""
          fi

          # If we have gotten this deep, then we are toggling between backtick
          # and bash. So se should unset the code.
          unset code
        fi
        ;;

      '') 
        __tick_fun_parse_tickcount_reset

        # this is a newline. If we are in ticktick, then we want to consume
        # them for the parser later on. If we are in bash, then we want to
        # preserve them.  We do this by emitting our buffer and then clearing
        # it
        if (( tickFlag == 0 )); then
          echo ""$code""
          unset code
        fi

        ;;

      *) 
        __tick_fun_parse_tickcount_reset
        
        # This is a buffer of the current code, either bash or backtick
        code+=""$token""
        ;;
    esac 
  done
}

# The code tokenization and interpretation of bash code.  This
# can be passed a path to be interpreted or, if that is not passed
# it figures out the caller and just does the same thing
#
# If two arguments are called, then the second acts as a signal to
# print the tokenized ticktick code and exit.
#
# This means in a language with declared arguments the signature
# would look like this:
#
#   __tick_fun_tokenize(path_name, set_to_return_and_not_execute) {
#
__tick_fun_tokenize() {
  [[ $# -eq ""0"" ]] && __tick_fun_tokenize ""$(caller 1 | cut -d ' ' -f 3)""
  local fname=""$1""

  # This makes sure that when we rerun the code that we are
  # interpreting, we don't try to interpret it again.
  export __tick_var_tokenized=1

  # Using bash's caller function, which is for debugging, we
  # can find out the name of the program that called us. We 
  # then cat the calling program and push it through our parser
  local code=$(cat $fname | __tick_fun_parse)

  # Before the execution we search to see if we emitted any parsing errors
  hasError=`echo ""$code"" | $GREP ""TICKTICK PARSING ERROR"" | wc -l`

  if [ ""$__tick_var_debug"" -o $# -eq 2 ]; then
    printf ""%s\n"" ""$code""
    exit 0
  fi

  # If there are no errors, then we go ahead
  if (( hasError == 0 )); then
    # Take the output and then execute it

    bash -c ""$code"" -- $ARGV
  else
    echo ""Parsing Error Detected, see below""

    # printf observes the new lines
    printf ""%s\n"" ""$code""
    echo ""Parsing stopped here.""
  fi

  exit
}

## Runtime {
if [[ $__tick_var_tokenized ]]; then 
  enable -n source
  enable -n .
  source() {
    source_temp_path=`mktemp`
    ( __tick_fun_tokenize ""$1"" ""debug"" ) > $source_temp_path

    enable source
    builtin source ""$source_temp_path""
    enable -n source

    unlink $source_temp_path
  }
  .() {
    source ""$1""
  }

  __tick_runtime_length() { echo $#; }
  __tick_runtime_first() { echo ${!1}; }
  __tick_runtime_last() { eval 'echo $'${!#}; }
  __tick_runtime_pop() { eval unset ${!#}; }

  __tick_runtime_shift() {
    local left=
    local right=

    for (( i = 1; i <= $# + 1; i++ )) ; do
      if [ ""$left"" ]; then
        eval ""$left=\$$right""
      fi
      left=$right
      right=${!i}
    done
    eval unset $left
  }
  __tick_runtime_push() {
    local value=""${1/\'/\\\'}""
    local base=$2
    local lastarg=${!#}

    let nextval=${lastarg/$base/}+1
    nextval=`printf ""%012d"" $nextval`

    eval $base$nextval=\'$value\'
  }

  tickParse() {
    eval `echo ""$1"" | __tick_json_tokenize | __tick_json_parse | tr '\n' ';'`
  }

  tickVars() {
    local tick_vars_opt='' sup_ln_number='' sup_trailing_nl='' indent=""  ""

    # Process commandline flags
    OPTIND=1
    while getopts ':hiln' tick_vars_opt; do
      case $tick_vars_opt in
        h)
        cat 1>&2 <<-""ENDHELP""
		USAGE: tickVars [-hiln]
		-h: Emit this usage information.
		-i: Suppress the indentation that usually precedes each line of output.
		-l: Suppress the line number information that usually appears at the beginning of output.
		-n: Suppress the blank line which usually prints at the end of output.
		ENDHELP
        exit 0
        ;;
        i) indent="""" ;;
        l) sup_ln_number=yes ;;
        n) sup_trailing_nl=yes ;;
      esac
    done

    [[ -z ""$sup_ln_number"" ]] && echo ""@ Line `caller | sed s/\ NULL//`:""
    set | sed -nr /^__tick_data_/s/^__tick_data_/""$indent""/p
    [[ -z ""$sup_trailing_nl"" ]] && echo
    return 0
  }

  tickReset() {
    for var in `set | sed -nr 's/^(__tick_data_[^=]+).*/\1/p'`
      do unset ""$var""
    done
  }
else 
  __tick_fun_tokenize
fi"
wait-for-it,"#!/usr/bin/env bash
# Use this script to test if a given TCP host/port are available

WAITFORIT_cmdname=${0##*/}

echoerr() { if [[ $WAITFORIT_QUIET -ne 1 ]]; then echo ""$@"" 1>&2; fi }

usage()
{
    cat << USAGE >&2
Usage:
    $WAITFORIT_cmdname host:port [-s] [-t timeout] [-- command args]
    -h HOST | --host=HOST       Host or IP under test
    -p PORT | --port=PORT       TCP port under test
                                Alternatively, you specify the host and port as host:port
    -s | --strict               Only execute subcommand if the test succeeds
    -q | --quiet                Don't output any status messages
    -t TIMEOUT | --timeout=TIMEOUT
                                Timeout in seconds, zero for no timeout
    -- COMMAND ARGS             Execute command with args after the test finishes
USAGE
    exit 1
}

wait_for()
{
    if [[ $WAITFORIT_TIMEOUT -gt 0 ]]; then
        echoerr ""$WAITFORIT_cmdname: waiting $WAITFORIT_TIMEOUT seconds for $WAITFORIT_HOST:$WAITFORIT_PORT""
    else
        echoerr ""$WAITFORIT_cmdname: waiting for $WAITFORIT_HOST:$WAITFORIT_PORT without a timeout""
    fi
    WAITFORIT_start_ts=$(date +%s)
    while :
    do
        if [[ $WAITFORIT_ISBUSY -eq 1 ]]; then
            nc -z $WAITFORIT_HOST $WAITFORIT_PORT
            WAITFORIT_result=$?
        else
            (echo -n > /dev/tcp/$WAITFORIT_HOST/$WAITFORIT_PORT) >/dev/null 2>&1
            WAITFORIT_result=$?
        fi
        if [[ $WAITFORIT_result -eq 0 ]]; then
            WAITFORIT_end_ts=$(date +%s)
            echoerr ""$WAITFORIT_cmdname: $WAITFORIT_HOST:$WAITFORIT_PORT is available after $((WAITFORIT_end_ts - WAITFORIT_start_ts)) seconds""
            break
        fi
        sleep 1
    done
    return $WAITFORIT_result
}

wait_for_wrapper()
{
    # In order to support SIGINT during timeout: http://unix.stackexchange.com/a/57692
    if [[ $WAITFORIT_QUIET -eq 1 ]]; then
        timeout $WAITFORIT_BUSYTIMEFLAG $WAITFORIT_TIMEOUT $0 --quiet --child --host=$WAITFORIT_HOST --port=$WAITFORIT_PORT --timeout=$WAITFORIT_TIMEOUT &
    else
        timeout $WAITFORIT_BUSYTIMEFLAG $WAITFORIT_TIMEOUT $0 --child --host=$WAITFORIT_HOST --port=$WAITFORIT_PORT --timeout=$WAITFORIT_TIMEOUT &
    fi
    WAITFORIT_PID=$!
    trap ""kill -INT -$WAITFORIT_PID"" INT
    wait $WAITFORIT_PID
    WAITFORIT_RESULT=$?
    if [[ $WAITFORIT_RESULT -ne 0 ]]; then
        echoerr ""$WAITFORIT_cmdname: timeout occurred after waiting $WAITFORIT_TIMEOUT seconds for $WAITFORIT_HOST:$WAITFORIT_PORT""
    fi
    return $WAITFORIT_RESULT
}

# process arguments
while [[ $# -gt 0 ]]
do
    case ""$1"" in
        *:* )
        WAITFORIT_hostport=(${1//:/ })
        WAITFORIT_HOST=${WAITFORIT_hostport[0]}
        WAITFORIT_PORT=${WAITFORIT_hostport[1]}
        shift 1
        ;;
        --child)
        WAITFORIT_CHILD=1
        shift 1
        ;;
        -q | --quiet)
        WAITFORIT_QUIET=1
        shift 1
        ;;
        -s | --strict)
        WAITFORIT_STRICT=1
        shift 1
        ;;
        -h)
        WAITFORIT_HOST=""$2""
        if [[ $WAITFORIT_HOST == """" ]]; then break; fi
        shift 2
        ;;
        --host=*)
        WAITFORIT_HOST=""${1#*=}""
        shift 1
        ;;
        -p)
        WAITFORIT_PORT=""$2""
        if [[ $WAITFORIT_PORT == """" ]]; then break; fi
        shift 2
        ;;
        --port=*)
        WAITFORIT_PORT=""${1#*=}""
        shift 1
        ;;
        -t)
        WAITFORIT_TIMEOUT=""$2""
        if [[ $WAITFORIT_TIMEOUT == """" ]]; then break; fi
        shift 2
        ;;
        --timeout=*)
        WAITFORIT_TIMEOUT=""${1#*=}""
        shift 1
        ;;
        --)
        shift
        WAITFORIT_CLI=(""$@"")
        break
        ;;
        --help)
        usage
        ;;
        *)
        echoerr ""Unknown argument: $1""
        usage
        ;;
    esac
done

if [[ ""$WAITFORIT_HOST"" == """" || ""$WAITFORIT_PORT"" == """" ]]; then
    echoerr ""Error: you need to provide a host and port to test.""
    usage
fi

WAITFORIT_TIMEOUT=${WAITFORIT_TIMEOUT:-15}
WAITFORIT_STRICT=${WAITFORIT_STRICT:-0}
WAITFORIT_CHILD=${WAITFORIT_CHILD:-0}
WAITFORIT_QUIET=${WAITFORIT_QUIET:-0}

# Check to see if timeout is from busybox?
WAITFORIT_TIMEOUT_PATH=$(type -p timeout)
WAITFORIT_TIMEOUT_PATH=$(realpath $WAITFORIT_TIMEOUT_PATH 2>/dev/null || readlink -f $WAITFORIT_TIMEOUT_PATH)

WAITFORIT_BUSYTIMEFLAG=""""
if [[ $WAITFORIT_TIMEOUT_PATH =~ ""busybox"" ]]; then
    WAITFORIT_ISBUSY=1
    # Check if busybox timeout uses -t flag
    # (recent Alpine versions don't support -t anymore)
    if timeout &>/dev/stdout | grep -q -e '-t '; then
        WAITFORIT_BUSYTIMEFLAG=""-t""
    fi
else
    WAITFORIT_ISBUSY=0
fi

if [[ $WAITFORIT_CHILD -gt 0 ]]; then
    wait_for
    WAITFORIT_RESULT=$?
    exit $WAITFORIT_RESULT
else
    if [[ $WAITFORIT_TIMEOUT -gt 0 ]]; then
        wait_for_wrapper
        WAITFORIT_RESULT=$?
    else
        wait_for
        WAITFORIT_RESULT=$?
    fi
fi

if [[ $WAITFORIT_CLI != """" ]]; then
    if [[ $WAITFORIT_RESULT -ne 0 && $WAITFORIT_STRICT -eq 1 ]]; then
        echoerr ""$WAITFORIT_cmdname: strict mode, refusing to execute subprocess""
        exit $WAITFORIT_RESULT
    fi
    exec ""${WAITFORIT_CLI[@]}""
else
    exit $WAITFORIT_RESULT
fi"
lyrics,"#!/usr/bin/env bash
# Author: Alexander Epstein https://github.com/alexanderepstein
currentVersion=""1.23.0""
configuredClient=""""
artist=""false""
song=""false""
filePath=""""

## This function determines which http get tool the system has installed and returns an error if there isnt one
getConfiguredClient()
{
  if  command -v curl &>/dev/null; then
    configuredClient=""curl""
  elif command -v wget &>/dev/null; then
    configuredClient=""wget""
  elif command -v http &>/dev/null; then
    configuredClient=""httpie""
  elif command -v fetch &>/dev/null; then
    configuredClient=""fetch""
  else
    echo ""Error: This tool requires either curl, wget, httpie or fetch to be installed."" >&2
    return 1
  fi
}

getConfiguredPython()
{
  if command -v python3 &>/dev/null; then
    configuredPython=""python3""
  elif  command -v python2 &>/dev/null; then
    configuredPython=""python2""
  elif command -v python &>/dev/null; then
    configuredPython=""python""
  else
    echo ""Error: This tool requires python to be installed.""
    return 1
  fi
}

if [[ $(uname) != ""Darwin"" ]]; then
  python()
  {
    case ""$configuredPython"" in
      python3) python3 ""$@"" ;;
      python2) python2 ""$@"" ;;
      python)  python ""$@"" ;;
    esac
  }
fi

## Grabs an element from a a json string and then echoes it to stdout
## $1 = the JSON string
## $n+1 = the elements to be indexed
AccessJsonElement() {
  json=""$1""
  shift
  accessor=""""
  for element in ""$@""; do
      accessor=""${accessor}['$element']""
  done
  echo ""$json"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)${accessor})"" 2> /dev/null
  return ""$?""
}



## Allows to call the users configured client without if statements everywhere
httpGet()
{
  case ""$configuredClient"" in
    curl)  curl -A curl -s ""$@"" ;;
    wget)  wget -qO- ""$@"" ;;
    httpie) http -b GET ""$@"" ;;
    fetch) fetch -q ""$@"" ;;
  esac
}

update()
{
  # Author: Alexander Epstein https://github.com/alexanderepstein
  # Update utility version 1.2.0
  # To test the tool enter in the defualt values that are in the examples for each variable
  repositoryName=""Bash-Snippets"" #Name of repostiory to be updated ex. Sandman-Lite
  githubUserName=""alexanderepstein"" #username that hosts the repostiory ex. alexanderepstein
  nameOfInstallFile=""install.sh"" # change this if the installer file has a different name be sure to include file extension if there is one
  latestVersion=$(httpGet https://api.github.com/repos/$githubUserName/$repositoryName/tags | grep -Eo '""name"":.*?[^\\]"",'| head -1 | grep -Eo ""[0-9.]+"" ) #always grabs the tag without the v option

  if [[ $currentVersion == """" || $repositoryName == """" || $githubUserName == """" || $nameOfInstallFile == """" ]]; then
    echo ""Error: update utility has not been configured correctly."" >&2
    exit 1
  elif [[ $latestVersion == """" ]]; then
    echo ""Error: no active internet connection"" >&2
    exit 1
  else
    if [[ ""$latestVersion"" != ""$currentVersion"" ]]; then
      echo ""Version $latestVersion available""
      echo -n ""Do you wish to update $repositoryName [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        cd ~ || { echo 'Update Failed'; exit 1; }
        if [[ -d  ~/$repositoryName ]]; then rm -r -f $repositoryName || { echo ""Permissions Error: try running the update as sudo""; exit 1; } ; fi
        git clone ""https://github.com/$githubUserName/$repositoryName"" || { echo ""Couldn't download latest version""; exit 1; }
        cd $repositoryName || { echo 'Update Failed'; exit 1; }
        git checkout ""v$latestVersion"" 2> /dev/null || git checkout ""$latestVersion"" 2> /dev/null || echo ""Couldn't git checkout to stable release, updating to latest commit.""
        chmod a+x install.sh #this might be necessary in your case but wasnt in mine.
        ./$nameOfInstallFile ""update"" || exit 1
        cd ..
        rm -r -f $repositoryName || { echo ""Permissions Error: update succesfull but cannot delete temp files located at ~/$repositoryName delete this directory with sudo""; exit 1; }
      else
        exit 1
      fi
    else
      echo ""$repositoryName is already the latest version""
    fi
  fi
}

checkInternet()
{
  httpGet github.com > /dev/null 2>&1 || { echo ""Error: no active internet connection"" >&2; return 1; } # query github with a get request
}

getLyrics()
{
  encodedArtist=$(echo ""$1"" | sed s/"" ""/%20/g | sed s/""&""/%26/g | sed s/,/%2C/g | sed s/-/%2D/g)
  encodedSong=$(echo ""$2"" | sed s/"" ""/%20/g | sed s/""&""/%26/g | sed s/,/%2C/g | sed s/-/%2D/g)
  response=$(httpGet ""https://api.lyrics.ovh/v1/$encodedArtist/$encodedSong"")
  lyrics=""$(AccessJsonElement ""$response"" ""lyrics"" 2> /dev/null)""
  if [[ $lyrics == """" ]];then { echo ""Error: no lyrics found!""; return 1; }; fi
}

printLyrics()
{
  if [[ $filePath == """" ]];then echo -e ""$lyrics""
  else
    if [ -f ""$filePath"" ];then
      echo -n ""File already exists, do you want to overwrite it [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        echo -e ""$lyrics"" > ""$filePath"";
      fi
    else
        echo -e ""$lyrics"" > ""$filePath"";
    fi
   fi
}

usage()
{
  cat <<EOF
Lyrics
Description: Fetch lyrics for a certain song.
Usage: lyrics [flags] or tool [-a] [arg] [-s] [arg]
  -a  Artist of the song to fetch lyrics for
  -s  Song of the artist to fetch lyrics for
  -f  Export the lyrics to file rather than outputting to stdout
  -u  Update Bash-Snippet Tools
  -h  Show the help
  -v  Get the tool version
Examples:
   lyrics -a logic -s run it
   lyrics -a logic -s run it -f ~/runItLyrics.txt
EOF
}


while getopts ""f:a:s:uvh"" opt; do
  case ""$opt"" in
    \?) echo ""Invalid option: -$OPTARG"" >&2
        exit 1
        ;;
    h)  usage
        exit 0
        ;;
    v)  echo ""Version $currentVersion""
        exit 0
        ;;
    u)
        getConfiguredClient || exit 1
        checkInternet || exit 1
        update
        exit 0
        ;;
    f)
       filePath=""$OPTARG""
        ;;
    a)
        artist=""true""
        if [[ ""$(echo ""$@"" | grep -Eo ""\-s"")"" == ""-s"" ]];then song=""true"";fi # wont go through both options if arg spaced and not quoted this solves that issue (dont need this but once had bug on system where it was necessary)
        if [[ ""$(echo ""$@"" | grep -Eo ""\-f"")"" == ""-f"" ]];then filePath=$(echo ""$@"" | grep -Eo ""\-f [ a-z A-Z / 0-9 . \ ]*[ -]?"" | sed s/-f//g | sed s/-//g | sed s/^"" ""//g);fi
      ;;
    s)
        song=""true""
        if [[ ""$(echo ""$@"" | grep -Eo ""\-a"")"" == ""-a"" ]];then artist=""true"";fi # wont go through both options if arg spaced and not quoted this solves that issue (dont need this but once had bug on system where it was necessary)
        if [[ ""$(echo ""$@"" | grep -Eo ""\-f"")"" == ""-f"" ]];then filePath=$(echo ""$@"" | grep -Eo ""\-f [ a-z A-Z / 0-9 . \ ]*[ -]?"" | sed s/-f//g | sed s/-//g | sed s/^"" ""//g);fi
      ;;
    :)  echo ""Option -$OPTARG requires an argument."" >&2
        exit 1
        ;;
  esac
done

# special set of first arguments that have a specific behavior across tools
if [[ $# == ""0"" ]]; then
  usage ## if calling the tool with no flags and args chances are you want to return usage
  exit 0
elif [[ $# == ""1"" ]]; then
  if [[ $1 == ""update"" ]]; then
    getConfiguredClient || exit 1
    checkInternet || exit 1
    update || exit 1
    exit 0
  elif [[ $1 == ""help"" ]]; then
    usage
    exit 0
  fi
fi

if ($artist && ! $song)  || ($song && ! $artist);then
  echo ""Error: the -a and the -s flag must be used to fetch lyrics.""
  exit 1
elif $artist && $song;then
  song=$(echo ""$@"" | grep -Eo ""\-s [ a-z A-Z 0-9 . \ ]*[ -]?"" | sed s/-s//g | sed s/-//g | sed s/^"" ""//g)
  if [[ $song == """" ]];then { echo ""Error: song could not be parsed from input.""; exit 1; };fi
  artist=$(echo ""$@"" | grep -Eo ""\-a [ a-z A-Z 0-9 . \ ]*[ -]?"" | sed s/-a//g | sed s/-//g | sed s/^"" ""//g)
  if [[ $artist == """" ]];then { echo ""Error: artist could not be parsed from input.""; exit 1; };fi
  getConfiguredClient || exit 1
  if [[ $(uname) != ""Darwin"" ]]; then getConfiguredPython || exit 1;fi
  checkInternet || exit 1
  getLyrics ""$artist"" ""$song"" || exit 1
  printLyrics
else
  { clear; echo ""You shouldnt be here but maaaaaaybeee you slipped passed me, learn to use the tool!""; sleep 5; clear;}
  usage
  exit 1
fi"
short,"#!/usr/bin/env bash
# Author: Alexander Epstein https://github.com/alexanderepstein

currentVersion=""1.23.0""
configuredClient=""""
configuredPython=""""

## This function determines which http get tool the system has installed and returns an error if there isnt one
getConfiguredClient()
{
  if  command -v curl &>/dev/null; then
    configuredClient=""curl""
  elif command -v wget &>/dev/null; then
    configuredClient=""wget""
  elif command -v http &>/dev/null; then
    configuredClient=""httpie""
  elif command -v fetch &>/dev/null; then
    configuredClient=""fetch""
  else
    echo ""Error: This tool requires either curl, wget, httpie or fetch to be installed."" >&2
    return 1
  fi
}

## Allows to call the users configured client without if statements everywhere
httpGet()
{
  case ""$configuredClient"" in
    curl)  curl -A curl -s ""$@"" ;;
    wget)  wget -qO- ""$@"" ;;
    httpie) http -b GET ""$@"" ;;
    fetch) fetch -q ""$@"" ;;
  esac
}

checkInternet()
{
  httpGet github.com > /dev/null 2>&1 || { echo ""Error: no active internet connection"" >&2; return 1; } # query github with a get request
}

update()
{
  # Author: Alexander Epstein https://github.com/alexanderepstein
  # Update utility version 2.2.0
  # To test the tool enter in the defualt values that are in the examples for each variable
  repositoryName=""Bash-Snippets"" #Name of repostiory to be updated ex. Sandman-Lite
  githubUserName=""alexanderepstein"" #username that hosts the repostiory ex. alexanderepstein
  nameOfInstallFile=""install.sh"" # change this if the installer file has a different name be sure to include file extension if there is one
  latestVersion=$(httpGet https://api.github.com/repos/$githubUserName/$repositoryName/tags | grep -Eo '""name"":.*?[^\\]"",'| head -1 | grep -Eo ""[0-9.]+"" ) #always grabs the tag without the v option

  if [[ $currentVersion == """" || $repositoryName == """" || $githubUserName == """" || $nameOfInstallFile == """" ]]; then
    echo ""Error: update utility has not been configured correctly."" >&2
    exit 1
  elif [[ $latestVersion == """" ]]; then
    echo ""Error: no active internet connection"" >&2
    exit 1
  else
    if [[ ""$latestVersion"" != ""$currentVersion"" ]]; then
      echo ""Version $latestVersion available""
      echo -n ""Do you wish to update $repositoryName [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        cd ~ || { echo 'Update Failed'; exit 1; }
        if [[ -d  ~/$repositoryName ]]; then rm -r -f $repositoryName || { echo ""Permissions Error: try running the update as sudo""; exit 1; } ; fi
        echo -n ""Downloading latest version of: $repositoryName.""
        git clone -q ""https://github.com/$githubUserName/$repositoryName"" && touch .BSnippetsHiddenFile || { echo ""Failure!""; exit 1; } &
        while [ ! -f .BSnippetsHiddenFile ]; do { echo -n "".""; sleep 2; };done
        rm -f .BSnippetsHiddenFile
        echo ""Success!""
        cd $repositoryName || { echo 'Update Failed'; exit 1; }
        git checkout ""v$latestVersion"" 2> /dev/null || git checkout ""$latestVersion"" 2> /dev/null || echo ""Couldn't git checkout to stable release, updating to latest commit.""
        chmod a+x install.sh #this might be necessary in your case but wasnt in mine.
        ./$nameOfInstallFile ""update"" || exit 1
        cd ..
        rm -r -f $repositoryName || { echo ""Permissions Error: update succesfull but cannot delete temp files located at ~/$repositoryName delete this directory with sudo""; exit 1; }
      else
        exit 1
      fi
    else
      echo ""$repositoryName is already the latest version""
    fi
  fi
}

usage()
{
  cat <<EOF
Short
Description: Shorten urls and unmask shortended urls.
Usage: short [flag] [URL] or short [flag]
  -s  Shorten the URL
  -e  Expand a shortened URL
  -u  Update Bash-Snippet Tools
  -h  Show the help
  -v  Get the tool version
Example:
   Input:  short tinyurl.com/jhkj
   Output: http://possiblemaliciouswebsiteornot.com
EOF
}

expandURL()
{
  testURL=$( echo ""$1"" | cut -c1-8 )
  if [[ $testURL != ""https://"" ]]; then
    testURL=$( echo ""$1"" | cut -c1-7 )
    if [[ $testURL != ""http://"" ]]; then
      url=""http://$1""
    else
      url=$1
    fi
  else
    url=$1
  fi
  response=$(httpGet https://unshorten.me/s/""$url"")
  errorCheck=$(echo ""$response"")
  if [[ $errorCheck == ""Invalid Short URL"" ]]; then
  echo ""Error: 404 could not find the website""
  return 1
fi
  returnedURL=$(echo ""$response"")
}

shortenURL()
{
newURL=$1
if [[ $(echo ""$1"" | grep -Eo ""^[h]ttp[s]?://"") == """" ]]; then newURL=""http://""$1; fi
response=$(httpGet http://tinyurl.com/api-create.php?url=""$newURL"")
returnedURL=$(echo ""$response"")
}

printResults()
{
  cat <<EOF
=====================================================================
Short URL:    $inputURL
Expanded URL: $returnedURL
=====================================================================
EOF
}

printShortenedResults()
{
  cat <<EOF
=====================================================================
Original URL:  $newURL
Shortened URL: $returnedURL
=====================================================================
EOF
}

getConfiguredClient || exit 1


while getopts ""e:s:uvh"" opt; do
  case ""$opt"" in
    \?) echo ""Invalid option: -$OPTARG"" >&2
        exit 1
        ;;
    e)
        expand=""true""
        inputURL=$OPTARG
        ;;
    s)
        shorten=""true""
        inputURL=$OPTARG
        ;;
    h)  usage
        exit 0
        ;;
    v)  echo ""Version $currentVersion""
        exit 0
        ;;
    u)  checkInternet || exit 1
        update
        exit 0
        ;;
    :)  echo ""Option -$OPTARG requires an argument."" >&2
        exit 1
        ;;
  esac
done

if  [[ $expand == ""true"" && $shorten == ""true"" ]];then
  echo ""Error: the -e and the -s options are mutually exclusive"" >&2
  exit 1
fi

if [[ $# == 0 ]]; then
  usage
  exit 0
elif [[ $# == ""1"" ]]; then
  if [[ $1 == ""update"" ]]; then
    checkInternet || exit 1
    update
  elif [[ $1 == ""help"" ]]; then
    usage

  else
    usage
    exit 1
  fi
elif [[ $expand == ""true"" ]];then
  checkInternet || exit 1
  expandURL ""$inputURL"" || exit 1
  printResults
elif [[ $shorten == ""true"" ]];then
  if [[ $configuredClient != ""curl"" ]];then
    echo ""Error: to shorten URLS you must have curl installed""
  fi
  checkInternet || exit 1
  shortenURL ""$inputURL""
  printShortenedResults
else
  echo ""Error: short only accepts one argument""
  exit 1
fi"
ec2-ebs-create-snapshots,"#!/usr/bin/env bash
# This script takes a snapshot of each EC2 volume that is tagged with Backup=1
# TODO: Add error handling and loop breaks

# Verify AWS CLI Credentials are setup
# http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html
if ! grep -q aws_access_key_id ~/.aws/config; then
  if ! grep -q aws_access_key_id ~/.aws/credentials; then
    echo ""AWS config not found or CLI not installed. Please run \""aws configure\"".""
    exit 1
  fi
fi

DESCRIBEVOLUMES=$(aws ec2 describe-volumes --filter Name=tag:Backup,Values=""1"")

TOTALBACKUPVOLUMES=$(echo ""$DESCRIBEVOLUMES"" | grep Name | cut -f 3 | nl | wc -l)

echo "" ""
echo ""=====================================================""
echo ""Creating EC2 Snapshots for Volumes with tag Backup=1""
echo ""Snapshots to be created:""$TOTALBACKUPVOLUMES
echo ""=====================================================""
echo "" ""

START=1
for (( COUNT=$START; COUNT<=$TOTALBACKUPVOLUMES; COUNT++ ))
do
  echo ""=====================================================""
  echo \#$COUNT

  VOLUME=$(echo ""$DESCRIBEVOLUMES"" | cut -f 9 | nl | grep -w $COUNT | cut -f 2)
  echo ""Volume ID: ""$VOLUME

  NAME=$(echo ""$DESCRIBEVOLUMES"" | grep Name | cut -f 3 | nl | grep -w [^0-9][[:space:]]$COUNT | cut -f 2)
  echo ""Volume Name: ""$NAME

  CLIENT=$(echo ""$DESCRIBEVOLUMES"" | grep Client | cut -f 3 | nl | grep -w [^0-9][[:space:]]$COUNT | cut -f 2)
  echo ""Client: ""$CLIENT

  DESCRIPTION=$NAME-$(date +%m-%d-%Y)
  echo ""Snapshot Description: ""$DESCRIPTION

  SNAPSHOTRESULT=$(aws ec2 create-snapshot --volume-id $VOLUME --description $DESCRIPTION)
  # echo ""Snapshot result is: ""$SNAPSHOTRESULT

  SNAPSHOTID=$(echo $SNAPSHOTRESULT | cut -d ' ' -f5)
  echo ""Snapshot ID: ""$SNAPSHOTID
  # echo $SNAPSHOTID | grep -E ""snap-........""
  # sleep 3

  TAGRESULT=$(aws ec2 create-tags --resources $SNAPSHOTID --tags Key=Name,Value=$NAME Key=Client,Value=$CLIENT Key=SnapshotCreation,Value=Automatic Key=SnapshotDate,Value=$(date +%m-%d-%Y))
  # echo ""Tag Result is: ""$TAGRESULT
done

echo ""=====================================================""
echo "" ""
echo ""Completed!""
echo "" """
update-blacklist,"#!/usr/bin/env bash
#
# usage update-blacklist.sh <configuration file>
# eg: update-blacklist.sh /etc/ipset-blacklist/ipset-blacklist.conf
#
function exists() { command -v ""$1"" >/dev/null 2>&1 ; }

if [[ -z ""$1"" ]]; then
  echo ""Error: please specify a configuration file, e.g. $0 /etc/ipset-blacklist/ipset-blacklist.conf""
  exit 1
fi

# shellcheck source=ipset-blacklist.conf
if ! source ""$1""; then
  echo ""Error: can't load configuration file $1""
  exit 1
fi

if ! exists curl && exists egrep && exists grep && exists ipset && exists iptables && exists sed && exists sort && exists wc ; then
  echo >&2 ""Error: searching PATH fails to find executables among: curl egrep grep ipset iptables sed sort wc""
  exit 1
fi

DO_OPTIMIZE_CIDR=no
if exists iprange && [[ ${OPTIMIZE_CIDR:-yes} != no ]]; then
  DO_OPTIMIZE_CIDR=yes
fi

if [[ ! -d $(dirname ""$IP_BLACKLIST"") || ! -d $(dirname ""$IP_BLACKLIST_RESTORE"") ]]; then
  echo >&2 ""Error: missing directory(s): $(dirname ""$IP_BLACKLIST"" ""$IP_BLACKLIST_RESTORE""|sort -u)""
  exit 1
fi

# create the ipset if needed (or abort if does not exists and FORCE=no)
if ! ipset list -n|command grep -q ""$IPSET_BLACKLIST_NAME""; then
  if [[ ${FORCE:-no} != yes ]]; then
    echo >&2 ""Error: ipset does not exist yet, add it using:""
    echo >&2 ""# ipset create $IPSET_BLACKLIST_NAME -exist hash:net family inet hashsize ${HASHSIZE:-16384} maxelem ${MAXELEM:-65536}""
    exit 1
  fi
  if ! ipset create ""$IPSET_BLACKLIST_NAME"" -exist hash:net family inet hashsize ""${HASHSIZE:-16384}"" maxelem ""${MAXELEM:-65536}""; then
    echo >&2 ""Error: while creating the initial ipset""
    exit 1
  fi
fi

# create the iptables binding if needed (or abort if does not exists and FORCE=no)
if ! iptables -nvL INPUT|command grep -q ""match-set $IPSET_BLACKLIST_NAME""; then
  # we may also have assumed that INPUT rule n1 is about packets statistics (traffic monitoring)
  if [[ ${FORCE:-no} != yes ]]; then
    echo >&2 ""Error: iptables does not have the needed ipset INPUT rule, add it using:""
    echo >&2 ""# iptables -I INPUT ${IPTABLES_IPSET_RULE_NUMBER:-1} -m set --match-set $IPSET_BLACKLIST_NAME src -j DROP""
    exit 1
  fi
  if ! iptables -I INPUT ""${IPTABLES_IPSET_RULE_NUMBER:-1}"" -m set --match-set ""$IPSET_BLACKLIST_NAME"" src -j DROP; then
    echo >&2 ""Error: while adding the --match-set ipset rule to iptables""
    exit 1
  fi
fi

IP_BLACKLIST_TMP=$(mktemp)
for i in ""${BLACKLISTS[@]}""
do
  IP_TMP=$(mktemp)
  (( HTTP_RC=$(curl -L -A ""blacklist-update/script/github"" --connect-timeout 10 --max-time 10 -o ""$IP_TMP"" -s -w ""%{http_code}"" ""$i"") ))
  if (( HTTP_RC == 200 || HTTP_RC == 302 || HTTP_RC == 0 )); then # ""0"" because file:/// returns 000
    command grep -Po '^(?:\d{1,3}\.){3}\d{1,3}(?:/\d{1,2})?' ""$IP_TMP"" | sed -r 's/^0*([0-9]+)\.0*([0-9]+)\.0*([0-9]+)\.0*([0-9]+)$/\1.\2.\3.\4/' >> ""$IP_BLACKLIST_TMP""
    [[ ${VERBOSE:-yes} == yes ]] && echo -n "".""
  elif (( HTTP_RC == 503 )); then
    echo -e ""\\nUnavailable (${HTTP_RC}): $i""
  else
    echo >&2 -e ""\\nWarning: curl returned HTTP response code $HTTP_RC for URL $i""
  fi
  rm -f ""$IP_TMP""
done

# sort -nu does not work as expected
sed -r -e '/^(0\.0\.0\.0|10\.|127\.|172\.1[6-9]\.|172\.2[0-9]\.|172\.3[0-1]\.|192\.168\.|22[4-9]\.|23[0-9]\.)/d' ""$IP_BLACKLIST_TMP""|sort -n|sort -mu >| ""$IP_BLACKLIST""
if [[ ${DO_OPTIMIZE_CIDR} == yes ]]; then
  if [[ ${VERBOSE:-no} == yes ]]; then
    echo -e ""\\nAddresses before CIDR optimization: $(wc -l ""$IP_BLACKLIST"" | cut -d' ' -f1)""
  fi
  < ""$IP_BLACKLIST"" iprange --optimize - > ""$IP_BLACKLIST_TMP"" 2>/dev/null
  if [[ ${VERBOSE:-no} == yes ]]; then
    echo ""Addresses after CIDR optimization:  $(wc -l ""$IP_BLACKLIST_TMP"" | cut -d' ' -f1)""
  fi
  cp ""$IP_BLACKLIST_TMP"" ""$IP_BLACKLIST""
fi

rm -f ""$IP_BLACKLIST_TMP""

# family = inet for IPv4 only
cat >| ""$IP_BLACKLIST_RESTORE"" <<EOF
create $IPSET_TMP_BLACKLIST_NAME -exist hash:net family inet hashsize ${HASHSIZE:-16384} maxelem ${MAXELEM:-65536}
create $IPSET_BLACKLIST_NAME -exist hash:net family inet hashsize ${HASHSIZE:-16384} maxelem ${MAXELEM:-65536}
EOF

# can be IPv4 including netmask notation
# IPv6 ? -e ""s/^([0-9a-f:./]+).*/add $IPSET_TMP_BLACKLIST_NAME \1/p"" \ IPv6
sed -rn -e '/^#|^$/d' \
  -e ""s/^([0-9./]+).*/add $IPSET_TMP_BLACKLIST_NAME \\1/p"" ""$IP_BLACKLIST"" >> ""$IP_BLACKLIST_RESTORE""

cat >> ""$IP_BLACKLIST_RESTORE"" <<EOF
swap $IPSET_BLACKLIST_NAME $IPSET_TMP_BLACKLIST_NAME
destroy $IPSET_TMP_BLACKLIST_NAME
EOF

ipset -file  ""$IP_BLACKLIST_RESTORE"" restore

if [[ ${VERBOSE:-no} == yes ]]; then
  echo
  echo ""Blacklisted addresses found: $(wc -l ""$IP_BLACKLIST"" | cut -d' ' -f1)""
fi"
cloudup,"currentVersion=""1.23.0""
configuredClient=""""
private=""0"" ## state of private flag
all=""0"" ## state of all flag
if [ -d ~/temp ]; then rm -rf ~/temp; fi ## if the temp folder exists we want to delete it just in case it was left over from a fatal error
source=""0""
tStamp=""0""


## This function determines which http get tool the system has installed and returns an error if there isnt one
getConfiguredClient()
{
  if  command -v curl &>/dev/null; then
    configuredClient=""curl""
  elif command -v wget &>/dev/null; then
    configuredClient=""wget""
  elif command -v fetch &>/dev/null; then
    configuredClient=""fetch""
  else
    echo ""Error: This tool requires either curl, wget, httpie or fetch to be installed."" >&2
    return 1
  fi
}

## Allows to call the users configured client without if statements everywhere
httpGet()
{
  case ""$configuredClient"" in
    curl)  curl -A curl -s ""$@"" ;;
    wget)  wget -qO- ""$@"" ;;
    fetch) fetch -q ""$@"" ;;
  esac
}

checkInternet()
{
  httpGet github.com > /dev/null 2>&1 || { echo ""Error: no active internet connection"" >&2; return 1; } # query github with a get request
}

update()
{
  # Author: Alexander Epstein https://github.com/alexanderepstein
  # Update utility version 2.2.0
  # To test the tool enter in the defualt values that are in the examples for each variable
  repositoryName=""Bash-Snippets"" #Name of repostiory to be updated ex. Sandman-Lite
  githubUserName=""alexanderepstein"" #username that hosts the repostiory ex. alexanderepstein
  nameOfInstallFile=""install.sh"" # change this if the installer file has a different name be sure to include file extension if there is one
  latestVersion=$(httpGethttps://api.github.com/repos/$githubUserName/$repositoryName/tagss | grep -Eo '""name"":.*?[^\\]"",'| head -1 | grep -Eo ""[0-9.]+"" ) #always grabs the tag without the v option

  if [[ $currentVersion == """" || $repositoryName == """" || $githubUserName == """" || $nameOfInstallFile == """" ]]; then
    echo ""Error: update utility has not been configured correctly."" >&2
    exit 1
  elif [[ $latestVersion == """" ]]; then
    echo ""Error: no active internet connection"" >&2
    exit 1
  else
    if [[ ""$latestVersion"" != ""$currentVersion"" ]]; then
      echo ""Version $latestVersion available""
      echo -n ""Do you wish to update $repositoryName [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        cd ~ || { echo 'Update Failed'; exit 1; }
        if [[ -d  ~/$repositoryName ]]; then rm -r -f $repositoryName || { echo ""Permissions Error: try running the update as sudo""; exit 1; } ; fi
        echo -n ""Downloading latest version of: $repositoryName.""
        git clone -q ""https://github.com/$githubUserName/$repositoryName"" && touch .BSnippetsHiddenFile || { echo ""Failure!""; exit 1; } &
        while [ ! -f .BSnippetsHiddenFile ]; do { echo -n "".""; sleep 2; };done
        rm -f .BSnippetsHiddenFile
        echo ""Success!""
        cd $repositoryName || { echo 'Update Failed'; exit 1; }
        git checkout ""v$latestVersion"" 2> /dev/null || git checkout ""$latestVersion"" 2> /dev/null || echo ""Couldn't git checkout to stable release, updating to latest commit.""
        chmod a+x install.sh #this might be necessary in your case but wasnt in mine.
        ./$nameOfInstallFile ""update"" || exit 1
        cd ..
        rm -r -f $repositoryName || { echo ""Permissions Error: update succesfull but cannot delete temp files located at ~/$repositoryName delete this directory with sudo""; exit 1; }
      else
        exit 1
      fi
    else
      echo ""$repositoryName is already the latest version""
    fi
  fi
}

## This grabs the users bitbucket info could be improved by making sure username exists
getBitbucketInfo()
{
  echo -n 'Enter your Bitbucket username: '
  read bbUsername
  if [[ $bbUsername == ""1"" ]]; then
    echo  ""Using github username as bitbucket username""
    bbUsername=$ghUsername
  fi
  echo -n 'Enter your Bitbucket password: '
  read -s password  # -s flag hides password text;
  echo
  echo
}

backupRepo()
{
  cd ~/temp/github/""$repoName"" || { echo ""Fatal error""; return 1; }
  repoSlug=$(echo ""$repoName"" | tr '[:upper:]' '[:lower:]')
  if [[ $tStamp == ""0"" ]]; then { echo -n ""Attempting to delete existing bitbucket repostiory...""; httpGet -X DELETE ""https://$bbUsername:$password@api.bitbucket.org/1.0/repositories/$bbUsername/$repoSlug"" > /dev/null || echo -n -e ""Failure!\n""; echo -n -e ""Success!\n""; }; fi ## if no timestamp then repo will not be unique we must look to delete old repo
  if [[ $private == ""1"" ]]; then
    echo -n ""Creating private repository for $repoName...""
  else
    echo -n ""Creating public repository for $repoName...""
  fi
  if [[ $tStamp == ""1"" ]]; then ## create the repository with a timestamp appended to repo name
    timestamp=$(date | tr "" "" _ | tr : _  ) ## we do this because it takes care of changes bitbucket would have made
    if [[ $private == ""1"" ]]; then # if so we will use --data is_private=true when creating repository
      httpGet --user ""$bbUsername"":""$password"" https://api.bitbucket.org/1.0/repositories/ --data name=""$repoName""""$timestamp"" --data is_private=true > /dev/null || { echo -n -e ""Failure!\n""; echo ""Error: creating the bitbucket repo failed, most likely due to an incorrect username or password.""; return 1; }
    else
      httpGet --user ""$bbUsername"":""$password"" https://api.bitbucket.org/1.0/repositories/ --data name=""$repoName""""$timestamp"" > /dev/null || { echo -n -e ""Failure!\n""; echo ""Error: creating the bitbucket repo failed, most likely due to an incorrect username or password.""; return 1; }
    fi
    echo -n -e ""Success!\n""
    echo -n ""Setting new remote url...""
    git remote set-url origin ""https://$bbUsername:$password@bitbucket.org/$bbUsername/$repoName$timestamp.git"" > /dev/null || { echo -n -e ""Failure!\n""; return 1;} ## switch the remote over to bitbucket rather than github
  else # we are creating a reoo without a timestamp appended name
    if [[ $private == ""1"" ]]; then # if so we will use --data is_private=true when creating repository
      httpGet --user ""$bbUsername"":""$password"" https://api.bitbucket.org/1.0/repositories/ --data name=""$repoName"" --data is_private=true > /dev/null || { echo -n -e ""Failure!\n""; echo ""Error: creating the bitbucket repo failed, most likely due to an incorrect username or password.""; return 1; }
    else
      httpGet --user ""$bbUsername"":""$password"" https://api.bitbucket.org/1.0/repositories/ --data name=""$repoName"" > /dev/null || { echo -n -e ""Failure!\n""; echo ""Error: creating the bitbucket repo failed, most likely due to an incorrect username or password.""; return 1; }
    fi
    echo -n -e ""Success!\n""
    echo -n ""Setting new remote url...""
    git remote set-url origin ""https://$bbUsername:$password@bitbucket.org/$bbUsername/$repoName.git"" > /dev/null || { echo -n -e ""Failure!\n""; return 1;} ## switch the remote over to bitbucket rather than github
    echo -n -e ""Success!\n""
  fi
  echo -n ""Uploading $repoName to bitbucket..""

  git push -q  origin --all > /dev/null && touch ~/temp/github/.BSnippetsHiddenFile || { echo -n -e ""Failure!\n""; touch -f ~/temp/github/.BSnippetsBrokenFile; return 1; } & ## pushes al files to github and most of the repo history
  while [[ ! -f ~/temp/github/.BSnippetsHiddenFile ]] ;do if [ -f ~/temp/github/.BSnippetsBrokenFile ];then return 1;fi && echo -n ""."" && sleep 2; done
  rm -f ~/temp/github/.BSnippetsHiddenFile
  echo -e -n ""Success!\n""
  echo -n ""Uploading the tags for $repoName..""
  git push -q origin --tags > /dev/null && touch ~/temp/github/.BSnippetsHiddenFile || { echo -n -e ""Failure!\n""; touch -f ~/temp/github/.BSnippetsBrokenFile; return 1; } & ## have to push tags here since --tags and --all are mutually exclusive
  while [[ ! -f ~/temp/github/.BSnippetsHiddenFile ]] ;do if [ -f ~/temp/github/.BSnippetsBrokenFile ];then return 1;fi && echo -n ""."" && sleep 2; done
  rm -f ~/temp/github/.BSnippetsHiddenFile
  echo -e -n ""Success!\n""
  rm -rf ~/temp #if we have succesfully backedup the repo we dion't need this anymore and if we do we will recreate it
  echo ""Successfully backed up $repoName""
}

## When cloudup is called with no flags
getGitHubRepoInfo()
{
  echo -n 'Enter the name of the repostiory to backup: '
  read repoName
}

## This grabs github user info could be improved upon by checking if user exists
getGitHubUserInfo()
{
  echo -n 'Enter your Github username: '
  read ghUsername
}

## function that handles cloning a repository it uses $ghUsername and $repoName
cloneGitHubRepo()
{
  echo -n ""Cloning $repoName..""
  validRepo=""false""
  for repo in ""${repoNames[@]}""; do
    if [[ $repo == ""$repoName"" ]];then validRepo=""true"" && break; fi
  done
  if ! $validRepo;then { echo -n -e ""Failure!\n""; echo ""Github repostiory is not valid (either incorrect username or repository)""; return 1;}; fi
  mkdir ~/temp
  cd || { echo ""Fatal error""; return 1; }
  mkdir ~/temp/github || { echo ""Fatal error""; return 1; }
  cd ~/temp/github || { echo ""Fatal error""; return 1; }
  git clone -q  https://github.com/""$ghUsername""/""$repoName"" && touch ~/temp/github/.BSnippetsHiddenFile || { touch ~/temp/github/.BSnippetsBrokenFile; echo -e -n ""Failure!\n""; return 1;} &
  while [[ ! -f ~/temp/github/.BSnippetsHiddenFile ]] ;do if [ -f ~/temp/github/.BSnippetsBrokenFile ];then return 1;fi && echo -n ""."" && sleep 2; done
  rm -f ~/temp/github/.BSnippetsHiddenFile
  echo -n -e ""Success!\n""
}

## Grabs the last 100 updated repos and greps to grab the repository names and puts them in an array called repoNames
getGithubRepoNames()
{
  for pageNumber in {1..100}; do ## iterate through 100 possible pages
    response=$(httpGet ""https://api.github.com/users/$ghUsername/repos?sort=updated&per_page=100&page=$pageNumber"") ## grab the original response
    if [[ $pageNumber == ""1"" && ( $(echo ""$response"" | grep -Eo ""Not Found"") == ""Not Found""  || $response == ""[' ']"") ]];then  { echo -e -n ""Failure!""; echo ""Github username is invalid""; return 1;};fi
    repoResponse=$(echo ""$response"" | grep -Eo '""full_name"": ""[ a-Z .  \/ \\ 0-9 -- _ ]*' | sed  s/'""full_name"": ""'/""""/g | sed s:""$ghUsername""/:: ) ## extract the repo names from the response
    forkResponse=($(echo ""$response"" | grep -Eo '""fork"": [a-Z]*' | cut -d "" "" -f 2 | sed  s/""'""//g  )) ## extract the fork status of each repo
    count=0  ## used to iterate through the fork statuses
    if [[ $repoResponse == """" ]]; then break; fi ## will only break if the page is empty
    for repo in $repoResponse; do ## go through each repo
      if [[ $source == ""1"" ]]; then ## if the user set the source flag
        if [[ ${forkResponse[$count]} == ""false"" ]]; then repoNames+=(""$repo""); fi ## if they are the owner of the repository add it to the list of repoNames
        count=$(( $count + 1 )) ## increment the counter
      else ## the user didnt set the source flag
        repoNames+=(""$repo"") ## add all repos in repoResponse to repoNames
      fi
    done
  done
}

usage()
{
  cat <<EOF
Cloudup
Description: Backs up a users github repositories to your bitbucket account.
  With no flags cloudup will guide you through backing up a single repository
Usage: cloudup [flags] or cloudup [flags] [listOfGHRepoNamesSplitBySpaces]
  -p  Upload the repositor(y)(ies) as private to bitbucket (must have private
      repo ability on bitbucket)
  -a  Backup all github repositories
  -s  Only backup repositories that you have created (no forks) (only works in
      conjunction with the -a flag)
  -t  Backup the repository with a timestamp added to the repostiory name (will
      always create a new unique bitbucket repo)
  -u  Update Bash-Snippet Tools
  -h  Show the help
  -v  Get the tool version
Examples:
  cloudup
  cloudup -p -a
  cloudup -a -s
  cloudup -t
  cloudup -a -s -t -p
  cloudup -p nameOfRepo1 nameOfRepo2
  cloudup nameOfRepo
  cloudup -a
EOF
}

getConfiguredClient || exit 1


while getopts ""tspauvh"" opt; do
  case ""$opt"" in
    \?) echo ""Invalid option: -$OPTARG"" >&2
        exit 1
        ;;
    s)  source=""1""  ;;
    p)  private=""1"" ;;
    t)  tStamp=""1""  ;;
    h)  usage
        exit 0
        ;;
    a)  all=""1"" ;;
    v)  echo ""Version $currentVersion""
        exit 0
        ;;
    u)  checkInternet || exit 1
        update
        exit 0
        ;;
    :)  echo ""Option -$OPTARG requires an argument."" >&2
        exit 1
        ;;
  esac
done

if [[ $source == ""1"" && $all == ""0"" ]]; then { echo ""Error: the -s flag only works in conjunction with the -a flag.""; exit 1; }; fi ## check if the source flag was used correctly (no need to have source flag when specifying the repositories)
if [[ $configuredClient != ""curl"" ]]; then { echo ""Error: to use cloudup without the -t option curl must be installed""; exit 1; }; fi ## we have to have the ability to delete an unique repo which is possible with curl -X DELETE
if [[ $# == ""1"" ]]; then # check for keywords
  if [[ $1 == ""update"" ]]; then
    checkInternet || exit 1
    update
    exit 0
  elif [[ $1 == ""help"" ]]; then
    usage
    exit 0
  fi
fi

checkInternet || exit 1
if [[ $all == ""0"" ]]; then
  if [[ ($private == ""0"" && $tStamp == ""0"" && $1 != """")]]; then ## checking for an arguments after possible flags if so then run through the arguments (repositories) and back them up
    getGitHubUserInfo || exit 1
    getGithubRepoNames || exit 1
    getBitbucketInfo || exit 1
    for i in ""$@""; do ## if private is not on as a flag start rpping through them
      repoName=$i
      echo ""Starting to backup $repoName""
      cloneGitHubRepo || exit 1
      backupRepo || { echo ""Error: couldnt backup $repoName to bitbucket""; exit 1; }
      echo
    done
    exit 0
  elif [[ ( $private == ""0"" && $tStamp == ""0"" &&  $1 == """" ) || ( $private == ""1"" && $tStamp == ""0"" && $2 == """" ) || ( $private == ""0"" && $tStamp == ""1"" && $2 == """" ) || ( $private == ""1"" && $tStamp == ""1"" && $3 == """" )  ]]; then ## check for empty arguments after all possible flags, this will intiate a guided backup
    getGitHubUserInfo || exit 1
    getGithubRepoNames || exit 1
    getGitHubRepoInfo || exit 1
    getBitbucketInfo || exit 1
    echo
    cloneGitHubRepo || exit 1
    backupRepo || { echo ""Error: couldnt backup $repoName to bitbucket""; exit 1; }
    exit 0
  else ## flags are set but arguments are also provided
    firstArg=$(( $private + $tStamp + 1 ))
    getGitHubUserInfo || exit 1
    getGithubRepoNames || exit 1
    getBitbucketInfo || exit 1
    for i in ""${@:$firstArg}""; do
      repoName=$i
      echo ""Starting to backup $repoName""
      cloneGitHubRepo || exit 1
      backupRepo || { echo ""Error: couldnt backup $repoName to bitbucket""; exit 1; }
      echo
    done
    exit 0
  fi
else
  getGitHubUserInfo || exit 1
  getGithubRepoNames || exit 1
  getBitbucketInfo || exit 1
  echo
  for repo in ""${repoNames[@]}""; do
    repoName=$repo
    echo ""Starting to backup $repoName""
    cloneGitHubRepo || exit 1
    backupRepo  || { echo ""Error: couldnt backup $repoName to bitbucket""; exit 1; }
    echo
  done
  echo ""Successfully backed up all repositories""
  exit 0
fi"
movies,"currentVersion=""1.23.0""
configuredClient=""""
configuredPython=""""
detail=false

## This function determines which http get tool the system has installed and returns an error if there isnt one
getConfiguredClient()
{
  if  command -v curl &>/dev/null; then
    configuredClient=""curl""
  elif command -v wget &>/dev/null; then
    configuredClient=""wget""
  elif command -v http &>/dev/null; then
    configuredClient=""httpie""
  elif command -v fetch &>/dev/null; then
    configuredClient=""fetch""
  else
    echo ""Error: This tool requires either curl, wget, httpie or fetch to be installed."" >&2
    return 1
  fi
}

## Allows to call the users configured client without if statements everywhere
httpGet()
{
  case ""$configuredClient"" in
    curl)  curl -A curl -s ""$@"" ;;
    wget)  wget -qO- ""$@"" ;;
    httpie) http -b GET ""$@"" ;;
    fetch) fetch -q ""$@"" ;;
  esac
}

getConfiguredPython()
{
  if command -v python3 &>/dev/null; then
    configuredPython=""python3""
  elif  command -v python2 &>/dev/null; then
    configuredPython=""python2""
  elif command -v python &>/dev/null; then
    configuredPython=""python""
  else
    echo ""Error: This tool requires python to be installed.""
    return 1
  fi
}

if [[ $(uname) != ""Darwin"" ]]; then
  python()
  {
    case ""$configuredPython"" in
      python3) python3 ""$@"" ;;
      python2) python2 ""$@"" ;;
      python)  python ""$@"" ;;
    esac
  }
fi

## Grabs an element from a a json string and then echoes it to stdout
## $1 = the JSON string
## $n+1 = the elements to be indexed
AccessJsonElement() {
  json=""$1""
  shift
  accessor=""""
  for element in ""$@""; do
      accessor=""${accessor}['$element']""
  done
  echo ""$json"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)${accessor})"" 2> /dev/null
  return ""$?""
}

checkInternet()
{
  httpGet github.com > /dev/null 2>&1 || { echo ""Error: no active internet connection"" >&2; return 1; } # query github with a get request
}

## This function grabs information about a movie and using python parses the
## JSON response to extrapolate the information for storage
getMovieInfo()
{
  apiKey=946f500a # try not to abuse this it is a key that came from the ruby-scripts repo I link to.
  movie=$( (echo ""$@"" | tr "" "" + ) | sed 's/-d+//g' ) ## format the inputs to use for the api. Added sed command to filter -d flag.
  export PYTHONIOENCODING=utf8 #necessary for python in some cases
  movieInfo=$(httpGet ""http://www.omdbapi.com/?t=$movie&apikey=$apiKey"") > /dev/null # query the server and get the JSON response
  checkResponse=$(echo ""$movieInfo"" | python -c ""import sys, json; print json.load(sys.stdin)['Response']"" 2> /dev/null)
  if [[ $checkResponse == ""False"" ]]; then { echo ""No movie found"" ; return 1 ;} fi ## check to see if the movie was found
  # The rest of the code is just extrapolating the data with python from the JSON response
  title=""$(AccessJsonElement ""$movieInfo"" ""Title"")""
  year=""$(AccessJsonElement ""$movieInfo"" ""Year"")""
  runtime=""$(AccessJsonElement ""$movieInfo"" ""Runtime"")""
  imdbScore=$(echo ""$movieInfo"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Ratings'][0]['Value'])"" 2> /dev/null)
  tomatoScore=$(echo ""$movieInfo"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Ratings'][1]['Value'])"" 2> /dev/null)
  rated=""$(AccessJsonElement ""$movieInfo"" ""Rated"")""
  genre=""$(AccessJsonElement ""$movieInfo"" ""Genre"")""
  director=""$(AccessJsonElement ""$movieInfo"" ""Director"")""
  actors=""$(AccessJsonElement ""$movieInfo"" ""Actors"")""
  plot=""$(AccessJsonElement ""$movieInfo"" ""Plot"")""
  
  if $detail; then
    awards=""$(AccessJsonElement ""$movieInfo"" ""Awards"")""
    boxOffice=""$(AccessJsonElement ""$movieInfo"" ""BoxOffice"")""
    metacriticScore=$(echo ""$movieInfo"" | python -c ""from __future__ import print_function; import sys, json; print(json.load(sys.stdin)['Ratings'][2]['Value'])"" 2> /dev/null)
    production=""$(AccessJsonElement ""$movieInfo"" ""Production"")""
  fi
}

# Prints the movie information out in a human readable format
printMovieInfo()
{
  echo
  echo '=================================================='
  echo ""| Title: $title""
  echo ""| Year: $year""
  echo ""| Runtime: $runtime""
  if [[ $imdbScore != """" ]]; then echo ""| IMDB: $imdbScore""; fi
  if [[ $tomatoScore != """" ]]; then echo ""| Tomato: $tomatoScore""; fi
  if $detail; then
    if [[ $metacriticScore != """" ]]; then echo ""| Metascore: $metacriticScore""; fi
  fi
  if [[ $rated != ""N/A"" && $rated != """" ]]; then echo ""| Rated: $rated""; fi
  echo ""| Genre: $genre""
  echo ""| Director: $director""
  echo ""| Actors: $actors""
  if [[ $plot != ""N/A"" && $plot != """" ]]; then echo ""| Plot: $plot""; fi
  if $detail; then
    if [[ $boxOffice != """" ]]; then echo ""| Box Office: $boxOffice""; fi
    if [[ $production != """" ]]; then echo ""| Production: $production""; fi
    if [[ $awards != """" ]]; then echo ""| Awards: $awards""; fi
  fi
  echo '=================================================='
  echo
}

update()
{
  # Author: Alexander Epstein https://github.com/alexanderepstein
  # Update utility version 2.2.0
  # To test the tool enter in the defualt values that are in the examples for each variable
  repositoryName=""Bash-Snippets"" #Name of repostiory to be updated ex. Sandman-Lite
  githubUserName=""alexanderepstein"" #username that hosts the repostiory ex. alexanderepstein
  nameOfInstallFile=""install.sh"" # change this if the installer file has a different name be sure to include file extension if there is one
  latestVersion=$(httpGet https://api.github.com/repos/$githubUserName/$repositoryName/tags | grep -Eo '""name"":.*?[^\\]"",'| head -1 | grep -Eo ""[0-9.]+"" ) #always grabs the tag without the v option

  if [[ $currentVersion == """" || $repositoryName == """" || $githubUserName == """" || $nameOfInstallFile == """" ]]; then
    echo ""Error: update utility has not been configured correctly."" >&2
    exit 1
  elif [[ $latestVersion == """" ]]; then
    echo ""Error: no active internet connection"" >&2
    exit 1
  else
    if [[ ""$latestVersion"" != ""$currentVersion"" ]]; then
      echo ""Version $latestVersion available""
      echo -n ""Do you wish to update $repositoryName [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        cd ~ || { echo 'Update Failed'; exit 1; }
        if [[ -d  ~/$repositoryName ]]; then rm -r -f $repositoryName || { echo ""Permissions Error: try running the update as sudo""; exit 1; } ; fi
        echo -n ""Downloading latest version of: $repositoryName.""
        git clone -q ""https://github.com/$githubUserName/$repositoryName"" && touch .BSnippetsHiddenFile || { echo ""Failure!""; exit 1; } &
        while [ ! -f .BSnippetsHiddenFile ]; do { echo -n "".""; sleep 2; };done
        rm -f .BSnippetsHiddenFile
        echo ""Success!""
        cd $repositoryName || { echo 'Update Failed'; exit 1; }
        git checkout ""v$latestVersion"" 2> /dev/null || git checkout ""$latestVersion"" 2> /dev/null || echo ""Couldn't git checkout to stable release, updating to latest commit.""
        chmod a+x install.sh #this might be necessary in your case but wasnt in mine.
        ./$nameOfInstallFile ""update"" || exit 1
        cd ..
        rm -r -f $repositoryName || { echo ""Permissions Error: update succesfull but cannot delete temp files located at ~/$repositoryName delete this directory with sudo""; exit 1; }
      else
        exit 1
      fi
    else
      echo ""$repositoryName is already the latest version""
    fi
  fi
}

usage()
{
  cat <<EOF
Movies
Description: Provides relevant information about a certain movie.
Usage: movies [flag] or movies [movieToSearch]
  -u  Update Bash-Snippet Tools
  -h  Show the help
  -v  Get the tool version
  -d  Show detailed information
Examples:
  movies Argo
  movies Inception
EOF
}

if [[ $(uname) != ""Darwin"" ]]; then getConfiguredPython || exit 1; fi
getConfiguredClient || exit 1


while getopts 'ud:hv' flag; do
  case ""${flag}"" in
    u) checkInternet || exit 1 # check if we have a valid internet connection if this isnt true the rest of the script will not work so stop here
      update
       exit 0 ;;
    d) detail=true ;;
    h) usage
       exit 0 ;;
    v) echo ""Version $currentVersion""
       exit 0 ;;
    :) echo ""Option -$OPTARG requires an argument."" >&2
       exit 1 ;;
    *) exit 1 ;;
  esac
done

if [[ $# == 0 ]]; then
  usage
elif [[ $1 == ""update"" ]]; then
  checkInternet || exit 1 # check if we have a valid internet connection if this isnt true the rest of the script will not work so stop here
  update
elif [[ $1 == ""help"" ]]; then
  usage
else
  checkInternet || exit 1 # check if we have a valid internet connection if this isnt true the rest of the script will not work so stop here
  getMovieInfo ""$@"" || exit 1 ## exit if we return 1 (chances are movie was not found)
  printMovieInfo ## print out the data
fi"
newton,"declare -a simpleOperations=(simplify factor derive integrate zeroes roots tangent area cos sin tan arccos arcsin arctan abs log)

## This function determines which http get tool the system has installed and returns an error if there isnt one
getConfiguredClient()
{
  if  command -v curl &>/dev/null; then
    configuredClient=""curl""
  elif command -v wget &>/dev/null; then
    configuredClient=""wget""
  elif command -v http &>/dev/null; then
    configuredClient=""httpie""
  elif command -v fetch &>/dev/null; then
    configuredClient=""fetch""
  else
    echo ""Error: This tool requires either curl, wget, httpie or fetch to be installed."" >&2
    return 1
  fi
}

## Allows to call the users configured client without if statements everywhere
httpGet()
{
  case ""$configuredClient"" in
    curl)  curl -A curl -s ""$@"" ;;
    wget)  wget -qO- ""$@"" ;;
    httpie) http -b GET ""$@"" ;;
    fetch) fetch -q ""$@"" ;;
  esac
}


checkInternet()
{
  httpGet github.com > /dev/null 2>&1 || { echo ""Error: no active internet connection"" >&2; return 1; } # query github with a get request
}


update()
{
  # Author: Alexander Epstein https://github.com/alexanderepstein
  # Update utility version 2.2.0
  # To test the tool enter in the defualt values that are in the examples for each variable
  repositoryName=""Bash-Snippets"" #Name of repostiory to be updated ex. Sandman-Lite
  githubUserName=""alexanderepstein"" #username that hosts the repostiory ex. alexanderepstein
  nameOfInstallFile=""install.sh"" # change this if the installer file has a different name be sure to include file extension if there is one
  latestVersion=$(httpGet https://api.github.com/repos/$githubUserName/$repositoryName/tags | grep -Eo '""name"":.*?[^\\]"",'| head -1 | grep -Eo ""[0-9.]+"" ) #always grabs the tag without the v option

  if [[ $currentVersion == """" || $repositoryName == """" || $githubUserName == """" || $nameOfInstallFile == """" ]]; then
    echo ""Error: update utility has not been configured correctly."" >&2
    exit 1
  elif [[ $latestVersion == """" ]]; then
    echo ""Error: no active internet connection"" >&2
    exit 1
  else
    if [[ ""$latestVersion"" != ""$currentVersion"" ]]; then
      echo ""Version $latestVersion available""
      echo -n ""Do you wish to update $repositoryName [Y/n]: ""
      read -r answer
      if [[ ""$answer"" == [Yy] ]]; then
        cd ~ || { echo 'Update Failed'; exit 1; }
        if [[ -d  ~/$repositoryName ]]; then rm -r -f $repositoryName || { echo ""Permissions Error: try running the update as sudo""; exit 1; } ; fi
        echo -n ""Downloading latest version of: $repositoryName.""
        git clone -q ""https://github.com/$githubUserName/$repositoryName"" && touch .BSnippetsHiddenFile || { echo ""Failure!""; exit 1; } &
        while [ ! -f .BSnippetsHiddenFile ]; do { echo -n "".""; sleep 2; };done
        rm -f .BSnippetsHiddenFile
        echo ""Success!""
        cd $repositoryName || { echo 'Update Failed'; exit 1; }
        git checkout ""v$latestVersion"" 2> /dev/null || git checkout ""$latestVersion"" 2> /dev/null || echo ""Couldn't git checkout to stable release, updating to latest commit.""
        chmod a+x install.sh #this might be necessary in your case but wasnt in mine.
        ./$nameOfInstallFile ""update"" || exit 1
        cd ..
        rm -r -f $repositoryName || { echo ""Permissions Error: update succesfull but cannot delete temp files located at ~/$repositoryName delete this directory with sudo""; exit 1; }
      else
        exit 1
      fi
    else
      echo ""$repositoryName is already the latest version""
    fi
  fi
}

validateExpression()
{
  local parsedExpression # only used here
  originalEquation=$(echo ""$1"" | sed ""s/\[/\(/g"" | sed ""s/\]/\)/g"") # accont for the fact that we have to use brackets and not parenthesis
  parsedExpression=$(echo ""$1"" | sed ""s/\[/\(/g"" | sed ""s/\]/\)/g"" | grep -Eo ""[0-9 + -- / * ^ . a-z A-Z ~ : ( ) ]*"") # only grepping valid characters
  if [ ""$parsedExpression"" != ""$originalEquation"" ];then { echo ""Error: Expression contains invalid characters""; return 1; }; fi # compare result to original
  return 0
}

encodeEquation()
{
  equation=$(echo ""$originalEquation"" | sed ""s:/:(over):g"" | sed ""s/~/|/g"" | sed ""s/-/%2D/g"") # encode all the special characters
}

validateOperation()
{
  operation=$(echo ""$1"" | tr ""[[:upper:]]"" ""[[:lower:]]"") # get rid of case being an issue
  validOp=""false"" # lets us know if oeration is valid
  for op in ""${simpleOperations[@]}""; do # go through all valid simple operations
    if [[ ""$op"" == ""$operation"" ]]; then { opType=""simple""; validOp=""true""; break; }; fi # if the operation matches leave the loop
  done
  if ! $validOp; then { echo ""Error: invalid operation, run newton -h to get a list of valid operations""; return 1; }; fi # if not a valid operation error out
  if [[ $operation == ""roots"" ]]; then operation=zeroes;fi # I gave the ability to use root or zeores but real op is zeroes
}

getSimpleResponse()
{
  result=$(httpGet https://newton.now.sh/api/v2/$operation/""$equation"" | grep -Eo '""result"":""[a-z A-Z 0-9 ( ) \^ / -- + , ]*' | sed s/'""result"":""'//g | tr '""' "" "") # get reponse, grab result
  if [[ $result == """" ]];then { echo ""Error: no result was returned, did you use valid characters?""; return 1; }; fi # if result is empty sometthing went wrong...
}

printAnswer()
{
  cat <<EOF
================================
|Operation: $operation
|Expression: $originalEquation
|Result: $result
================================
EOF
}


usage()
{
  cat <<EOF
Newton
Description: Performs numerical calculations all the way up to symbolic math parsing.
Usage: newton [optionalFlags] [operation] [expression] or newton [flag]
  -r  Only print the result, useful for piping output elsewhere
  -u  Update Bash-Snippet Tools
  -h  Show the help
  -v  Get the tool version
 ===================================================
|Operations     Sample Expression      Sample Result|
|---------------------------------------------------|
|Simplify       [[2x^2]+7]*[4x^2]    8 x^4 + 28 x^2 |
|Factor             x^2 + 2x             x (x + 2)  |
|Derive              x^2+2x               2 x + 2   |
|Integrate           x^2+2x         1/3 x^3 + x^2 +C|
|Roots/Zeroes        x^2+2x                2, 0     |
|Tangent             2~x^3              12 x + -16  | (Finding tangent line when x=2 for expression x^3)
|Area               2:4~x^3                 60      | (Finding area under curve from 2 to 4 for expression x^3)
|Cos                   pi                   -1      |
|Sin                   pi                    0      |
|Tan                  pi/4                   1      |
|ArcCos                 1                    0      |
|ArcSin                 0                    0      |
|ArcTan                pi                arcsin(pi) |
|Abs                   -2                    2      |
|Log                   2~8                   3      | (Log base 2 of eight)
 ===================================================
Valid Symbols:
  + add
  - subtract
  [ left parenthesis (you must use brackets bash has a bultin for parenthesis)
  ] right parenthesis (you must use brackets bash has a bultin for parenthesis)
  * multiply
  / divide
  ^ power
  : between the range of left and right side (only for area under curve)
  ~ parameter on right side (only for area, tangent line and log)
EOF
}


getConfiguredClient || exit 1

while getopts ""ur:vh"" opt; do
  case ""$opt"" in
    \?) echo ""Invalid option: -$OPTARG"" >&2
        exit 1
        ;;
    h)  usage
        exit 0
        ;;
    v)  echo ""Version $currentVersion""
        exit 0
        ;;
    u)  update
        exit 0
        ;;
    r)  resultOnly=""true"" && flagCount=$((flagCount + 1 ));;
    :)  echo ""Option -$OPTARG requires an argument."" >&2
        exit 1
        ;;
  esac
done

if [[ $# == ""0"" ]]; then usage && exit 0
elif [[ $# == ""1"" ]]; then
  if [[ $1 == ""update"" ]]; then checkInternet && update && exit 0 || exit 1
  elif [[ $1 == ""help"" ]]; then usage && exit 0 || exit 1
  else echo ""Error: newton needs two arguments, operation and expression"" && exit 1;fi
elif [ $# -gt 3 ];then echo ""Error: newton only accepts two arguments, operation and expression"" && exit 1;fi

# flagCount helps us determine what argument to pass to the functions
# flow: validateOperation, validateExpression, encodeEquation, getResponse, print Answer/Result
checkInternet || exit 1
if [[ $flagCount == ""0"" ]];then validateOperation ""$1"" || exit 1
elif [[ $flagCount == ""1"" ]];then validateOperation ""$2"" || exit 1; fi
if [[ $flagCount == ""0"" ]];then validateExpression ""$2"" || exit 1
elif [[ $flagCount == ""1"" ]];then validateExpression ""$3"" || exit 1; fi
encodeEquation || exit 1
if [[ $opType == ""simple"" ]];then getSimpleResponse || exit 1;fi
if [ -z $resultOnly ];then printAnswer
else echo ""$result""; fi"
parseOpts,"readonly _opts_ec=$'\033' # escape char
readonly _opts_eend=$'\033[0m' # escape end

_opts_SED_CMD=sed
if command -v gsed &> /dev/null; then
    _opts_SED_CMD=gsed
fi

_opts_colorEcho() {
    local color=$1
    shift
    # if stdout is console, turn on color output.
    [ -t 1 ] && echo ""$_opts_ec[1;${color}m$@$_opts_eend"" || echo ""$@""
}

_opts_redEcho() {
    _opts_colorEcho 31 ""$@""
}

_opts_convertToVarName() {
    [ $# -ne 1 ] && {
        _opts_redEcho ""NOT 1 arguemnts when call _opts_convertToVarName: $@""
        return 1
    }
    echo ""$1"" | $_opts_SED_CMD 's/-/_/g'
}

#####################################################################
# Parse Functions
#
# Use Globle Variable: 
# * _OPT_INFO_LIST_INDEX : Option info, data structure.
#                          _OPT_INFO_LIST_INDEX ->* _a_a_long -> option value.
# * _OPT_VALUE_* : value of option. is Array type for + mode option
# * _OPT_ARGS : option arguments
#####################################################################

_opts_findOptMode() {
    [ $# -ne 1 ] && {
        _opts_redEcho ""NOT 1 arguemnts when call _opts_findOptMode: $@""
        return 1
    }

    local opt=""$1"" # like a, a-long
    local idxName
    for idxName in ""${_OPT_INFO_LIST_INDEX[@]}"" ; do
        local idxNameArrayPlaceHolder=""$idxName[@]""
        local -a idxNameArray=(""${!idxNameArrayPlaceHolder}"")

        local mode=""${idxNameArray[0]}""

        local optName
        for optName in ""${idxNameArray[@]:1:${#idxNameArray[@]}}""; do # index from 1, skip mode
            [ ""$opt"" == ""${optName}"" ] && {
                echo ""$mode""
                return
            }
        done
    done

    echo """"
}

_opts_setOptBool() {
    [ $# -ne 2 ] && {
        _opts_redEcho ""NOT 2 arguemnts when call _opts_setOptBool: $@""
        return 1
    }

    _opts_setOptValue ""$@""
}

_opts_setOptValue() {
    [ $# -ne 2 ] && {
        _opts_redEcho ""NOT 2 arguemnts when call _opts_setOptValue: $@""
        return 1
    }

    local opt=""$1"" # like a, a-long
    local value=""$2""

    local idxName
    for idxName in ""${_OPT_INFO_LIST_INDEX[@]}"" ; do
        local idxNameArrayPlaceHolder=""$idxName[@]""
        local -a idxNameArray=(""${!idxNameArrayPlaceHolder}"")

        local optName
        for optName in ""${idxNameArray[@]:1:${#idxNameArray[@]}}""; do # index from 1, skip mode
            [ ""$opt"" == ""$optName"" ] && {
                local optName2
                for optName2 in ""${idxNameArray[@]:1:${#idxNameArray[@]}}""; do
                    local optValueVarName=""_OPT_VALUE_`_opts_convertToVarName ""${optName2}""`""
                    local from='""$value""'
                    eval ""$optValueVarName=$from"" # set global var!
                done
                return
            }
        done
    done

    _opts_redEcho ""NOT Found option $opt!""
    return 1
}

_opts_setOptArray() {
    local opt=""$1"" # like a, a-long
    shift

    local idxName
    for idxName in ""${_OPT_INFO_LIST_INDEX[@]}"" ; do
        local idxNameArrayPlaceHolder=""$idxName[@]""
        local -a idxNameArray=(""${!idxNameArrayPlaceHolder}"")
        
        local optName
        for optName in ""${idxNameArray[@]:1:${#idxNameArray[@]}}""; do # index from 1, skip mode
            [ ""$opt"" == ""$optName"" ] && {
                # set _OPT_VALUE
                local optName2
                for optName2 in ""${idxNameArray[@]:1:${#idxNameArray[@]}}""; do
                    local optValueVarName=""_OPT_VALUE_`_opts_convertToVarName ""${optName2}""`""
                    local from='""$@""'
                    eval ""$optValueVarName=($from)"" # set global var!
                done
                return
            }
        done
    done

    _opts_redEcho ""NOT Found option $opt!""
    return 1
}

_opts_cleanOptValueInfoList() {
    local idxName
    for idxName in ""${_OPT_INFO_LIST_INDEX[@]}""; do
        local idxNameArrayPlaceHolder=""$idxName[@]""
        local -a idxNameArray=(""${!idxNameArrayPlaceHolder}"")

        eval ""unset $idxName""

        local optName
        for optName in ""${idxNameArray[@]:1:${#idxNameArray[@]}}""; do # index from 1, skip mode
            local optValueVarName=""_OPT_VALUE_`_opts_convertToVarName ""$optName""`""
            eval ""unset $optValueVarName""
        done
    done

    unset _OPT_INFO_LIST_INDEX
    unset _OPT_ARGS
}

parseOpts() {
    local optsDescription=""$1"" # optsDescription LIKE a,a-long|b,b-long:|c,c-long+
    shift

    _OPT_INFO_LIST_INDEX=() # set global var!
    
    local optDescLines=`echo ""$optsDescription"" | 
        # cut head and tail space
        $_opts_SED_CMD -r 's/^\s+//;s/\s+$//' |
        awk -F '[\t ]*\\\\|[\t ]*' '{for(i=1; i<=NF; i++) print $i}'`
    
    local optDesc
    while read optDesc ; do # optDesc LIKE b,b-long:
        [ -z ""$optDesc"" ] && continue

        local mode=""${optDesc:(-1)}"" # LIKE : or +
        case ""$mode"" in
        +|:|-)
            optDesc=""${optDesc:0:(${#optDesc}-1)}"" # LIKE b,b-long
            ;;
        *)
            mode=""-""
            ;;
        esac

        local optLines=`echo ""$optDesc"" | awk -F '[\t ]*,[\t ]*' '{for(i=1; i<=NF; i++) print $i}'` # LIKE ""a\na-long""

        [ $(echo ""$optLines"" | wc -l) -gt 2 ] && {
            _opts_redEcho ""Illegal option description($optDesc), more than 2 opt name!"" 1>&2
            _opts_cleanOptValueInfoList
            return 220
        }

        local -a optTuple=()
        local opt
        while read opt ; do # opt LIKE a , a-long
            [ -z ""$opt"" ] && continue
            
            [ ${#opt} -eq 1 ] && {
                echo ""$opt"" | grep -E '^[a-zA-Z0-9]$' -q || {
                    _opts_redEcho ""Illegal short option name($opt in $optDesc) in option description!"" 1>&2
                    _opts_cleanOptValueInfoList
                    return 221
                }
            } || {
                echo ""$opt"" | grep -E '^[-a-zA-Z0-9]+$' -q || {
                    _opts_redEcho ""Illegal long option name($opt in $optDesc) in option description!"" 1>&2
                    _opts_cleanOptValueInfoList
                    return 222
                }
            }
            optTuple=(""${optTuple[@]}"" ""$opt"")
        done < <(echo ""$optLines"")

        [ ${#optTuple[@]} -gt 2 ] && {
            _opts_redEcho ""more than 2 opt(${optTuple[@]}) in option description($optDesc)!"" 1>&2
            _opts_cleanOptValueInfoList
            return 223
        }

        local idxName=
        local evalOpts=
        local o
        for o in ""${optTuple[@]}""; do
            idxName=""${idxName}_opts_index_name_`_opts_convertToVarName ""$o""`""
            evalOpts=""${evalOpts} $o""
        done

        eval ""$idxName=($mode $evalOpts)""
        _OPT_INFO_LIST_INDEX=(""${_OPT_INFO_LIST_INDEX[@]}"" ""$idxName"")
    done < <(echo ""$optDescLines"")

    local -a args=()
    while true; do
        [ $# -eq 0 ] && break

        case ""$1"" in
        ---*)
            _opts_redEcho ""Illegal option($1), more than 2 prefix '-'!"" 1>&2
            _opts_cleanOptValueInfoList
            return 230
            ;;
        --)
            shift
            args=(""${args[@]}"" ""$@"")
            break
            ;;
        -*) # short & long option(-a, -a-long), use same read-in logic.
            local opt=""$1""
            local optName=`echo ""$1"" | $_opts_SED_CMD -r 's/^--?//'`
            local mode=`_opts_findOptMode ""$optName""`
            case ""$mode"" in
            -)
                _opts_setOptBool ""$optName"" ""true""
                shift
                ;;
            :)
                [ $# -lt 2 ] && {
                    _opts_redEcho ""Option $opt has NO value!"" 1>&2
                    _opts_cleanOptValueInfoList
                    return 231
                } 
                _opts_setOptValue ""$optName"" ""$2""
                shift 2
                ;;
            +)
                shift
                local -a valueArray=()
                local foundComma=""""

                local value
                for value in ""$@"" ; do
                    [ "";"" == ""$value"" ] && {
                        foundComma=true
                        break
                    } || valueArray=(""${valueArray[@]}"" ""$value"")
                done
                [ ""$foundComma"" ] || {
                    _opts_redEcho ""value of option $opt no end comma, value = ${valueArray[@]}"" 1>&2
                    _opts_cleanOptValueInfoList
                    return 231
                }
                shift ""$((${#valueArray[@]} + 1))""
                _opts_setOptArray ""$optName"" ""${valueArray[@]}""
                ;;
            *)
                _opts_redEcho ""Undefined option $opt!"" 1>&2
                _opts_cleanOptValueInfoList
                return 232
                ;;
            esac
            ;;
        *)
            args=(""${args[@]}"" ""$1"")
            shift
            ;;
        esac
    done
    _OPT_ARGS=(""${args[@]}"") # set global var!
}

#####################################################################
# Show parsed Option Info Functions
#####################################################################

_opts_showOptDescInfoList() {
    echo ""===============================================================================""
    echo ""show option desc info list:""
    local idxName
    for idxName in ""${_OPT_INFO_LIST_INDEX[@]}""; do
        local idxNameArrayPlaceHolder=""$idxName[@]""
        echo ""$idxName = (${!idxNameArrayPlaceHolder})""
    done
    echo ""===============================================================================""
}

_opts_showOptValueInfoList() {
    echo ""===============================================================================""
    echo ""show option value info list:""
    local idxName
    for idxName in ""${_OPT_INFO_LIST_INDEX[@]}""; do
        local idxNameArrayPlaceHolder=""$idxName[@]""
        local -a idxNameArray=(""${!idxNameArrayPlaceHolder}"")

        local mode=${idxNameArray[0]}

        local optName
        for optName in ""${idxNameArray[@]:1:${#idxNameArray[@]}}""; do # index from 1, skip mode
            local optValueVarName=""_OPT_VALUE_`_opts_convertToVarName ""$optName""`"" 
            case ""$mode"" in
            -)
                echo ""$optValueVarName=${!optValueVarName}""
                ;;
            :)
                echo ""$optValueVarName=${!optValueVarName}""
                ;;
            +)
                local optArrayValueArrayPlaceHolder=""$optValueVarName[@]""
                echo ""$optValueVarName=(${!optArrayValueArrayPlaceHolder})""
                ;;
            esac
        done
    done
    echo ""_OPT_ARGS=(${_OPT_ARGS[@]})""
    echo ""===============================================================================""
}"
dehydrated-1,"#!/usr/bin/env bash

# dehydrated by lukas2511
# Source: https://dehydrated.io
#
# This script is licensed under The MIT License (see LICENSE for more information).

set -e
set -u
set -o pipefail
[[ -n ""${ZSH_VERSION:-}"" ]] && set -o SH_WORD_SPLIT && set +o FUNCTION_ARGZERO && set -o NULL_GLOB && set -o noglob
[[ -z ""${ZSH_VERSION:-}"" ]] && shopt -s nullglob && set -f

umask 077 # paranoid umask, we're creating private keys

# Close weird external file descriptors
exec 3>&-
exec 4>&-

VERSION=""0.7.1""

# Find directory in which this script is stored by traversing all symbolic links
SOURCE=""${0}""
while [ -h ""$SOURCE"" ]; do # resolve $SOURCE until the file is no longer a symlink
  DIR=""$( cd -P ""$( dirname ""$SOURCE"" )"" && pwd )""
  SOURCE=""$(readlink ""$SOURCE"")""
  [[ $SOURCE != /* ]] && SOURCE=""$DIR/$SOURCE"" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
done
SCRIPTDIR=""$( cd -P ""$( dirname ""$SOURCE"" )"" && pwd )""

BASEDIR=""${SCRIPTDIR}""
ORIGARGS=(""${@}"")

noglob_set() {
  if [[ -n ""${ZSH_VERSION:-}"" ]]; then
    set +o noglob
  else
    set +f
  fi
}

noglob_clear() {
  if [[ -n ""${ZSH_VERSION:-}"" ]]; then
    set -o noglob
  else
    set -f
  fi
}

# Generate json.sh path matching string
json_path() {
	if [ ! ""${1}"" = ""-p"" ]; then
		printf '""%s""' ""${1}""
	else
		printf '%s' ""${2}""
	fi
}

# Get string value from json dictionary
get_json_string_value() {
  local filter
  filter=""$(printf 's/.*\[%s\][[:space:]]*""\([^""]*\)""/\\1/p' ""$(json_path ""${1:-}"" ""${2:-}"")"")""
  sed -n ""${filter}""
}

# Get array values from json dictionary
get_json_array_values() {
  grep -E '^\['""$(json_path ""${1:-}"" ""${2:-}"")""',[0-9]*\]' | sed -e 's/\[[^\]*\][[:space:]]*//g' -e 's/^""//' -e 's/""$//'
}

# Get sub-dictionary from json
get_json_dict_value() {
  local filter
  filter=""$(printf 's/.*\[%s\][[:space:]]*\(.*\)/\\1/p' ""$(json_path ""${1:-}"" ""${2:-}"")"")""
  sed -n ""${filter}"" | jsonsh
}

# Get integer value from json
get_json_int_value() {
  local filter
  filter=""$(printf 's/.*\[%s\][[:space:]]*\([^""]*\)/\\1/p' ""$(json_path ""${1:-}"" ""${2:-}"")"")""
  sed -n ""${filter}""
}

# Get boolean value from json
get_json_bool_value() {
  local filter
  filter=""$(printf 's/.*\[%s\][[:space:]]*\([^""]*\)/\\1/p' ""$(json_path ""${1:-}"" ""${2:-}"")"")""
  sed -n ""${filter}""
}

# JSON.sh JSON-parser
# Modified from https://github.com/dominictarr/JSON.sh
# Original Copyright (c) 2011 Dominic Tarr
# Licensed under The MIT License
jsonsh() {

  throw() {
    echo ""$*"" >&2
    exit 1
  }

  awk_egrep () {
    local pattern_string=$1

    awk '{
      while ($0) {
        start=match($0, pattern);
        token=substr($0, start, RLENGTH);
        print token;
        $0=substr($0, start+RLENGTH);
      }
    }' pattern=""$pattern_string""
  }

  tokenize () {
    local GREP
    local ESCAPE
    local CHAR

    if echo ""test string"" | grep -Eao --color=never ""test"" >/dev/null 2>&1
    then
      GREP='grep -Eao --color=never'
    else
      GREP='grep -Eao'
    fi

    # shellcheck disable=SC2196
    if echo ""test string"" | egrep -ao ""test"" >/dev/null 2>&1
    then
      ESCAPE='(\\[^u[:cntrl:]]|\\u[0-9a-fA-F]{4})'
      CHAR='[^[:cntrl:]""\\]'
    else
      GREP=awk_egrep
      ESCAPE='(\\\\[^u[:cntrl:]]|\\u[0-9a-fA-F]{4})'
      CHAR='[^[:cntrl:]""\\\\]'
    fi

    local STRING=""\""$CHAR*($ESCAPE$CHAR*)*\""""
    local NUMBER='-?(0|[1-9][0-9]*)([.][0-9]*)?([eE][+-]?[0-9]*)?'
    local KEYWORD='null|false|true'
    local SPACE='[[:space:]]+'

    # Force zsh to expand $A into multiple words
    local is_wordsplit_disabled
    is_wordsplit_disabled=""$(unsetopt 2>/dev/null | grep -c '^shwordsplit$')""
    if [ ""${is_wordsplit_disabled}"" != ""0"" ]; then setopt shwordsplit; fi
    $GREP ""$STRING|$NUMBER|$KEYWORD|$SPACE|."" | grep -Ev ""^$SPACE$""
    if [ ""${is_wordsplit_disabled}"" != ""0"" ]; then unsetopt shwordsplit; fi
  }

  parse_array () {
    local index=0
    local ary=''
    read -r token
    case ""$token"" in
      ']') ;;
      *)
        while :
        do
          parse_value ""$1"" ""$index""
          index=$((index+1))
          ary=""$ary""""$value""
          read -r token
          case ""$token"" in
            ']') break ;;
            ',') ary=""$ary,"" ;;
            *) throw ""EXPECTED , or ] GOT ${token:-EOF}"" ;;
          esac
          read -r token
        done
        ;;
    esac
    value=$(printf '[%s]' ""$ary"") || value=
    :
  }

  parse_object () {
    local key
    local obj=''
    read -r token
    case ""$token"" in
      '}') ;;
      *)
        while :
        do
          case ""$token"" in
            '""'*'""') key=$token ;;
            *) throw ""EXPECTED string GOT ${token:-EOF}"" ;;
          esac
          read -r token
          case ""$token"" in
            ':') ;;
            *) throw ""EXPECTED : GOT ${token:-EOF}"" ;;
          esac
          read -r token
          parse_value ""$1"" ""$key""
          obj=""$obj$key:$value""
          read -r token
          case ""$token"" in
            '}') break ;;
            ',') obj=""$obj,"" ;;
            *) throw ""EXPECTED , or } GOT ${token:-EOF}"" ;;
          esac
          read -r token
        done
      ;;
    esac
    value=$(printf '{%s}' ""$obj"") || value=
    :
  }

  parse_value () {
    local jpath=""${1:+$1,}${2:-}""
    case ""$token"" in
      '{') parse_object ""$jpath"" ;;
      '[') parse_array  ""$jpath"" ;;
      # At this point, the only valid single-character tokens are digits.
      ''|[!0-9]) throw ""EXPECTED value GOT ${token:-EOF}"" ;;
      *) value=""${token/\\\///}""
         # replace solidus (""\/"") in json strings with normalized value: ""/""
         ;;
    esac
    [ ""$value"" = '' ] && return
    [ -z ""$jpath"" ] && return # do not print head

    printf ""[%s]\t%s\n"" ""$jpath"" ""$value""
    :
  }

  parse () {
    read -r token
    parse_value
    read -r token || true
    case ""$token"" in
      '') ;;
      *) throw ""EXPECTED EOF GOT $token"" ;;
    esac
  }

  tokenize | parse
}

# Create (identifiable) temporary files
_mktemp() {
  mktemp ""${TMPDIR:-/tmp}/dehydrated-XXXXXX""
}

# Check for script dependencies
check_dependencies() {
  # look for required binaries
  for binary in grep mktemp diff sed awk curl cut; do
    bin_path=""$(command -v ""${binary}"" 2>/dev/null)"" || _exiterr ""This script requires ${binary}.""
    [[ -x ""${bin_path}"" ]] || _exiterr ""${binary} found in PATH but it's not executable""
  done

  # just execute some dummy and/or version commands to see if required tools are actually usable
  ""${OPENSSL}"" version > /dev/null 2>&1 || _exiterr ""This script requires an openssl binary.""
  _sed """" < /dev/null > /dev/null 2>&1 || _exiterr ""This script requires sed with support for extended (modern) regular expressions.""

  # curl returns with an error code in some ancient versions so we have to catch that
  set +e
  CURL_VERSION=""$(curl -V 2>&1 | head -n1 | awk '{print $2}')""
  set -e
}

store_configvars() {
  __KEY_ALGO=""${KEY_ALGO}""
  __OCSP_MUST_STAPLE=""${OCSP_MUST_STAPLE}""
  __OCSP_FETCH=""${OCSP_FETCH}""
  __OCSP_DAYS=""${OCSP_DAYS}""
  __PRIVATE_KEY_RENEW=""${PRIVATE_KEY_RENEW}""
  __PRIVATE_KEY_ROLLOVER=""${PRIVATE_KEY_ROLLOVER}""
  __KEYSIZE=""${KEYSIZE}""
  __CHALLENGETYPE=""${CHALLENGETYPE}""
  __HOOK=""${HOOK}""
  __PREFERRED_CHAIN=""${PREFERRED_CHAIN}""
  __WELLKNOWN=""${WELLKNOWN}""
  __HOOK_CHAIN=""${HOOK_CHAIN}""
  __OPENSSL_CNF=""${OPENSSL_CNF}""
  __RENEW_DAYS=""${RENEW_DAYS}""
  __IP_VERSION=""${IP_VERSION}""
}

reset_configvars() {
  KEY_ALGO=""${__KEY_ALGO}""
  OCSP_MUST_STAPLE=""${__OCSP_MUST_STAPLE}""
  OCSP_FETCH=""${__OCSP_FETCH}""
  OCSP_DAYS=""${__OCSP_DAYS}""
  PRIVATE_KEY_RENEW=""${__PRIVATE_KEY_RENEW}""
  PRIVATE_KEY_ROLLOVER=""${__PRIVATE_KEY_ROLLOVER}""
  KEYSIZE=""${__KEYSIZE}""
  CHALLENGETYPE=""${__CHALLENGETYPE}""
  HOOK=""${__HOOK}""
  PREFERRED_CHAIN=""${__PREFERRED_CHAIN}""
  WELLKNOWN=""${__WELLKNOWN}""
  HOOK_CHAIN=""${__HOOK_CHAIN}""
  OPENSSL_CNF=""${__OPENSSL_CNF}""
  RENEW_DAYS=""${__RENEW_DAYS}""
  IP_VERSION=""${__IP_VERSION}""
}

hookscript_bricker_hook() {
  # Hook scripts should ignore any hooks they don't know.
  # Calling a random hook to make this clear to the hook script authors...
  if [[ -n ""${HOOK}"" ]]; then
    ""${HOOK}"" ""this_hookscript_is_broken__dehydrated_is_working_fine__please_ignore_unknown_hooks_in_your_script"" || _exiterr ""Please check your hook script, it should exit cleanly without doing anything on unknown/new hooks.""
  fi
}

# verify configuration values
verify_config() {
  [[ ""${CHALLENGETYPE}"" == ""http-01"" || ""${CHALLENGETYPE}"" == ""dns-01"" || ""${CHALLENGETYPE}"" == ""tls-alpn-01"" ]] || _exiterr ""Unknown challenge type ${CHALLENGETYPE}... cannot continue.""
  if [[ ""${CHALLENGETYPE}"" = ""dns-01"" ]] && [[ -z ""${HOOK}"" ]]; then
    _exiterr ""Challenge type dns-01 needs a hook script for deployment... cannot continue.""
  fi
  if [[ ""${CHALLENGETYPE}"" = ""http-01"" && ! -d ""${WELLKNOWN}"" && ! ""${COMMAND:-}"" = ""register"" ]]; then
    _exiterr ""WELLKNOWN directory doesn't exist, please create ${WELLKNOWN} and set appropriate permissions.""
  fi
  [[ ""${KEY_ALGO}"" == ""rsa"" || ""${KEY_ALGO}"" == ""prime256v1"" || ""${KEY_ALGO}"" == ""secp384r1"" || ""${KEY_ALGO}"" == ""secp521r1"" ]] || _exiterr ""Unknown public key algorithm ${KEY_ALGO}... cannot continue.""
  if [[ -n ""${IP_VERSION}"" ]]; then
    [[ ""${IP_VERSION}"" = ""4"" || ""${IP_VERSION}"" = ""6"" ]] || _exiterr ""Unknown IP version ${IP_VERSION}... cannot continue.""
  fi
  [[ ""${API}"" == ""auto"" || ""${API}"" == ""1"" || ""${API}"" == ""2"" ]] || _exiterr ""Unsupported API version defined in config: ${API}""
  [[ ""${OCSP_DAYS}"" =~ ^[0-9]+$ ]] || _exiterr ""OCSP_DAYS must be a number""
}

# Setup default config values, search for and load configuration files
load_config() {
  # Check for config in various locations
  if [[ -z ""${CONFIG:-}"" ]]; then
    for check_config in ""/etc/dehydrated"" ""/usr/local/etc/dehydrated"" ""${PWD}"" ""${SCRIPTDIR}""; do
      if [[ -f ""${check_config}/config"" ]]; then
        BASEDIR=""${check_config}""
        CONFIG=""${check_config}/config""
        break
      fi
    done
  fi

  # Preset
  CA_ZEROSSL=""https://acme.zerossl.com/v2/DV90""
  CA_LETSENCRYPT=""https://acme-v02.api.letsencrypt.org/directory""
  CA_LETSENCRYPT_TEST=""https://acme-staging-v02.api.letsencrypt.org/directory""
  CA_BUYPASS=""https://api.buypass.com/acme/directory""
  CA_BUYPASS_TEST=""https://api.test4.buypass.no/acme/directory""

  # Default values
  CA=""letsencrypt""
  OLDCA=
  CERTDIR=
  ALPNCERTDIR=
  ACCOUNTDIR=
  ACCOUNT_KEYSIZE=""4096""
  ACCOUNT_KEY_ALGO=rsa
  CHALLENGETYPE=""http-01""
  CONFIG_D=
  CURL_OPTS=
  DOMAINS_D=
  DOMAINS_TXT=
  HOOK=
  PREFERRED_CHAIN=
  HOOK_CHAIN=""no""
  RENEW_DAYS=""30""
  KEYSIZE=""4096""
  WELLKNOWN=
  PRIVATE_KEY_RENEW=""yes""
  PRIVATE_KEY_ROLLOVER=""no""
  KEY_ALGO=secp384r1
  OPENSSL=openssl
  OPENSSL_CNF=
  CONTACT_EMAIL=
  LOCKFILE=
  OCSP_MUST_STAPLE=""no""
  OCSP_FETCH=""no""
  OCSP_DAYS=5
  IP_VERSION=
  CHAINCACHE=
  AUTO_CLEANUP=""no""
  DEHYDRATED_USER=
  DEHYDRATED_GROUP=
  API=""auto""

  if [[ -z ""${CONFIG:-}"" ]]; then
    echo ""#"" >&2
    echo ""# !! WARNING !! No main config file found, using default config!"" >&2
    echo ""#"" >&2
  elif [[ -f ""${CONFIG}"" ]]; then
    echo ""# INFO: Using main config file ${CONFIG}""
    BASEDIR=""$(dirname ""${CONFIG}"")""
    # shellcheck disable=SC1090
    . ""${CONFIG}""
  else
    _exiterr ""Specified config file doesn't exist.""
  fi

  if [[ -n ""${CONFIG_D}"" ]]; then
    if [[ ! -d ""${CONFIG_D}"" ]]; then
      _exiterr ""The path ${CONFIG_D} specified for CONFIG_D does not point to a directory.""
    fi

    # Allow globbing
    noglob_set

    for check_config_d in ""${CONFIG_D}""/*.sh; do
      if [[ -f ""${check_config_d}"" ]] && [[ -r ""${check_config_d}"" ]]; then
        echo ""# INFO: Using additional config file ${check_config_d}""
        # shellcheck disable=SC1090
        . ""${check_config_d}""
      else
        _exiterr ""Specified additional config ${check_config_d} is not readable or not a file at all.""
      fi
    done

    # Disable globbing
    noglob_clear
  fi

  # Check for missing dependencies
  check_dependencies

  has_sudo() {
    command -v sudo > /dev/null 2>&1 || _exiterr ""DEHYDRATED_USER set but sudo not available. Please install sudo.""
  }

  # Check if we are running & are allowed to run as root
  if [[ -n ""$DEHYDRATED_USER"" ]]; then
    command -v getent > /dev/null 2>&1 || _exiterr ""DEHYDRATED_USER set but getent not available. Please install getent.""

    TARGET_UID=""$(getent passwd ""${DEHYDRATED_USER}"" | cut -d':' -f3)"" || _exiterr ""DEHYDRATED_USER ${DEHYDRATED_USER} is invalid""
    if [[ -z ""${DEHYDRATED_GROUP}"" ]]; then
      if [[ ""${EUID}"" != ""${TARGET_UID}"" ]]; then
        echo ""# INFO: Running $0 as ${DEHYDRATED_USER}""
        has_sudo && exec sudo -u ""${DEHYDRATED_USER}"" ""${0}"" ""${ORIGARGS[@]}""
      fi
    else
      TARGET_GID=""$(getent group ""${DEHYDRATED_GROUP}"" | cut -d':' -f3)"" || _exiterr ""DEHYDRATED_GROUP ${DEHYDRATED_GROUP} is invalid""
      if [[ -z ""${EGID:-}"" ]]; then
        command -v id > /dev/null 2>&1 || _exiterr ""DEHYDRATED_GROUP set, don't know current gid and 'id' not available... Please provide 'id' binary.""
        EGID=""$(id -g)""
      fi
      if [[ ""${EUID}"" != ""${TARGET_UID}"" ]] || [[ ""${EGID}"" != ""${TARGET_GID}"" ]]; then
        echo ""# INFO: Running $0 as ${DEHYDRATED_USER}/${DEHYDRATED_GROUP}""
        has_sudo && exec sudo -u ""${DEHYDRATED_USER}"" -g ""${DEHYDRATED_GROUP}"" ""${0}"" ""${ORIGARGS[@]}""
      fi
    fi
  elif [[ -n ""${DEHYDRATED_GROUP}"" ]]; then
    _exiterr ""DEHYDRATED_GROUP can only be used in combination with DEHYDRATED_USER.""
  fi

  # Remove slash from end of BASEDIR. Mostly for cleaner outputs, doesn't change functionality.
  [[ ""$BASEDIR"" != ""/"" ]] && BASEDIR=""${BASEDIR%%/}""

  # Check BASEDIR and set default variables
  [[ -d ""${BASEDIR}"" ]] || _exiterr ""BASEDIR does not exist: ${BASEDIR}""

  # Check for ca cli parameter
  if [ -n ""${PARAM_CA:-}"" ]; then
    CA=""${PARAM_CA}""
  fi

  # Preset CAs
  if [ ""${CA}"" = ""letsencrypt"" ]; then
    CA=""${CA_LETSENCRYPT}""
  elif [ ""${CA}"" = ""letsencrypt-test"" ]; then
    CA=""${CA_LETSENCRYPT_TEST}""
  elif [ ""${CA}"" = ""zerossl"" ]; then
    CA=""${CA_ZEROSSL}""
  elif [ ""${CA}"" = ""buypass"" ]; then
    CA=""${CA_BUYPASS}""
  elif [ ""${CA}"" = ""buypass-test"" ]; then
    CA=""${CA_BUYPASS_TEST}""
  fi

  if [[ -z ""${OLDCA}"" ]] && [[ ""${CA}"" = ""https://acme-v02.api.letsencrypt.org/directory"" ]]; then
    OLDCA=""https://acme-v01.api.letsencrypt.org/directory""
  fi

  # Create new account directory or symlink to account directory from old CA
  # dev note: keep in mind that because of the use of 'echo' instead of 'printf' or
  # similar there is a newline encoded in the directory name. not going to fix this
  # since it's a non-issue and trying to fix existing installations would be too much
  # trouble
  CAHASH=""$(echo ""${CA}"" | urlbase64)""
  [[ -z ""${ACCOUNTDIR}"" ]] && ACCOUNTDIR=""${BASEDIR}/accounts""
  if [[ ! -e ""${ACCOUNTDIR}/${CAHASH}"" ]]; then
    OLDCAHASH=""$(echo ""${OLDCA}"" | urlbase64)""
    mkdir -p ""${ACCOUNTDIR}""
    if [[ -n ""${OLDCA}"" ]] && [[ -e ""${ACCOUNTDIR}/${OLDCAHASH}"" ]]; then
      echo ""! Reusing account from ${OLDCA}""
      ln -s ""${OLDCAHASH}"" ""${ACCOUNTDIR}/${CAHASH}""
    else
      mkdir ""${ACCOUNTDIR}/${CAHASH}""
    fi
  fi

  # shellcheck disable=SC1090
  [[ -f ""${ACCOUNTDIR}/${CAHASH}/config"" ]] && . ""${ACCOUNTDIR}/${CAHASH}/config""
  ACCOUNT_KEY=""${ACCOUNTDIR}/${CAHASH}/account_key.pem""
  ACCOUNT_KEY_JSON=""${ACCOUNTDIR}/${CAHASH}/registration_info.json""
  ACCOUNT_ID_JSON=""${ACCOUNTDIR}/${CAHASH}/account_id.json""
  ACCOUNT_DEACTIVATED=""${ACCOUNTDIR}/${CAHASH}/deactivated""

  if [[ -f ""${ACCOUNT_DEACTIVATED}"" ]]; then
    _exiterr ""Account has been deactivated. Remove account and create a new one using --register.""
  fi

  if [[ -f ""${BASEDIR}/private_key.pem"" ]] && [[ ! -f ""${ACCOUNT_KEY}"" ]]; then
    echo ""! Moving private_key.pem to ${ACCOUNT_KEY}""
    mv ""${BASEDIR}/private_key.pem"" ""${ACCOUNT_KEY}""
  fi
  if [[ -f ""${BASEDIR}/private_key.json"" ]] && [[ ! -f ""${ACCOUNT_KEY_JSON}"" ]]; then
    echo ""! Moving private_key.json to ${ACCOUNT_KEY_JSON}""
    mv ""${BASEDIR}/private_key.json"" ""${ACCOUNT_KEY_JSON}""
  fi

  [[ -z ""${CERTDIR}"" ]] && CERTDIR=""${BASEDIR}/certs""
  [[ -z ""${ALPNCERTDIR}"" ]] && ALPNCERTDIR=""${BASEDIR}/alpn-certs""
  [[ -z ""${CHAINCACHE}"" ]] && CHAINCACHE=""${BASEDIR}/chains""
  [[ -z ""${DOMAINS_TXT}"" ]] && DOMAINS_TXT=""${BASEDIR}/domains.txt""
  [[ -z ""${WELLKNOWN}"" ]] && WELLKNOWN=""/var/www/dehydrated""
  [[ -z ""${LOCKFILE}"" ]] && LOCKFILE=""${BASEDIR}/lock""
  [[ -z ""${OPENSSL_CNF}"" ]] && OPENSSL_CNF=""$(""${OPENSSL}"" version -d | cut -d\"" -f2)/openssl.cnf""
  [[ -n ""${PARAM_LOCKFILE_SUFFIX:-}"" ]] && LOCKFILE=""${LOCKFILE}-${PARAM_LOCKFILE_SUFFIX}""
  [[ -n ""${PARAM_NO_LOCK:-}"" ]] && LOCKFILE=""""

  [[ -n ""${PARAM_HOOK:-}"" ]] && HOOK=""${PARAM_HOOK}""
  [[ -n ""${PARAM_DOMAINS_TXT:-}"" ]] && DOMAINS_TXT=""${PARAM_DOMAINS_TXT}""
  [[ -n ""${PARAM_PREFERRED_CHAIN:-}"" ]] && PREFERRED_CHAIN=""${PARAM_PREFERRED_CHAIN}""
  [[ -n ""${PARAM_CERTDIR:-}"" ]] && CERTDIR=""${PARAM_CERTDIR}""
  [[ -n ""${PARAM_ALPNCERTDIR:-}"" ]] && ALPNCERTDIR=""${PARAM_ALPNCERTDIR}""
  [[ -n ""${PARAM_CHALLENGETYPE:-}"" ]] && CHALLENGETYPE=""${PARAM_CHALLENGETYPE}""
  [[ -n ""${PARAM_KEY_ALGO:-}"" ]] && KEY_ALGO=""${PARAM_KEY_ALGO}""
  [[ -n ""${PARAM_OCSP_MUST_STAPLE:-}"" ]] && OCSP_MUST_STAPLE=""${PARAM_OCSP_MUST_STAPLE}""
  [[ -n ""${PARAM_IP_VERSION:-}"" ]] && IP_VERSION=""${PARAM_IP_VERSION}""

  if [ ""${PARAM_FORCE_VALIDATION:-no}"" = ""yes"" ] && [ ""${PARAM_FORCE:-no}"" = ""no"" ]; then
    _exiterr ""Argument --force-validation can only be used in combination with --force (-x)""
  fi

  if [ ! ""${1:-}"" = ""noverify"" ]; then
    verify_config
  fi
  store_configvars
}

# Initialize system
init_system() {
  load_config

  # Lockfile handling (prevents concurrent access)
  if [[ -n ""${LOCKFILE}"" ]]; then
    LOCKDIR=""$(dirname ""${LOCKFILE}"")""
    [[ -w ""${LOCKDIR}"" ]] || _exiterr ""Directory ${LOCKDIR} for LOCKFILE ${LOCKFILE} is not writable, aborting.""
    ( set -C; date > ""${LOCKFILE}"" ) 2>/dev/null || _exiterr ""Lock file '${LOCKFILE}' present, aborting.""
    remove_lock() { rm -f ""${LOCKFILE}""; }
    trap 'remove_lock' EXIT
  fi

  # Get CA URLs
  CA_DIRECTORY=""$(http_request get ""${CA}"" | jsonsh)""

  # Automatic discovery of API version
  if [[ ""${API}"" = ""auto"" ]]; then
    grep -q newOrder <<< ""${CA_DIRECTORY}"" && API=2 || API=1
  fi

  # shellcheck disable=SC2015
  if [[ ""${API}"" = ""1"" ]]; then
    CA_NEW_CERT=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value new-cert)"" &&
    CA_NEW_AUTHZ=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value new-authz)"" &&
    CA_NEW_REG=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value new-reg)"" &&
    CA_TERMS=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value terms-of-service)"" &&
    CA_REQUIRES_EAB=""false"" &&
    CA_REVOKE_CERT=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value revoke-cert)"" ||
    _exiterr ""Problem retrieving ACME/CA-URLs, check if your configured CA points to the directory entrypoint.""
    # Since reg URI is missing from directory we will assume it is the same as CA_NEW_REG without the new part
    CA_REG=${CA_NEW_REG/new-reg/reg}
  else
    CA_NEW_ORDER=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value newOrder)"" &&
    CA_NEW_NONCE=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value newNonce)"" &&
    CA_NEW_ACCOUNT=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value newAccount)"" &&
    CA_TERMS=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value -p '""meta"",""termsOfService""')"" &&
    CA_REQUIRES_EAB=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_bool_value -p '""meta"",""externalAccountRequired""' || echo false)"" &&
    CA_REVOKE_CERT=""$(printf ""%s"" ""${CA_DIRECTORY}"" | get_json_string_value revokeCert)"" ||
    _exiterr ""Problem retrieving ACME/CA-URLs, check if your configured CA points to the directory entrypoint.""
  fi

  # Export some environment variables to be used in hook script
  export WELLKNOWN BASEDIR CERTDIR ALPNCERTDIR CONFIG COMMAND

  # Checking for private key ...
  register_new_key=""no""
  generated=""false""
  if [[ -n ""${PARAM_ACCOUNT_KEY:-}"" ]]; then
    # a private key was specified from the command line so use it for this run
    echo ""Using private key ${PARAM_ACCOUNT_KEY} instead of account key""
    ACCOUNT_KEY=""${PARAM_ACCOUNT_KEY}""
    ACCOUNT_KEY_JSON=""${PARAM_ACCOUNT_KEY}.json""
    ACCOUNT_ID_JSON=""${PARAM_ACCOUNT_KEY}_id.json""
    [ ""${COMMAND:-}"" = ""register"" ] && register_new_key=""yes""
  else
    # Check if private account key exists, if it doesn't exist yet generate a new one (rsa key)
    if [[ ! -e ""${ACCOUNT_KEY}"" ]]; then
      if [[ ! ""${PARAM_ACCEPT_TERMS:-}"" = ""yes"" ]]; then
        printf '\n' >&2
        printf 'To use dehydrated with this certificate authority you have to agree to their terms of service which you can find here: %s\n\n' ""${CA_TERMS}"" >&2
        printf 'To accept these terms of service run ""%s --register --accept-terms"".\n' ""${0}"" >&2
        exit 1
      fi

      echo ""+ Generating account key...""
      generated=""true""
      local tmp_account_key
      tmp_account_key=""$(_mktemp)""
      if [[ ${API} -eq 1 && ! ""${ACCOUNT_KEY_ALGO}"" = ""rsa"" ]]; then
        _exiterr ""ACME API version 1 does not support EC account keys""
      fi
      case ""${ACCOUNT_KEY_ALGO}"" in
        rsa) _openssl genrsa -out ""${tmp_account_key}"" ""${ACCOUNT_KEYSIZE}"";;
        prime256v1|secp384r1|secp521r1) _openssl ecparam -genkey -name ""${ACCOUNT_KEY_ALGO}"" -out ""${tmp_account_key}"" -noout;;
      esac
      cat ""${tmp_account_key}"" > ""${ACCOUNT_KEY}""
      rm ""${tmp_account_key}""
      register_new_key=""yes""
    fi
  fi

  if (""${OPENSSL}"" rsa -in ""${ACCOUNT_KEY}"" -check 2>/dev/null > /dev/null); then
    # Get public components from private key and calculate thumbprint
    pubExponent64=""$(printf '%x' ""$(""${OPENSSL}"" rsa -in ""${ACCOUNT_KEY}"" -noout -text | awk '/publicExponent/ {print $2}')"" | hex2bin | urlbase64)""
    pubMod64=""$(""${OPENSSL}"" rsa -in ""${ACCOUNT_KEY}"" -noout -modulus | cut -d'=' -f2 | hex2bin | urlbase64)""

    account_key_info=""$(printf '{""e"":""%s"",""kty"":""RSA"",""n"":""%s""}' ""${pubExponent64}"" ""${pubMod64}"")""
    account_key_sigalgo=RS256
  elif (""${OPENSSL}"" ec -in ""${ACCOUNT_KEY}"" -check 2>/dev/null > /dev/null); then
    curve=""$(""${OPENSSL}"" ec -in ""${ACCOUNT_KEY}"" -noout -text 2>/dev/null | grep 'NIST CURVE' | cut -d':' -f2 | tr -d ' ')""
    pubkey=""$(""${OPENSSL}"" ec -in ""${ACCOUNT_KEY}"" -noout -text 2>/dev/null | tr -d '\n ' | grep -Eo 'pub:.*ASN1' | _sed -e 's/^pub://' -e 's/ASN1$//' | tr -d ':')""

    if [ ""${curve}"" = ""P-256"" ]; then
      account_key_sigalgo=""ES256""
    elif [ ""${curve}"" = ""P-384"" ]; then
      account_key_sigalgo=""ES384""
    elif [ ""${curve}"" = ""P-521"" ]; then
      account_key_sigalgo=""ES512""
    else
      _exiterr ""Unknown account key curve: ${curve}""
    fi

    ec_x_offset=2
    ec_x_len=$((${#pubkey}/2 - 1))
    ec_x=""${pubkey:$ec_x_offset:$ec_x_len}""
    ec_x64=""$(printf ""%s"" ""${ec_x}"" | hex2bin | urlbase64)""

    ec_y_offset=$((ec_x_offset+ec_x_len))
    ec_y_len=$((${#pubkey}-ec_y_offset))
    ec_y=""${pubkey:$ec_y_offset:$ec_y_len}""
    ec_y64=""$(printf ""%s"" ""${ec_y}"" | hex2bin | urlbase64)""

    account_key_info=""$(printf '{""crv"":""%s"",""kty"":""EC"",""x"":""%s"",""y"":""%s""}' ""${curve}"" ""${ec_x64}"" ""${ec_y64}"")""
  else
    _exiterr ""Account key is not valid, cannot continue.""
  fi
  thumbprint=""$(printf '%s' ""${account_key_info}"" | ""${OPENSSL}"" dgst -sha256 -binary | urlbase64)""

  # If we generated a new private key in the step above we have to register it with the acme-server
  if [[ ""${register_new_key}"" = ""yes"" ]]; then
    echo ""+ Registering account key with ACME server...""
    FAILED=false

    if [[ ${API} -eq 1 && -z ""${CA_NEW_REG}"" ]] || [[ ${API} -eq 2 && -z ""${CA_NEW_ACCOUNT}"" ]]; then
      echo ""Certificate authority doesn't allow registrations.""
      FAILED=true
    fi

    # ZeroSSL special sauce
    if [[ ""${CA}"" = ""${CA_ZEROSSL}"" ]]; then
      if [[ -z ""${EAB_KID:-}"" ]] ||  [[ -z ""${EAB_HMAC_KEY:-}"" ]]; then
        if [[ -z ""${CONTACT_EMAIL}"" ]]; then
          echo ""ZeroSSL requires contact email to be set or EAB_KID/EAB_HMAC_KEY to be manually configured""
          FAILED=true
        else
          zeroapi=""$(curl -s ""https://api.zerossl.com/acme/eab-credentials-email"" -d ""email=${CONTACT_EMAIL}"" | jsonsh)""
          EAB_KID=""$(printf ""%s"" ""${zeroapi}"" | get_json_string_value eab_kid)""
          EAB_HMAC_KEY=""$(printf ""%s"" ""${zeroapi}"" | get_json_string_value eab_hmac_key)""
          if [[ -z ""${EAB_KID:-}"" ]] ||  [[ -z ""${EAB_HMAC_KEY:-}"" ]]; then
            echo ""Unknown error retrieving ZeroSSL API credentials""
            echo ""${zeroapi}""
            FAILED=true
          fi
        fi
      fi
    fi

    # Check if external account is required
    if [[ ""${FAILED}"" = ""false"" ]]; then
      if [[ ""${CA_REQUIRES_EAB}"" = ""true"" ]]; then
        if [[ -z ""${EAB_KID:-}"" ]] || [[ -z ""${EAB_HMAC_KEY:-}"" ]]; then
          FAILED=true
          echo ""This CA requires an external account but no EAB_KID/EAB_HMAC_KEY has been configured""
        fi
      fi
    fi

    # If an email for the contact has been provided then adding it to the registration request
    if [[ ""${FAILED}"" = ""false"" ]]; then
      if [[ ${API} -eq 1 ]]; then
        if [[ -n ""${CONTACT_EMAIL}"" ]]; then
          (signed_request ""${CA_NEW_REG}"" '{""resource"": ""new-reg"", ""contact"":[""mailto:'""${CONTACT_EMAIL}""'""], ""agreement"": ""'""${CA_TERMS}""'""}' > ""${ACCOUNT_KEY_JSON}"") || FAILED=true
        else
          (signed_request ""${CA_NEW_REG}"" '{""resource"": ""new-reg"", ""agreement"": ""'""${CA_TERMS}""'""}' > ""${ACCOUNT_KEY_JSON}"") || FAILED=true
        fi
      else
        if [[ -n ""${EAB_KID:-}"" ]] && [[ -n ""${EAB_HMAC_KEY:-}"" ]]; then
          eab_url=""${CA_NEW_ACCOUNT}""
          eab_protected64=""$(printf '{""alg"":""HS256"",""kid"":""%s"",""url"":""%s""}' ""${EAB_KID}"" ""${eab_url}"" | urlbase64)""
          eab_payload64=""$(printf ""%s"" ""${account_key_info}"" | urlbase64)""
          eab_key=""$(printf ""%s"" ""${EAB_HMAC_KEY}"" | deurlbase64 | bin2hex)""
          eab_signed64=""$(printf '%s' ""${eab_protected64}.${eab_payload64}"" | ""${OPENSSL}"" dgst -binary -sha256 -mac HMAC -macopt ""hexkey:${eab_key}"" | urlbase64)""

          if [[ -n ""${CONTACT_EMAIL}"" ]]; then
            regjson='{""contact"":[""mailto:'""${CONTACT_EMAIL}""'""], ""termsOfServiceAgreed"": true, ""externalAccountBinding"": {""protected"": ""'""${eab_protected64}""'"", ""payload"": ""'""${eab_payload64}""'"", ""signature"": ""'""${eab_signed64}""'""}}'
          else
            regjson='{""termsOfServiceAgreed"": true, ""externalAccountBinding"": {""protected"": ""'""${eab_protected64}""'"", ""payload"": ""'""${eab_payload64}""'"", ""signature"": ""'""${eab_signed64}""'""}}'
          fi
        else
          if [[ -n ""${CONTACT_EMAIL}"" ]]; then
            regjson='{""contact"":[""mailto:'""${CONTACT_EMAIL}""'""], ""termsOfServiceAgreed"": true}'
          else
            regjson='{""termsOfServiceAgreed"": true}'
          fi
        fi
        (signed_request ""${CA_NEW_ACCOUNT}"" ""${regjson}"" > ""${ACCOUNT_KEY_JSON}"") || FAILED=true
      fi
    fi

    if [[ ""${FAILED}"" = ""true"" ]]; then
      echo >&2
      echo >&2
      echo ""Error registering account key. See message above for more information."" >&2
      if [[ ""${generated}"" = ""true"" ]]; then
        rm ""${ACCOUNT_KEY}""
      fi
      rm -f ""${ACCOUNT_KEY_JSON}""
      exit 1
    fi
  elif [[ ""${COMMAND:-}"" = ""register"" ]]; then
    echo ""+ Account already registered!""
    exit 0
  fi

  # Read account information or request from CA if missing
  if [[ -e ""${ACCOUNT_KEY_JSON}"" ]]; then
    if [[ ${API} -eq 1 ]]; then
      ACCOUNT_ID=""$(jsonsh < ""${ACCOUNT_KEY_JSON}"" | get_json_int_value id)""
      ACCOUNT_URL=""${CA_REG}/${ACCOUNT_ID}""
    else
      if [[ -e ""${ACCOUNT_ID_JSON}"" ]]; then
        ACCOUNT_URL=""$(jsonsh < ""${ACCOUNT_ID_JSON}"" | get_json_string_value url)""
      fi
      # if account URL is not storred, fetch it from the CA
      if [[ -z ""${ACCOUNT_URL:-}"" ]]; then
        echo ""+ Fetching account URL...""
        ACCOUNT_URL=""$(signed_request ""${CA_NEW_ACCOUNT}"" '{""onlyReturnExisting"": true}' 4>&1 | grep -i ^Location: | cut -d':' -f2- | tr -d ' \t\r\n')""
        if [[ -z ""${ACCOUNT_URL}"" ]]; then
          _exiterr ""Unknown error on fetching account information""
        fi
        echo '{""url"":""'""${ACCOUNT_URL}""'""}' > ""${ACCOUNT_ID_JSON}"" # store the URL for next time
      fi
    fi
  else
    echo ""Fetching missing account information from CA...""
    if [[ ${API} -eq 1 ]]; then
      _exiterr ""This is not implemented for ACMEv1! Consider switching to ACMEv2 :)""
    else
      ACCOUNT_URL=""$(signed_request ""${CA_NEW_ACCOUNT}"" '{""onlyReturnExisting"": true}' 4>&1 | grep -i ^Location: | cut -d':' -f2- | tr -d ' \t\r\n')""
      ACCOUNT_INFO=""$(signed_request ""${ACCOUNT_URL}"" '{}')""
    fi
    echo ""${ACCOUNT_INFO}"" > ""${ACCOUNT_KEY_JSON}""
  fi
}

# Different sed version for different os types...
_sed() {
  if [[ ""${OSTYPE}"" = ""Linux"" || ""${OSTYPE:0:5}"" = ""MINGW"" ]]; then
    sed -r ""${@}""
  else
    sed -E ""${@}""
  fi
}

# Print error message and exit with error
_exiterr() {
  if [ -n ""${1:-}"" ]; then
    echo ""ERROR: ${1}"" >&2
  fi
  [[ ""${skip_exit_hook:-no}"" = ""no"" ]] && [[ -n ""${HOOK:-}"" ]] && (""${HOOK}"" ""exit_hook"" ""${1:-}"" || echo 'exit_hook returned with non-zero exit code!' >&2)
  exit 1
}

# Remove newlines and whitespace from json
clean_json() {
  tr -d '\r\n' | _sed -e 's/ +/ /g' -e 's/\{ /{/g' -e 's/ \}/}/g' -e 's/\[ /[/g' -e 's/ \]/]/g'
}

# Encode data as url-safe formatted base64
urlbase64() {
  # urlbase64: base64 encoded string with '+' replaced with '-' and '/' replaced with '_'
  ""${OPENSSL}"" base64 -e | tr -d '\n\r' | _sed -e 's:=*$::g' -e 'y:+/:-_:'
}

# Decode data from url-safe formatted base64
deurlbase64() {
  data=""$(cat | tr -d ' \n\r')""
  modlen=$((${#data} % 4))
  padding=""""
  if [[ ""${modlen}"" = ""2"" ]]; then padding=""=="";
  elif [[ ""${modlen}"" = ""3"" ]]; then padding=""=""; fi
  printf ""%s%s"" ""${data}"" ""${padding}"" | tr -d '\n\r' | _sed -e 'y:-_:+/:' | ""${OPENSSL}"" base64 -d -A
}

# Convert hex string to binary data
hex2bin() {
  # Remove spaces, add leading zero, escape as hex string and parse with printf
  # shellcheck disable=SC2059
  printf ""%b"" ""$(cat | _sed -e 's/[[:space:]]//g' -e 's/^(.(.{2})*)$/0\1/' -e 's/(.{2})/\\x\1/g')""
}

# Convert binary data to hex string
bin2hex() {
  hexdump -e '16/1 ""%02x""'
}

# OpenSSL writes to stderr/stdout even when there are no errors. So just
# display the output if the exit code was != 0 to simplify debugging.
_openssl() {
  set +e
  out=""$(""${OPENSSL}"" ""${@}"" 2>&1)""
  res=$?
  set -e
  if [[ ${res} -ne 0 ]]; then
    echo ""  + ERROR: failed to run $* (Exitcode: ${res})"" >&2
    echo >&2
    echo ""Details:"" >&2
    echo ""${out}"" >&2
    echo >&2
    exit ""${res}""
  fi
}

# Send http(s) request with specified method
http_request() {
  tempcont=""$(_mktemp)""
  tempheaders=""$(_mktemp)""

  if [[ -n ""${IP_VERSION:-}"" ]]; then
      ip_version=""-${IP_VERSION}""
  fi

  set +e
  # shellcheck disable=SC2086
  if [[ ""${1}"" = ""head"" ]]; then
    statuscode=""$(curl ${ip_version:-} ${CURL_OPTS} -A ""dehydrated/${VERSION} curl/${CURL_VERSION}"" -s -w ""%{http_code}"" -o ""${tempcont}"" ""${2}"" -I)""
    curlret=""${?}""
    touch ""${tempheaders}""
  elif [[ ""${1}"" = ""get"" ]]; then
    statuscode=""$(curl ${ip_version:-} ${CURL_OPTS} -A ""dehydrated/${VERSION} curl/${CURL_VERSION}"" -L -s -w ""%{http_code}"" -o ""${tempcont}"" -D ""${tempheaders}"" ""${2}"")""
    curlret=""${?}""
  elif [[ ""${1}"" = ""post"" ]]; then
    statuscode=""$(curl ${ip_version:-} ${CURL_OPTS} -A ""dehydrated/${VERSION} curl/${CURL_VERSION}"" -s -w ""%{http_code}"" -o ""${tempcont}"" ""${2}"" -D ""${tempheaders}"" -H 'Content-Type: application/jose+json' -d ""${3}"")""
    curlret=""${?}""
  else
    set -e
    _exiterr ""Unknown request method: ${1}""
  fi
  set -e

  if [[ ! ""${curlret}"" = ""0"" ]]; then
    _exiterr ""Problem connecting to server (${1} for ${2}; curl returned with ${curlret})""
  fi

  if [[ ! ""${statuscode:0:1}"" = ""2"" ]]; then
    # check for existing registration warning
    if [[ ""${API}"" = ""1"" ]] && [[ -n ""${CA_NEW_REG:-}"" ]] && [[ ""${2}"" = ""${CA_NEW_REG:-}"" ]] && [[ ""${statuscode}"" = ""409"" ]] && grep -q ""Registration key is already in use"" ""${tempcont}""; then
      # do nothing
      :
    # check for already-revoked warning
    elif [[ -n ""${CA_REVOKE_CERT:-}"" ]] && [[ ""${2}"" = ""${CA_REVOKE_CERT:-}"" ]] && [[ ""${statuscode}"" = ""409"" ]]; then
      grep -q ""Certificate already revoked"" ""${tempcont}"" && return
    else
      echo ""  + ERROR: An error occurred while sending ${1}-request to ${2} (Status ${statuscode})"" >&2
      echo >&2
      echo ""Details:"" >&2
      cat ""${tempheaders}"" >&2
      cat ""${tempcont}"" >&2
      echo >&2
      echo >&2

      # An exclusive hook for the {1}-request error might be useful (e.g., for sending an e-mail to admins)
      if [[ -n ""${HOOK}"" ]]; then
        errtxt=""$(cat ""${tempcont}"")""
        errheaders=""$(cat ""${tempheaders}"")""
        ""${HOOK}"" ""request_failure"" ""${statuscode}"" ""${errtxt}"" ""${1}"" ""${errheaders}"" || _exiterr 'request_failure hook returned with non-zero exit code'
      fi

      rm -f ""${tempcont}""
      rm -f ""${tempheaders}""

      # remove temporary domains.txt file if used
      [[ ""${COMMAND:-}"" = ""sign_domains"" && -n ""${PARAM_DOMAIN:-}"" && -n ""${DOMAINS_TXT:-}"" ]] && rm ""${DOMAINS_TXT}""
      _exiterr
    fi
  fi

  if { true >&4; } 2>/dev/null; then
    cat ""${tempheaders}"" >&4
  fi
  cat ""${tempcont}""
  rm -f ""${tempcont}""
  rm -f ""${tempheaders}""
}

# Send signed request
signed_request() {
  # Encode payload as urlbase64
  payload64=""$(printf '%s' ""${2}"" | urlbase64)""

  # Retrieve nonce from acme-server
  if [[ ${API} -eq 1 ]]; then
    nonce=""$(http_request head ""${CA}"" | grep -i ^Replay-Nonce: | cut -d':' -f2- | tr -d ' \t\n\r')""
  else
    nonce=""$(http_request head ""${CA_NEW_NONCE}"" | grep -i ^Replay-Nonce: | cut -d':' -f2- | tr -d ' \t\n\r')""
  fi

  if [[ ${API} -eq 1 ]]; then
    # Build another header which also contains the previously received nonce and encode it as urlbase64
    protected='{""alg"": ""RS256"", ""jwk"": {""e"": ""'""${pubExponent64}""'"", ""kty"": ""RSA"", ""n"": ""'""${pubMod64}""'""}, ""nonce"": ""'""${nonce}""'""}'
    protected64=""$(printf '%s' ""${protected}"" | urlbase64)""
  else
    # Build another header which also contains the previously received nonce and url and encode it as urlbase64
    if [[ -n ""${ACCOUNT_URL:-}"" ]]; then
      protected='{""alg"": ""'""${account_key_sigalgo}""'"", ""kid"": ""'""${ACCOUNT_URL}""'"", ""url"": ""'""${1}""'"", ""nonce"": ""'""${nonce}""'""}'
    else
      protected='{""alg"": ""'""${account_key_sigalgo}""'"", ""jwk"": '""${account_key_info}""', ""url"": ""'""${1}""'"", ""nonce"": ""'""${nonce}""'""}'
    fi
    protected64=""$(printf '%s' ""${protected}"" | urlbase64)""
  fi

  # Sign header with nonce and our payload with our private key and encode signature as urlbase64
  if [[ ""${account_key_sigalgo}"" = ""RS256"" ]]; then
    signed64=""$(printf '%s' ""${protected64}.${payload64}"" | ""${OPENSSL}"" dgst -sha256 -sign ""${ACCOUNT_KEY}"" | urlbase64)""
  else
    dgstparams=""$(printf '%s' ""${protected64}.${payload64}"" | ""${OPENSSL}"" dgst -sha${account_key_sigalgo:2} -sign ""${ACCOUNT_KEY}"" | ""${OPENSSL}"" asn1parse -inform DER)""
    dgst_parm_1=""$(echo ""$dgstparams"" | head -n 2 | tail -n 1 | cut -d':' -f4)""
    dgst_parm_2=""$(echo ""$dgstparams"" | head -n 3 | tail -n 1 | cut -d':' -f4)""

    # zero-padding (doesn't seem to be necessary, but other clients are doing this as well...
    case ""${account_key_sigalgo}"" in
      ""ES256"") siglen=64;;
      ""ES384"") siglen=96;;
      ""ES512"") siglen=132;;
    esac
    while [[ ${#dgst_parm_1} -lt $siglen ]]; do dgst_parm_1=""0${dgst_parm_1}""; done
    while [[ ${#dgst_parm_2} -lt $siglen ]]; do dgst_parm_2=""0${dgst_parm_2}""; done

    signed64=""$(printf ""%s%s"" ""${dgst_parm_1}"" ""${dgst_parm_2}"" | hex2bin | urlbase64)""
  fi

  if [[ ${API} -eq 1 ]]; then
    # Build header with just our public key and algorithm information
    header='{""alg"": ""RS256"", ""jwk"": {""e"": ""'""${pubExponent64}""'"", ""kty"": ""RSA"", ""n"": ""'""${pubMod64}""'""}}'

    # Send header + extended header + payload + signature to the acme-server
    data='{""header"": '""${header}""', ""protected"": ""'""${protected64}""'"", ""payload"": ""'""${payload64}""'"", ""signature"": ""'""${signed64}""'""}'
  else
    # Send extended header + payload + signature to the acme-server
    data='{""protected"": ""'""${protected64}""'"", ""payload"": ""'""${payload64}""'"", ""signature"": ""'""${signed64}""'""}'
  fi

  http_request post ""${1}"" ""${data}""
}

# Extracts all subject names from a CSR
# Outputs either the CN, or the SANs, one per line
extract_altnames() {
  csr=""${1}"" # the CSR itself (not a file)

  if ! <<<""${csr}"" ""${OPENSSL}"" req -verify -noout 2>/dev/null; then
    _exiterr ""Certificate signing request isn't valid""
  fi

  reqtext=""$( <<<""${csr}"" ""${OPENSSL}"" req -noout -text )""
  if <<<""${reqtext}"" grep -q '^[[:space:]]*X509v3 Subject Alternative Name:[[:space:]]*$'; then
    # SANs used, extract these
    altnames=""$( <<<""${reqtext}"" awk '/X509v3 Subject Alternative Name:/{print;getline;print;}' | tail -n1 )""
    # split to one per line:
    # shellcheck disable=SC1003
    altnames=""$( <<<""${altnames}"" _sed -e 's/^[[:space:]]*//; s/, /\'$'\n''/g' )""
    # we can only get DNS: ones signed
    if grep -qEv '^(DNS|othername):' <<<""${altnames}""; then
      _exiterr ""Certificate signing request contains non-DNS Subject Alternative Names""
    fi
    # strip away the DNS: prefix
    altnames=""$( <<<""${altnames}"" _sed -e 's/^(DNS:|othername:<unsupported>)//' )""
    printf ""%s"" ""${altnames}"" | tr '\n' ' '
  else
    # No SANs, extract CN
    altnames=""$( <<<""${reqtext}"" grep '^[[:space:]]*Subject:' | _sed -e 's/.*[ /]CN ?= ?([^ /,]*).*/\1/' )""
    printf ""%s"" ""${altnames}""
  fi
}

# Get last issuer CN in certificate chain
get_last_cn() {
  <<<""${1}"" _sed 'H;/-----BEGIN CERTIFICATE-----/h;$!d;x' | ""${OPENSSL}"" x509 -noout -issuer | head -n1 | _sed -e 's/.*[ /]CN ?= ?([^/,]*).*/\1/'
}

# Create certificate for domain(s) and outputs it FD 3
sign_csr() {
  csr=""${1}"" # the CSR itself (not a file)

  if { true >&3; } 2>/dev/null; then
    : # fd 3 looks OK
  else
    _exiterr ""sign_csr: FD 3 not open""
  fi

  shift 1 || true
  export altnames=""${*}""

  if [[ ${API} -eq 1 ]]; then
    if [[ -z ""${CA_NEW_AUTHZ}"" ]] || [[ -z ""${CA_NEW_CERT}"" ]]; then
      _exiterr ""Certificate authority doesn't allow certificate signing""
    fi
  elif [[ ${API} -eq 2 ]] && [[ -z ""${CA_NEW_ORDER}"" ]]; then
    _exiterr ""Certificate authority doesn't allow certificate signing""
  fi

  if [[ -n ""${ZSH_VERSION:-}"" ]]; then
    local -A challenge_names challenge_uris challenge_tokens authorizations keyauths deploy_args
  else
    local -a challenge_names challenge_uris challenge_tokens authorizations keyauths deploy_args
  fi

  # Initial step: Find which authorizations we're dealing with
  if [[ ${API} -eq 2 ]]; then
    # Request new order and store authorization URIs
    local challenge_identifiers=""""
    for altname in ${altnames}; do
      challenge_identifiers+=""$(printf '{""type"": ""dns"", ""value"": ""%s""}, ' ""${altname}"")""
    done
    challenge_identifiers=""[${challenge_identifiers%, }]""

    echo "" + Requesting new certificate order from CA...""
    order_location=""$(signed_request ""${CA_NEW_ORDER}"" '{""identifiers"": '""${challenge_identifiers}""'}' 4>&1 | grep -i ^Location: | cut -d':' -f2- | tr -d ' \t\r\n')""
    result=""$(signed_request ""${order_location}"" """" | jsonsh)""

    order_authorizations=""$(echo ""${result}"" | get_json_array_values authorizations)""
    finalize=""$(echo ""${result}"" | get_json_string_value finalize)""

    local idx=0
    for uri in ${order_authorizations}; do
      authorizations[${idx}]=""${uri}""
      idx=$((idx+1))
    done
    echo "" + Received ${idx} authorizations URLs from the CA""
  else
    # Copy $altnames to $authorizations (just doing this to reduce duplicate code later on)
    local idx=0
    for altname in ${altnames}; do
      authorizations[${idx}]=""${altname}""
      idx=$((idx+1))
    done
  fi

  # Check if authorizations are valid and gather challenge information for pending authorizations
  local idx=0
  for authorization in ${authorizations[*]}; do
    if [[ ""${API}"" -eq 2 ]]; then
      # Receive authorization ($authorization is authz uri)
      response=""$(signed_request ""$(echo ""${authorization}"" | _sed -e 's/\""(.*)"".*/\1/')"" """" | jsonsh)""
      identifier=""$(echo ""${response}"" | get_json_string_value -p '""identifier"",""value""')""
      echo "" + Handling authorization for ${identifier}""
    else
      # Request new authorization ($authorization is altname)
      identifier=""${authorization}""
      echo "" + Requesting authorization for ${identifier}...""
      response=""$(signed_request ""${CA_NEW_AUTHZ}"" '{""resource"": ""new-authz"", ""identifier"": {""type"": ""dns"", ""value"": ""'""${identifier}""'""}}' | jsonsh)""
    fi

    # Check if authorization has already been validated
    if [ ""$(echo ""${response}"" | get_json_string_value status)"" = ""valid"" ]; then
      if [ ""${PARAM_FORCE_VALIDATION:-no}"" = ""yes"" ]; then
        echo "" + A valid authorization has been found but will be ignored""
      else
        echo "" + Found valid authorization for ${identifier}""
        continue
      fi
    fi

    # Find challenge in authorization
    challengeindex=""$(echo ""${response}"" | grep -E '^\[""challenges"",[0-9]+,""type""\][[:space:]]+""'""${CHALLENGETYPE}""'""' | cut -d',' -f2 || true)""

    if [ -z ""${challengeindex}"" ]; then
      allowed_validations=""$(echo ""${response}"" | grep -E '^\[""challenges"",[0-9]+,""type""\]' | sed -e 's/\[[^\]*\][[:space:]]*//g' -e 's/^""//' -e 's/""$//' | tr '\n' ' ')""
      _exiterr ""Validating this certificate is not possible using ${CHALLENGETYPE}. Possible validation methods are: ${allowed_validations}""
    fi
    challenge=""$(echo ""${response}"" | get_json_dict_value -p '""challenges"",'""${challengeindex}"")""

    # Gather challenge information
    challenge_names[${idx}]=""${identifier}""
    challenge_tokens[${idx}]=""$(echo ""${challenge}"" | get_json_string_value token)""

    if [[ ${API} -eq 2 ]]; then
      challenge_uris[${idx}]=""$(echo ""${challenge}"" | get_json_string_value url)""
    else
      if [[ ""$(echo ""${challenge}"" | get_json_string_value type)"" = ""urn:acme:error:unauthorized"" ]]; then
        _exiterr ""Challenge unauthorized: $(echo ""${challenge}"" | get_json_string_value detail)""
      fi
      challenge_uris[${idx}]=""$(echo ""${challenge}"" | get_json_dict_value validationRecord | get_json_string_value uri)""
    fi

    # Prepare challenge tokens and deployment parameters
    keyauth=""${challenge_tokens[${idx}]}.${thumbprint}""

    case ""${CHALLENGETYPE}"" in
      ""http-01"")
        # Store challenge response in well-known location and make world-readable (so that a webserver can access it)
        printf '%s' ""${keyauth}"" > ""${WELLKNOWN}/${challenge_tokens[${idx}]}""
        chmod a+r ""${WELLKNOWN}/${challenge_tokens[${idx}]}""
        keyauth_hook=""${keyauth}""
        ;;
      ""dns-01"")
        # Generate DNS entry content for dns-01 validation
        keyauth_hook=""$(printf '%s' ""${keyauth}"" | ""${OPENSSL}"" dgst -sha256 -binary | urlbase64)""
        ;;
      ""tls-alpn-01"")
        keyauth_hook=""$(printf '%s' ""${keyauth}"" | ""${OPENSSL}"" dgst -sha256 -c -hex | awk '{print $NF}')""
        generate_alpn_certificate ""${identifier}"" ""${keyauth_hook}""
        ;;
    esac

    keyauths[${idx}]=""${keyauth}""
    deploy_args[${idx}]=""${identifier} ${challenge_tokens[${idx}]} ${keyauth_hook}"""
dehydrated-2," idx=$((idx+1))
  done
  local num_pending_challenges=${idx}
  echo "" + ${num_pending_challenges} pending challenge(s)""

  # Deploy challenge tokens
  if [[ ${num_pending_challenges} -ne 0 ]]; then
    echo "" + Deploying challenge tokens...""
    if [[ -n ""${HOOK}"" ]] && [[ ""${HOOK_CHAIN}"" = ""yes"" ]]; then
      # shellcheck disable=SC2068
      ""${HOOK}"" ""deploy_challenge"" ${deploy_args[@]} || _exiterr 'deploy_challenge hook returned with non-zero exit code'
    elif [[ -n ""${HOOK}"" ]]; then
      # Run hook script to deploy the challenge token
      local idx=0
      while [ ${idx} -lt ${num_pending_challenges} ]; do
        # shellcheck disable=SC2086
        ""${HOOK}"" ""deploy_challenge"" ${deploy_args[${idx}]} || _exiterr 'deploy_challenge hook returned with non-zero exit code'
        idx=$((idx+1))
      done
    fi
  fi

  # Validate pending challenges
  local idx=0
  while [ ${idx} -lt ${num_pending_challenges} ]; do
    echo "" + Responding to challenge for ${challenge_names[${idx}]} authorization...""

    # Ask the acme-server to verify our challenge and wait until it is no longer pending
    if [[ ${API} -eq 1 ]]; then
      result=""$(signed_request ""${challenge_uris[${idx}]}"" '{""resource"": ""challenge"", ""keyAuthorization"": ""'""${keyauths[${idx}]}""'""}' | jsonsh)""
    else
      result=""$(signed_request ""${challenge_uris[${idx}]}"" '{}' | jsonsh)""
    fi

    reqstatus=""$(echo ""${result}"" | get_json_string_value status)""

    while [[ ""${reqstatus}"" = ""pending"" ]] || [[ ""${reqstatus}"" = ""processing"" ]]; do
      sleep 1
      if [[ ""${API}"" -eq 2 ]]; then
        result=""$(signed_request ""${challenge_uris[${idx}]}"" """" | jsonsh)""
      else
        result=""$(http_request get ""${challenge_uris[${idx}]}"" | jsonsh)""
      fi
      reqstatus=""$(echo ""${result}"" | get_json_string_value status)""
    done

    [[ ""${CHALLENGETYPE}"" = ""http-01"" ]] && rm -f ""${WELLKNOWN}/${challenge_tokens[${idx}]}""
    [[ ""${CHALLENGETYPE}"" = ""tls-alpn-01"" ]] && rm -f ""${ALPNCERTDIR}/${challenge_names[${idx}]}.crt.pem"" ""${ALPNCERTDIR}/${challenge_names[${idx}]}.key.pem""

    if [[ ""${reqstatus}"" = ""valid"" ]]; then
      echo "" + Challenge is valid!""
    else
      [[ -n ""${HOOK}"" ]] && (""${HOOK}"" ""invalid_challenge"" ""${altname}"" ""${result}"" || _exiterr 'invalid_challenge hook returned with non-zero exit code')
      break
    fi
    idx=$((idx+1))
  done

  if [[ ${num_pending_challenges} -ne 0 ]]; then
    echo "" + Cleaning challenge tokens...""

    # Clean challenge tokens using chained hook
    # shellcheck disable=SC2068
    [[ -n ""${HOOK}"" ]] && [[ ""${HOOK_CHAIN}"" = ""yes"" ]] && (""${HOOK}"" ""clean_challenge"" ${deploy_args[@]} || _exiterr 'clean_challenge hook returned with non-zero exit code')

    # Clean remaining challenge tokens if validation has failed
    local idx=0
    while [ ${idx} -lt ${num_pending_challenges} ]; do
      # Delete challenge file
      [[ ""${CHALLENGETYPE}"" = ""http-01"" ]] && rm -f ""${WELLKNOWN}/${challenge_tokens[${idx}]}""
      # Delete alpn verification certificates
      [[ ""${CHALLENGETYPE}"" = ""tls-alpn-01"" ]] && rm -f ""${ALPNCERTDIR}/${challenge_names[${idx}]}.crt.pem"" ""${ALPNCERTDIR}/${challenge_names[${idx}]}.key.pem""
      # Clean challenge token using non-chained hook
      # shellcheck disable=SC2086
      [[ -n ""${HOOK}"" ]] && [[ ""${HOOK_CHAIN}"" != ""yes"" ]] && (""${HOOK}"" ""clean_challenge"" ${deploy_args[${idx}]} || _exiterr 'clean_challenge hook returned with non-zero exit code')
      idx=$((idx+1))
    done

    if [[ ""${reqstatus}"" != ""valid"" ]]; then
      echo "" + Challenge validation has failed :(""
      _exiterr ""Challenge is invalid! (returned: ${reqstatus}) (result: ${result})""
    fi
  fi

  # Finally request certificate from the acme-server and store it in cert-${timestamp}.pem and link from cert.pem
  echo "" + Requesting certificate...""
  csr64=""$( <<<""${csr}"" ""${OPENSSL}"" req -config ""${OPENSSL_CNF}"" -outform DER | urlbase64)""
  if [[ ${API} -eq 1 ]]; then
    crt64=""$(signed_request ""${CA_NEW_CERT}"" '{""resource"": ""new-cert"", ""csr"": ""'""${csr64}""'""}' | ""${OPENSSL}"" base64 -e)""
    crt=""$( printf -- '-----BEGIN CERTIFICATE-----\n%s\n-----END CERTIFICATE-----\n' ""${crt64}"" )""
  else
    result=""$(signed_request ""${finalize}"" '{""csr"": ""'""${csr64}""'""}' | jsonsh)""
    while :; do
      orderstatus=""$(echo ""${result}"" | get_json_string_value status)""
      case ""${orderstatus}""
      in
        ""processing"" | ""pending"")
          echo "" + Order is ${orderstatus}...""
          sleep 2;
          ;;
        ""valid"")
          break;
          ;;
        *)
          _exiterr ""Order in status ${orderstatus}""
          ;;
      esac
      result=""$(signed_request ""${order_location}"" """" | jsonsh)""
    done

    resheaders=""$(_mktemp)""
    certificate=""$(echo ""${result}"" | get_json_string_value certificate)""
    crt=""$(signed_request ""${certificate}"" """" 4>""${resheaders}"")""

    if [ -n ""${PREFERRED_CHAIN:-}"" ]; then
      foundaltchain=0
      altcn=""$(get_last_cn ""${crt}"")""
      altoptions=""${altcn}""
      if [ ""${altcn}"" = ""${PREFERRED_CHAIN}"" ]; then
        foundaltchain=1
      fi
      if [ ""${foundaltchain}"" = ""0"" ] && (grep -Ei '^link:' ""${resheaders}"" | grep -q -Ei 'rel=""alternate""'); then
        while read -r altcrturl; do
          if [ ""${foundaltchain}"" = ""0"" ]; then
            altcrt=""$(signed_request ""${altcrturl}"" """")""
            altcn=""$(get_last_cn ""${altcrt}"")""
            altoptions=""${altoptions}, ${altcn}""
            if [ ""${altcn}"" = ""${PREFERRED_CHAIN}"" ]; then
              foundaltchain=1
              crt=""${altcrt}""
            fi
          fi
        done <<< ""$(grep -Ei '^link:' ""${resheaders}"" | grep -Ei 'rel=""alternate""' | cut -d'<' -f2 | cut -d'>' -f1)""
      fi
      if [ ""${foundaltchain}"" = ""0"" ]; then
        _exiterr ""Alternative chain with CN = ${PREFERRED_CHAIN} not found, available options: ${altoptions}""
      fi
      echo "" + Using preferred chain with CN = ${altcn}""
    fi
    rm -f ""${resheaders}""
  fi

  # Try to load the certificate to detect corruption
  echo "" + Checking certificate...""
  _openssl x509 -text <<<""${crt}""

  echo ""${crt}"" >&3

  unset challenge_token
  echo "" + Done!""
}

# grep issuer cert uri from certificate
get_issuer_cert_uri() {
  certificate=""${1}""
  ""${OPENSSL}"" x509 -in ""${certificate}"" -noout -text | (grep 'CA Issuers - URI:' | cut -d':' -f2-) || true
}

get_issuer_hash() {
  certificate=""${1}""
  ""${OPENSSL}"" x509 -in ""${certificate}"" -noout -issuer_hash
}

get_ocsp_url() {
  certificate=""${1}""
  ""${OPENSSL}"" x509 -in ""${certificate}"" -noout -ocsp_uri
}

# walk certificate chain, retrieving all intermediate certificates
walk_chain() {
  local certificate
  certificate=""${1}""

  local issuer_cert_uri
  issuer_cert_uri=""${2:-}""
  if [[ -z ""${issuer_cert_uri}"" ]]; then issuer_cert_uri=""$(get_issuer_cert_uri ""${certificate}"")""; fi
  if [[ -n ""${issuer_cert_uri}"" ]]; then
    # create temporary files
    local tmpcert
    local tmpcert_raw
    tmpcert_raw=""$(_mktemp)""
    tmpcert=""$(_mktemp)""

    # download certificate
    http_request get ""${issuer_cert_uri}"" > ""${tmpcert_raw}""

    # PEM
    if grep -q ""BEGIN CERTIFICATE"" ""${tmpcert_raw}""; then mv ""${tmpcert_raw}"" ""${tmpcert}""
    # DER
    elif ""${OPENSSL}"" x509 -in ""${tmpcert_raw}"" -inform DER -out ""${tmpcert}"" -outform PEM 2> /dev/null > /dev/null; then :
    # PKCS7
    elif ""${OPENSSL}"" pkcs7 -in ""${tmpcert_raw}"" -inform DER -out ""${tmpcert}"" -outform PEM -print_certs 2> /dev/null > /dev/null; then :
    # Unknown certificate type
    else _exiterr ""Unknown certificate type in chain""
    fi

    local next_issuer_cert_uri
    next_issuer_cert_uri=""$(get_issuer_cert_uri ""${tmpcert}"")""
    if [[ -n ""${next_issuer_cert_uri}"" ]]; then
      printf ""\n%s\n"" ""${issuer_cert_uri}""
      cat ""${tmpcert}""
      walk_chain ""${tmpcert}"" ""${next_issuer_cert_uri}""
    fi
    rm -f ""${tmpcert}"" ""${tmpcert_raw}""
  fi
}

# Generate ALPN verification certificate
generate_alpn_certificate() {
  local altname=""${1}""
  local acmevalidation=""${2}""

  local alpncertdir=""${ALPNCERTDIR}""
  if [[ ! -e ""${alpncertdir}"" ]]; then
    echo "" + Creating new directory ${alpncertdir} ...""
    mkdir -p ""${alpncertdir}"" || _exiterr ""Unable to create directory ${alpncertdir}""
  fi

  echo "" + Generating ALPN certificate and key for ${1}...""
  tmp_openssl_cnf=""$(_mktemp)""
  cat ""${OPENSSL_CNF}"" > ""${tmp_openssl_cnf}""
  printf ""\n[SAN]\nsubjectAltName=DNS:%s\n"" ""${altname}"" >> ""${tmp_openssl_cnf}""
  printf ""1.3.6.1.5.5.7.1.31=critical,DER:04:20:%s\n"" ""${acmevalidation}"" >> ""${tmp_openssl_cnf}""
  SUBJ=""/CN=${altname}/""
  [[ ""${OSTYPE:0:5}"" = ""MINGW"" ]] && SUBJ=""/${SUBJ}""
  _openssl req -x509 -new -sha256 -nodes -newkey rsa:2048 -keyout ""${alpncertdir}/${altname}.key.pem"" -out ""${alpncertdir}/${altname}.crt.pem"" -subj ""${SUBJ}"" -extensions SAN -config ""${tmp_openssl_cnf}""
  chmod g+r ""${alpncertdir}/${altname}.key.pem"" ""${alpncertdir}/${altname}.crt.pem""
  rm -f ""${tmp_openssl_cnf}""
}

# Create certificate for domain(s)
sign_domain() {
  local certdir=""${1}""
  shift
  timestamp=""${1}""
  shift
  domain=""${1}""
  altnames=""${*}""

  export altnames

  echo "" + Signing domains...""
  if [[ ${API} -eq 1 ]]; then
    if [[ -z ""${CA_NEW_AUTHZ}"" ]] || [[ -z ""${CA_NEW_CERT}"" ]]; then
      _exiterr ""Certificate authority doesn't allow certificate signing""
    fi
  elif [[ ${API} -eq 2 ]] && [[ -z ""${CA_NEW_ORDER}"" ]]; then
    _exiterr ""Certificate authority doesn't allow certificate signing""
  fi

  local privkey=""privkey.pem""
  if [[ ! -e ""${certdir}/cert-${timestamp}.csr"" ]]; then
    # generate a new private key if we need or want one
    if [[ ! -r ""${certdir}/privkey.pem"" ]] || [[ ""${PRIVATE_KEY_RENEW}"" = ""yes"" ]]; then
      echo "" + Generating private key...""
      privkey=""privkey-${timestamp}.pem""
      local tmp_privkey
      tmp_privkey=""$(_mktemp)""
      case ""${KEY_ALGO}"" in
        rsa) _openssl genrsa -out ""${tmp_privkey}"" ""${KEYSIZE}"";;
        prime256v1|secp384r1) _openssl ecparam -genkey -name ""${KEY_ALGO}"" -out ""${tmp_privkey}"" -noout;;
      esac
      cat ""${tmp_privkey}"" > ""${certdir}/privkey-${timestamp}.pem""
      rm ""${tmp_privkey}""
    fi
    # move rolloverkey into position (if any)
    if [[ -r ""${certdir}/privkey.pem"" && -r ""${certdir}/privkey.roll.pem"" && ""${PRIVATE_KEY_RENEW}"" = ""yes"" && ""${PRIVATE_KEY_ROLLOVER}"" = ""yes"" ]]; then
      echo "" + Moving Rolloverkey into position....  ""
      mv ""${certdir}/privkey.roll.pem"" ""${certdir}/privkey-tmp.pem""
      mv ""${certdir}/privkey-${timestamp}.pem"" ""${certdir}/privkey.roll.pem""
      mv ""${certdir}/privkey-tmp.pem"" ""${certdir}/privkey-${timestamp}.pem""
    fi
    # generate a new private rollover key if we need or want one
    if [[ ! -r ""${certdir}/privkey.roll.pem"" && ""${PRIVATE_KEY_ROLLOVER}"" = ""yes"" && ""${PRIVATE_KEY_RENEW}"" = ""yes"" ]]; then
      echo "" + Generating private rollover key...""
      case ""${KEY_ALGO}"" in
        rsa) _openssl genrsa -out ""${certdir}/privkey.roll.pem"" ""${KEYSIZE}"";;
        prime256v1|secp384r1) _openssl ecparam -genkey -name ""${KEY_ALGO}"" -out ""${certdir}/privkey.roll.pem"" -noout;;
      esac
    fi
    # delete rolloverkeys if disabled
    if [[ -r ""${certdir}/privkey.roll.pem"" && ! ""${PRIVATE_KEY_ROLLOVER}"" = ""yes"" ]]; then
      echo "" + Removing Rolloverkey (feature disabled)...""
      rm -f ""${certdir}/privkey.roll.pem""
    fi

    # Generate signing request config and the actual signing request
    echo "" + Generating signing request...""
    SAN=""""
    for altname in ${altnames}; do
      SAN=""${SAN}DNS:${altname}, ""
    done
    SAN=""${SAN%%, }""
    local tmp_openssl_cnf
    tmp_openssl_cnf=""$(_mktemp)""
    cat ""${OPENSSL_CNF}"" > ""${tmp_openssl_cnf}""
    printf ""\n[SAN]\nsubjectAltName=%s"" ""${SAN}"" >> ""${tmp_openssl_cnf}""
    if [ ""${OCSP_MUST_STAPLE}"" = ""yes"" ]; then
      printf ""\n1.3.6.1.5.5.7.1.24=DER:30:03:02:01:05"" >> ""${tmp_openssl_cnf}""
    fi
    SUBJ=""/CN=${domain}/""
    if [[ ""${OSTYPE:0:5}"" = ""MINGW"" ]]; then
      # The subject starts with a /, so MSYS will assume it's a path and convert
      # it unless we escape it with another one:
      SUBJ=""/${SUBJ}""
    fi
    ""${OPENSSL}"" req -new -sha256 -key ""${certdir}/${privkey}"" -out ""${certdir}/cert-${timestamp}.csr"" -subj ""${SUBJ}"" -reqexts SAN -config ""${tmp_openssl_cnf}""
    rm -f ""${tmp_openssl_cnf}""
  fi

  crt_path=""${certdir}/cert-${timestamp}.pem""
  # shellcheck disable=SC2086
  sign_csr ""$(< ""${certdir}/cert-${timestamp}.csr"")"" ${altnames} 3>""${crt_path}""

  # Create fullchain.pem
  echo "" + Creating fullchain.pem...""
  if [[ ${API} -eq 1 ]]; then
    cat ""${crt_path}"" > ""${certdir}/fullchain-${timestamp}.pem""
    local issuer_hash
    issuer_hash=""$(get_issuer_hash ""${crt_path}"")""
    if [ -e ""${CHAINCACHE}/${issuer_hash}.chain"" ]; then
      echo "" + Using cached chain!""
      cat ""${CHAINCACHE}/${issuer_hash}.chain"" > ""${certdir}/chain-${timestamp}.pem""
    else
      echo "" + Walking chain...""
      local issuer_cert_uri
      issuer_cert_uri=""$(get_issuer_cert_uri ""${crt_path}"" || echo ""unknown"")""
      (walk_chain ""${crt_path}"" > ""${certdir}/chain-${timestamp}.pem"") || _exiterr ""Walking chain has failed, your certificate has been created and can be found at ${crt_path}, the corresponding private key at ${privkey}. If you want you can manually continue on creating and linking all necessary files. If this error occurs again you should manually generate the certificate chain and place it under ${CHAINCACHE}/${issuer_hash}.chain (see ${issuer_cert_uri})""
      cat ""${certdir}/chain-${timestamp}.pem"" > ""${CHAINCACHE}/${issuer_hash}.chain""
    fi
    cat ""${certdir}/chain-${timestamp}.pem"" >> ""${certdir}/fullchain-${timestamp}.pem""
  else
    tmpcert=""$(_mktemp)""
    tmpchain=""$(_mktemp)""
    awk '{print >out}; /----END CERTIFICATE-----/{out=tmpchain}' out=""${tmpcert}"" tmpchain=""${tmpchain}"" ""${certdir}/cert-${timestamp}.pem""
    mv ""${certdir}/cert-${timestamp}.pem"" ""${certdir}/fullchain-${timestamp}.pem""
    cat ""${tmpcert}"" > ""${certdir}/cert-${timestamp}.pem""
    cat ""${tmpchain}"" > ""${certdir}/chain-${timestamp}.pem""
    rm ""${tmpcert}"" ""${tmpchain}""
  fi

  # Wait for hook script to sync the files before creating the symlinks
  [[ -n ""${HOOK}"" ]] && (""${HOOK}"" ""sync_cert"" ""${certdir}/privkey-${timestamp}.pem"" ""${certdir}/cert-${timestamp}.pem"" ""${certdir}/fullchain-${timestamp}.pem"" ""${certdir}/chain-${timestamp}.pem"" ""${certdir}/cert-${timestamp}.csr"" || _exiterr 'sync_cert hook returned with non-zero exit code')

  # Update symlinks
  [[ ""${privkey}"" = ""privkey.pem"" ]] || ln -sf ""privkey-${timestamp}.pem"" ""${certdir}/privkey.pem""

  ln -sf ""chain-${timestamp}.pem"" ""${certdir}/chain.pem""
  ln -sf ""fullchain-${timestamp}.pem"" ""${certdir}/fullchain.pem""
  ln -sf ""cert-${timestamp}.csr"" ""${certdir}/cert.csr""
  ln -sf ""cert-${timestamp}.pem"" ""${certdir}/cert.pem""

  # Wait for hook script to clean the challenge and to deploy cert if used
  [[ -n ""${HOOK}"" ]] && (""${HOOK}"" ""deploy_cert"" ""${domain}"" ""${certdir}/privkey.pem"" ""${certdir}/cert.pem"" ""${certdir}/fullchain.pem"" ""${certdir}/chain.pem"" ""${timestamp}"" || _exiterr 'deploy_cert hook returned with non-zero exit code')

  unset challenge_token
  echo "" + Done!""
}

# Usage: --version (-v)
# Description: Print version information
command_version() {
  load_config noverify

  echo ""Dehydrated by Lukas Schauer""
  echo ""https://dehydrated.io""
  echo """"
  echo ""Dehydrated version: ${VERSION}""
  revision=""$(cd ""${SCRIPTDIR}""; git rev-parse HEAD 2>/dev/null || echo ""unknown"")""
  echo ""GIT-Revision: ${revision}""
  echo """"
  # shellcheck disable=SC1091
  if [[ ""${OSTYPE}"" =~ (BSD|Darwin) ]]; then
    echo ""OS: $(uname -sr)""
  elif [[ -e /etc/os-release ]]; then
    ( . /etc/os-release && echo ""OS: $PRETTY_NAME"" )
  elif [[ -e /usr/lib/os-release ]]; then
    ( . /usr/lib/os-release && echo ""OS: $PRETTY_NAME"" )
  else
    echo ""OS: $(grep -v '^$' /etc/issue | head -n1 | _sed 's/\\(r|n|l) .*//g')""
  fi
  echo ""Used software:""
  [[ -n ""${BASH_VERSION:-}"" ]] && echo "" bash: ${BASH_VERSION}""
  [[ -n ""${ZSH_VERSION:-}"" ]] && echo "" zsh: ${ZSH_VERSION}""
  echo "" curl: ${CURL_VERSION}""
  if [[ ""${OSTYPE}"" =~ (BSD|Darwin) ]]; then
    echo "" awk, sed, mktemp, grep, diff: BSD base system versions""
  else
    echo "" awk: $(awk -W version 2>&1 | head -n1)""
    echo "" sed: $(sed --version 2>&1 | head -n1)""
    echo "" mktemp: $(mktemp --version 2>&1 | head -n1)""
    echo "" grep: $(grep --version 2>&1 | head -n1)""
    echo "" diff: $(diff --version 2>&1 | head -n1)""
  fi
  echo "" openssl: $(""${OPENSSL}"" version 2>&1)""

  exit 0
}

# Usage: --display-terms
# Description: Display current terms of service
command_terms() {
  init_system
  echo ""The current terms of service: $CA_TERMS""
  echo ""+ Done!""
  exit 0
}

# Usage: --register
# Description: Register account key
command_register() {
  init_system
  echo ""+ Done!""
  exit 0
}

# Usage: --account
# Description: Update account contact information
command_account() {
  init_system
  FAILED=false

  NEW_ACCOUNT_KEY_JSON=""$(_mktemp)""

  # Check if we have the registration url
  if [[ -z ""${ACCOUNT_URL}"" ]]; then
    _exiterr ""Error retrieving registration url.""
  fi

  echo ""+ Updating registration url: ${ACCOUNT_URL} contact information...""
  if [[ ${API} -eq 1 ]]; then
    # If an email for the contact has been provided then adding it to the registered account
    if [[ -n ""${CONTACT_EMAIL}"" ]]; then
      (signed_request ""${ACCOUNT_URL}"" '{""resource"": ""reg"", ""contact"":[""mailto:'""${CONTACT_EMAIL}""'""]}' > ""${NEW_ACCOUNT_KEY_JSON}"") || FAILED=true
    else
      (signed_request ""${ACCOUNT_URL}"" '{""resource"": ""reg"", ""contact"":[]}' > ""${NEW_ACCOUNT_KEY_JSON}"") || FAILED=true
    fi
  else
    # If an email for the contact has been provided then adding it to the registered account
    if [[ -n ""${CONTACT_EMAIL}"" ]]; then
      (signed_request ""${ACCOUNT_URL}"" '{""contact"":[""mailto:'""${CONTACT_EMAIL}""'""]}' > ""${NEW_ACCOUNT_KEY_JSON}"") || FAILED=true
    else
      (signed_request ""${ACCOUNT_URL}"" '{""contact"":[]}' > ""${NEW_ACCOUNT_KEY_JSON}"") || FAILED=true
    fi
  fi

  if [[ ""${FAILED}"" = ""true"" ]]; then
    rm ""${NEW_ACCOUNT_KEY_JSON}""
    _exiterr ""Error updating account information. See message above for more information.""
  fi
  if diff -q ""${NEW_ACCOUNT_KEY_JSON}"" ""${ACCOUNT_KEY_JSON}"" > /dev/null; then
    echo ""+ Account information was the same after the update""
    rm ""${NEW_ACCOUNT_KEY_JSON}""
  else
    ACCOUNT_KEY_JSON_BACKUP=""${ACCOUNT_KEY_JSON%.*}-$(date +%s).json""
    echo ""+ Backup ${ACCOUNT_KEY_JSON} as ${ACCOUNT_KEY_JSON_BACKUP}""
    cp -p ""${ACCOUNT_KEY_JSON}"" ""${ACCOUNT_KEY_JSON_BACKUP}""
    echo ""+ Populate ${ACCOUNT_KEY_JSON}""
    mv ""${NEW_ACCOUNT_KEY_JSON}"" ""${ACCOUNT_KEY_JSON}""
  fi
  echo ""+ Done!""
  exit 0
}

# Parse contents of domains.txt and domains.txt.d
parse_domains_txt() {
  # Allow globbing temporarily
  noglob_set
  local inputs=(""${DOMAINS_TXT}"" ""${DOMAINS_TXT}.d""/*.txt)
  noglob_clear

  cat ""${inputs[@]}"" |
    tr -d '\r' |
    awk '{print tolower($0)}' |
    _sed -e 's/^[[:space:]]*//g' -e 's/[[:space:]]*$//g' -e 's/[[:space:]]+/ /g' -e 's/([^ ])>/\1 >/g' -e 's/> />/g' |
    (grep -vE '^(#|$)' || true)
}

# Usage: --cron (-c)
# Description: Sign/renew non-existent/changed/expiring certificates.
command_sign_domains() {
  init_system
  hookscript_bricker_hook

  # Call startup hook
  [[ -n ""${HOOK}"" ]] && (""${HOOK}"" ""startup_hook"" || _exiterr 'startup_hook hook returned with non-zero exit code')

  if [ ! -d ""${CHAINCACHE}"" ]; then
    echo "" + Creating chain cache directory ${CHAINCACHE}""
    mkdir ""${CHAINCACHE}""
  fi

  if [[ -n ""${PARAM_DOMAIN:-}"" ]]; then
    DOMAINS_TXT=""$(_mktemp)""
    if [[ -n ""${PARAM_ALIAS:-}"" ]]; then
      printf ""%s > %s"" ""${PARAM_DOMAIN}"" ""${PARAM_ALIAS}"" > ""${DOMAINS_TXT}""
    else
      printf ""%s"" ""${PARAM_DOMAIN}"" > ""${DOMAINS_TXT}""
    fi
  elif [[ -e ""${DOMAINS_TXT}"" ]]; then
    if [[ ! -r ""${DOMAINS_TXT}"" ]]; then
      _exiterr ""domains.txt found but not readable""
    fi
  else
    _exiterr ""domains.txt not found and --domain not given""
  fi

  # Generate certificates for all domains found in domains.txt. Check if existing certificate are about to expire
  ORIGIFS=""${IFS}""
  IFS=$'\n'
  for line in $(parse_domains_txt); do
    reset_configvars
    IFS=""${ORIGIFS}""
    alias=""$(grep -Eo '>[^ ]+' <<< ""${line}"" || true)""
    line=""$(_sed -e 's/>[^ ]+[ ]*//g' <<< ""${line}"")""
    aliascount=""$(grep -Eo '>' <<< ""${alias}"" | awk 'END {print NR}' || true )""
    [ ""${aliascount}"" -gt 1 ] && _exiterr ""Only one alias per line is allowed in domains.txt!""

    domain=""$(printf '%s\n' ""${line}"" | cut -d' ' -f1)""
    morenames=""$(printf '%s\n' ""${line}"" | cut -s -d' ' -f2-)""
    [ ""${aliascount}"" -lt 1 ] && alias=""${domain}"" || alias=""${alias#>}""
    export alias

    if [[ -z ""${morenames}"" ]];then
      echo ""Processing ${domain}""
    else
      echo ""Processing ${domain} with alternative names: ${morenames}""
    fi

    if [ ""${alias:0:2}"" = ""*."" ]; then
      _exiterr ""Please define a valid alias for your ${domain} wildcard-certificate. See domains.txt-documentation for more details.""
    fi

    local certdir=""${CERTDIR}/${alias}""
    cert=""${certdir}/cert.pem""
    chain=""${certdir}/chain.pem""

    force_renew=""${PARAM_FORCE:-no}""

    timestamp=""$(date +%s)""

    # If there is no existing certificate directory => make it
    if [[ ! -e ""${certdir}"" ]]; then
      echo "" + Creating new directory ${certdir} ...""
      mkdir -p ""${certdir}"" || _exiterr ""Unable to create directory ${certdir}""
    fi

    # read cert config
    # for now this loads the certificate specific config in a subshell and parses a diff of set variables.
    # we could just source the config file but i decided to go this way to protect people from accidentally overriding
    # variables used internally by this script itself.
    if [[ -n ""${DOMAINS_D}"" ]]; then
      certconfig=""${DOMAINS_D}/${alias}""
    else
      certconfig=""${certdir}/config""
    fi

    if [ -f ""${certconfig}"" ]; then
      echo "" + Using certificate specific config file!""
      ORIGIFS=""${IFS}""
      IFS=$'\n'
      for cfgline in $(
        beforevars=""$(_mktemp)""
        aftervars=""$(_mktemp)""
        set > ""${beforevars}""
        # shellcheck disable=SC1090
        . ""${certconfig}""
        set > ""${aftervars}""
        diff -u ""${beforevars}"" ""${aftervars}"" | grep -E '^\+[^+]'
        rm ""${beforevars}""
        rm ""${aftervars}""
      ); do
        config_var=""$(echo ""${cfgline:1}"" | cut -d'=' -f1)""
        config_value=""$(echo ""${cfgline:1}"" | cut -d'=' -f2- | tr -d ""'"")""
	# All settings that are allowed here should also be stored and
	# restored in store_configvars() and reset_configvars()
        case ""${config_var}"" in
          KEY_ALGO|OCSP_MUST_STAPLE|OCSP_FETCH|OCSP_DAYS|PRIVATE_KEY_RENEW|PRIVATE_KEY_ROLLOVER|KEYSIZE|CHALLENGETYPE|HOOK|PREFERRED_CHAIN|WELLKNOWN|HOOK_CHAIN|OPENSSL_CNF|RENEW_DAYS)
            echo ""   + ${config_var} = ${config_value}""
            declare -- ""${config_var}=${config_value}""
            ;;
          _) ;;
          *) echo ""   ! Setting ${config_var} on a per-certificate base is not (yet) supported"" >&2
        esac
      done
      IFS=""${ORIGIFS}""
    fi
    verify_config
    hookscript_bricker_hook
    export WELLKNOWN CHALLENGETYPE KEY_ALGO PRIVATE_KEY_ROLLOVER

    skip=""no""

    # Allow for external CSR generation
    local csr=""""
    if [[ -n ""${HOOK}"" ]]; then
      csr=""$(""${HOOK}"" ""generate_csr"" ""${domain}"" ""${certdir}"" ""${domain} ${morenames}"")"" || _exiterr 'generate_csr hook returned with non-zero exit code'
      if grep -qE ""\-----BEGIN (NEW )?CERTIFICATE REQUEST-----"" <<< ""${csr}""; then
        altnames=""$(extract_altnames ""${csr}"")""
        domain=""$(cut -d' ' -f1 <<< ""${altnames}"")""
        morenames=""$(cut -s -d' ' -f2- <<< ""${altnames}"")""
        echo "" + Using CSR from hook script (real names: ${altnames})""
      else
        csr=""""
      fi
    fi

    # Check domain names of existing certificate
    if [[ -e ""${cert}"" && ""${force_renew}"" = ""no"" ]]; then
      printf "" + Checking domain name(s) of existing cert...""

      certnames=""$(""${OPENSSL}"" x509 -in ""${cert}"" -text -noout | grep DNS: | _sed 's/DNS://g' | tr -d ' ' | tr ',' '\n' | sort -u | tr '\n' ' ' | _sed 's/ $//')""
      givennames=""$(echo ""${domain}"" ""${morenames}""| tr ' ' '\n' | sort -u | tr '\n' ' ' | _sed 's/ $//' | _sed 's/^ //')""

      if [[ ""${certnames}"" = ""${givennames}"" ]]; then
        echo "" unchanged.""
      else
        echo "" changed!""
        echo "" + Domain name(s) are not matching!""
        echo "" + Names in old certificate: ${certnames}""
        echo "" + Configured names: ${givennames}""
        echo "" + Forcing renew.""
        force_renew=""yes""
      fi
    fi

    # Check expire date of existing certificate
    if [[ -e ""${cert}"" ]]; then
      echo "" + Checking expire date of existing cert...""
      valid=""$(""${OPENSSL}"" x509 -enddate -noout -in ""${cert}"" | cut -d= -f2- )""

      printf "" + Valid till %s "" ""${valid}""
      if (""${OPENSSL}"" x509 -checkend $((RENEW_DAYS * 86400)) -noout -in ""${cert}"" > /dev/null 2>&1); then
        printf ""(Longer than %d days). "" ""${RENEW_DAYS}""
        if [[ ""${force_renew}"" = ""yes"" ]]; then
          echo ""Ignoring because renew was forced!""
        else
          # Certificate-Names unchanged and cert is still valid
          echo ""Skipping renew!""
          [[ -n ""${HOOK}"" ]] && (""${HOOK}"" ""unchanged_cert"" ""${domain}"" ""${certdir}/privkey.pem"" ""${certdir}/cert.pem"" ""${certdir}/fullchain.pem"" ""${certdir}/chain.pem"" || _exiterr 'unchanged_cert hook returned with non-zero exit code')
          skip=""yes""
        fi
      else
        echo ""(Less than ${RENEW_DAYS} days). Renewing!""
      fi
    fi

    local update_ocsp
    update_ocsp=""no""

    # Sign certificate for this domain
    if [[ ! ""${skip}"" = ""yes"" ]]; then
      update_ocsp=""yes""
      [[ -z ""${csr}"" ]] || printf ""%s"" ""${csr}"" > ""${certdir}/cert-${timestamp}.csr""
      # shellcheck disable=SC2086
      if [[ ""${PARAM_KEEP_GOING:-}"" = ""yes"" ]]; then
        skip_exit_hook=yes
        sign_domain ""${certdir}"" ""${timestamp}"" ""${domain}"" ${morenames} &
        wait $! || exit_with_errorcode=1
        skip_exit_hook=no
      else
        sign_domain ""${certdir}"" ""${timestamp}"" ""${domain}"" ${morenames}
      fi
    fi

    if [[ ""${OCSP_FETCH}"" = ""yes"" ]]; then
      local ocsp_url
      ocsp_url=""$(get_ocsp_url ""${cert}"")""

      if [[ ! -e ""${certdir}/ocsp.der"" ]]; then
        update_ocsp=""yes""
      elif ! (""${OPENSSL}"" ocsp -no_nonce -issuer ""${chain}"" -verify_other ""${chain}"" -cert ""${cert}"" -respin ""${certdir}/ocsp.der"" -status_age $((OCSP_DAYS*24*3600)) 2>&1 | grep -q ""${cert}: good""); then
        update_ocsp=""yes""
      fi

      if [[ ""${update_ocsp}"" = ""yes"" ]]; then
        echo "" + Updating OCSP stapling file""
        ocsp_timestamp=""$(date +%s)""
        if grep -qE ""^(openssl (0|(1\.0))\.)|(libressl (1|2|3)\.)"" <<< ""$(${OPENSSL} version | awk '{print tolower($0)}')""; then
          ocsp_log=""$(""${OPENSSL}"" ocsp -no_nonce -issuer ""${chain}"" -verify_other ""${chain}"" -cert ""${cert}"" -respout ""${certdir}/ocsp-${ocsp_timestamp}.der"" -url ""${ocsp_url}"" -header ""HOST"" ""$(echo ""${ocsp_url}"" | _sed -e 's/^http(s?):\/\///' -e 's/\/.*$//g')"" 2>&1)"" || _exiterr ""Error while fetching OCSP information: ${ocsp_log}""
        else
          ocsp_log=""$(""${OPENSSL}"" ocsp -no_nonce -issuer ""${chain}"" -verify_other ""${chain}"" -cert ""${cert}"" -respout ""${certdir}/ocsp-${ocsp_timestamp}.der"" -url ""${ocsp_url}"" 2>&1)"" || _exiterr ""Error while fetching OCSP information: ${ocsp_log}""
        fi
        ln -sf ""ocsp-${ocsp_timestamp}.der"" ""${certdir}/ocsp.der""
        [[ -n ""${HOOK}"" ]] && (altnames=""${domain} ${morenames}"" ""${HOOK}"" ""deploy_ocsp"" ""${domain}"" ""${certdir}/ocsp.der"" ""${ocsp_timestamp}"" || _exiterr 'deploy_ocsp hook returned with non-zero exit code')
      else
        echo "" + OCSP stapling file is still valid (skipping update)""
      fi
    fi
  done
  reset_configvars

  # remove temporary domains.txt file if used
  [[ -n ""${PARAM_DOMAIN:-}"" ]] && rm -f ""${DOMAINS_TXT}""

  [[ -n ""${HOOK}"" ]] && (""${HOOK}"" ""exit_hook"" || echo 'exit_hook returned with non-zero exit code!' >&2)
  if [[ ""${AUTO_CLEANUP}"" == ""yes"" ]]; then
    echo ""+ Running automatic cleanup""
    command_cleanup noinit
  fi

  exit ""${exit_with_errorcode}""
}

# Usage: --signcsr (-s) path/to/csr.pem
# Description: Sign a given CSR, output CRT on stdout (advanced usage)
command_sign_csr() {
  init_system

  # redirect stdout to stderr
  # leave stdout over at fd 3 to output the cert
  exec 3>&1 1>&2

  # load csr
  csrfile=""${1}""
  if [ ! -r ""${csrfile}"" ]; then
    _exiterr ""Could not read certificate signing request ${csrfile}""
  fi
  csr=""$(cat ""${csrfile}"")""

  # extract names
  altnames=""$(extract_altnames ""${csr}"")""

  # gen cert
  certfile=""$(_mktemp)""
  # shellcheck disable=SC2086
  sign_csr ""${csr}"" ${altnames} 3> ""${certfile}""

  # print cert
  echo ""# CERT #"" >&3
  cat ""${certfile}"" >&3
  echo >&3

  # print chain
  if [ -n ""${PARAM_FULL_CHAIN:-}"" ]; then
    # get and convert ca cert
    chainfile=""$(_mktemp)""
    tmpchain=""$(_mktemp)""
    http_request get ""$(""${OPENSSL}"" x509 -in ""${certfile}"" -noout -text | grep 'CA Issuers - URI:' | cut -d':' -f2-)"" > ""${tmpchain}""
    if grep -q ""BEGIN CERTIFICATE"" ""${tmpchain}""; then
      mv ""${tmpchain}"" ""${chainfile}""
    else
      ""${OPENSSL}"" x509 -in ""${tmpchain}"" -inform DER -out ""${chainfile}"" -outform PEM
      rm ""${tmpchain}""
    fi

    echo ""# CHAIN #"" >&3
    cat ""${chainfile}"" >&3

    rm ""${chainfile}""
  fi

  # cleanup
  rm ""${certfile}""

  exit 0
}

# Usage: --revoke (-r) path/to/cert.pem
# Description: Revoke specified certificate
command_revoke() {
  init_system

  [[ -n ""${CA_REVOKE_CERT}"" ]] || _exiterr ""Certificate authority doesn't allow certificate revocation.""

  cert=""${1}""
  if [[ -L ""${cert}"" ]]; then
    # follow symlink and use real certificate name (so we move the real file and not the symlink at the end)
    local link_target
    link_target=""$(readlink -n ""${cert}"")""
    if [[ ""${link_target}"" =~ ^/ ]]; then
      cert=""${link_target}""
    else
      cert=""$(dirname ""${cert}"")/${link_target}""
    fi
  fi
  [[ -f ""${cert}"" ]] || _exiterr ""Could not find certificate ${cert}""

  echo ""Revoking ${cert}""

  cert64=""$(""${OPENSSL}"" x509 -in ""${cert}"" -inform PEM -outform DER | urlbase64)""
  if [[ ${API} -eq 1 ]]; then
    response=""$(signed_request ""${CA_REVOKE_CERT}"" '{""resource"": ""revoke-cert"", ""certificate"": ""'""${cert64}""'""}' | clean_json)""
  else
    response=""$(signed_request ""${CA_REVOKE_CERT}"" '{""certificate"": ""'""${cert64}""'""}' | clean_json)""
  fi
  # if there is a problem with our revoke request _request (via signed_request) will report this and ""exit 1"" out
  # so if we are here, it is safe to assume the request was successful
  echo "" + Done.""
  echo "" + Renaming certificate to ${cert}-revoked""
  mv -f ""${cert}"" ""${cert}-revoked""
}

# Usage: --deactivate
# Description: Deactivate account
command_deactivate() {
  init_system

  echo ""Deactivating account ${ACCOUNT_URL}""

  if [[ ${API} -eq 1 ]]; then
    echo ""Deactivation for ACMEv1 is not implemented""
  else
    response=""$(signed_request ""${ACCOUNT_URL}"" '{""status"": ""deactivated""}' | clean_json)""
    deactstatus=$(echo ""$response"" | jsonsh | get_json_string_value ""status"")
    if [[ ""${deactstatus}"" = ""deactivated"" ]]; then
      touch ""${ACCOUNT_DEACTIVATED}""
    else
      _exiterr ""Account deactivation failed!""
    fi
  fi

  echo "" + Done.""
}

# Usage: --cleanup (-gc)
# Description: Move unused certificate files to archive directory
command_cleanup() {
  if [ ! ""${1:-}"" = ""noinit"" ]; then
    load_config
  fi

  if [[ ! ""${PARAM_CLEANUPDELETE:-}"" = ""yes"" ]]; then
    # Create global archive directory if not existent
    if [[ ! -e ""${BASEDIR}/archive"" ]]; then
      mkdir ""${BASEDIR}/archive""
    fi
  fi

  # Allow globbing
  noglob_set

  # Loop over all certificate directories
  for certdir in ""${CERTDIR}/""*; do
    # Skip if entry is not a folder
    [[ -d ""${certdir}"" ]] || continue

    # Get certificate name
    certname=""$(basename ""${certdir}"")""

    # Create certificates archive directory if not existent
    if [[ ! ""${PARAM_CLEANUPDELETE:-}"" = ""yes"" ]]; then
      archivedir=""${BASEDIR}/archive/${certname}""
      if [[ ! -e ""${archivedir}"" ]]; then
        mkdir ""${archivedir}""
      fi
    fi

    # Loop over file-types (certificates, keys, signing-requests, ...)
    for filetype in cert.csr cert.pem chain.pem fullchain.pem privkey.pem ocsp.der; do
      # Delete all if symlink is broken
      if [[ -r ""${certdir}/${filetype}"" ]]; then
        # Look up current file in use
        current=""$(basename ""$(readlink ""${certdir}/${filetype}"")"")""
      else
        if [[ -h ""${certdir}/${filetype}"" ]]; then
          echo ""Removing broken symlink: ${certdir}/${filetype}""
          rm -f ""${certdir}/${filetype}""
        fi
        current=""""
      fi

      # Split filetype into name and extension
      filebase=""$(echo ""${filetype}"" | cut -d. -f1)""
      fileext=""$(echo ""${filetype}"" | cut -d. -f2)""

      # Loop over all files of this type
      for file in ""${certdir}/${filebase}-""*"".${fileext}"" ""${certdir}/${filebase}-""*"".${fileext}-revoked""; do
        # Check if current file is in use, if unused move to archive directory
        filename=""$(basename ""${file}"")""
        if [[ ! ""${filename}"" = ""${current}"" ]] && [[ -f ""${certdir}/${filename}"" ]]; then
          if [[ ""${PARAM_CLEANUPDELETE:-}"" = ""yes"" ]]; then
            echo ""Deleting unused file: ${certname}/${filename}""
            rm ""${certdir}/${filename}""
          else
            echo ""Moving unused file to archive directory: ${certname}/${filename}""
            mv ""${certdir}/${filename}"" ""${archivedir}/${filename}""
          fi
        fi
      done
    done
  done

  exit ""${exit_with_errorcode}""
}

# Usage: --cleanup-delete (-gcd)
# Description: Deletes (!) unused certificate files
command_cleanupdelete() {
  command_cleanup
}


# Usage: --help (-h)
# Description: Show help text
command_help() {
  printf ""Usage: %s [-h] [command [argument]] [parameter [argument]] [parameter [argument]] ...\n\n"" ""${0}""
  printf ""Default command: help\n\n""
  echo ""Commands:""
  grep -e '^[[:space:]]*# Usage:' -e '^[[:space:]]*# Description:' -e '^command_.*()[[:space:]]*{' ""${0}"" | while read -r usage; read -r description; read -r command; do
    if [[ ! ""${usage}"" =~ Usage ]] || [[ ! ""${description}"" =~ Description ]] || [[ ! ""${command}"" =~ ^command_ ]]; then
      _exiterr ""Error generating help text.""
    fi
    printf "" %-32s %s\n"" ""${usage##""# Usage: ""}"" ""${description##""# Description: ""}""
  done
  printf -- ""\nParameters:\n""
  grep -E -e '^[[:space:]]*# PARAM_Usage:' -e '^[[:space:]]*# PARAM_Description:' ""${0}"" | while read -r usage; read -r description; do
    if [[ ! ""${usage}"" =~ Usage ]] || [[ ! ""${description}"" =~ Description ]]; then
      _exiterr ""Error generating help text.""
    fi
    printf "" %-32s %s\n"" ""${usage##""# PARAM_Usage: ""}"" ""${description##""# PARAM_Description: ""}""
  done
}

# Usage: --env (-e)
# Description: Output configuration variables for use in other scripts
command_env() {
  echo ""# dehydrated configuration""
  load_config
  typeset -p CA CERTDIR ALPNCERTDIR CHALLENGETYPE DOMAINS_D DOMAINS_TXT HOOK HOOK_CHAIN RENEW_DAYS ACCOUNT_KEY ACCOUNT_KEY_JSON ACCOUNT_ID_JSON KEYSIZE WELLKNOWN PRIVATE_KEY_RENEW OPENSSL_CNF CONTACT_EMAIL LOCKFILE
}

# Main method (parses script arguments and calls command_* methods)
main() {
  exit_with_errorcode=0
  skip_exit_hook=no
  COMMAND=""""
  set_command() {
    [[ -z ""${COMMAND}"" ]] || _exiterr ""Only one command can be executed at a time. See help (-h) for more information.""
    COMMAND=""${1}""
  }

  check_parameters() {
    if [[ -z ""${1:-}"" ]]; then
      echo ""The specified command requires additional parameters. See help:"" >&2
      echo >&2
      command_help >&2
      exit 1
    elif [[ ""${1:0:1}"" = ""-"" ]]; then
      _exiterr ""Invalid argument: ${1}""
    fi
  }

  [[ -z ""${*}"" ]] && eval set -- ""--help""

  while (( ${#} )); do
    case ""${1}"" in
      --help|-h)
        command_help
        exit 0
        ;;

      --env|-e)
        set_command env
        ;;

      --cron|-c)
        set_command sign_domains
        ;;

      --register)
        set_command register
        ;;

      --account)
        set_command account
        ;;

      # PARAM_Usage: --accept-terms
      # PARAM_Description: Accept CAs terms of service
      --accept-terms)
        PARAM_ACCEPT_TERMS=""yes""
        ;;

      --display-terms)
        set_command terms
        ;;

      --signcsr|-s)
        shift 1
        set_command sign_csr
        check_parameters ""${1:-}""
        PARAM_CSR=""${1}""
        ;;

      --revoke|-r)
        shift 1
        set_command revoke
        check_parameters ""${1:-}""
        PARAM_REVOKECERT=""${1}""
        ;;

      --deactivate)
        set_command deactivate
        ;;

      --version|-v)
        set_command version
        ;;

      --cleanup|-gc)
        set_command cleanup
        ;;

      --cleanup-delete|-gcd)
        set_command cleanupdelete
        PARAM_CLEANUPDELETE=""yes""
        ;;

      # PARAM_Usage: --full-chain (-fc)
      # PARAM_Description: Print full chain when using --signcsr
      --full-chain|-fc)
        PARAM_FULL_CHAIN=""1""
        ;;

      # PARAM_Usage: --ipv4 (-4)
      # PARAM_Description: Resolve names to IPv4 addresses only
      --ipv4|-4)
        PARAM_IP_VERSION=""4""
        ;;

      # PARAM_Usage: --ipv6 (-6)
      # PARAM_Description: Resolve names to IPv6 addresses only
      --ipv6|-6)
        PARAM_IP_VERSION=""6""
        ;;

      # PARAM_Usage: --domain (-d) domain.tld
      # PARAM_Description: Use specified domain name(s) instead of domains.txt entry (one certificate!)
      --domain|-d)
        shift 1
        check_parameters ""${1:-}""
        if [[ -z ""${PARAM_DOMAIN:-}"" ]]; then
          PARAM_DOMAIN=""${1}""
        else
          PARAM_DOMAIN=""${PARAM_DOMAIN} ${1}""
         fi
        ;;

      # PARAM_Usage: --ca url/preset
      # PARAM_Description: Use specified CA URL or preset
      --ca)
        shift 1
        check_parameters ""${1:-}""
        [[ -n ""${PARAM_CA:-}"" ]] && _exiterr ""CA can only be specified once!""
        PARAM_CA=""${1}""
        ;;

      # PARAM_Usage: --alias certalias
      # PARAM_Description: Use specified name for certificate directory (and per-certificate config) instead of the primary domain (only used if --domain is specified)
      --alias)
        shift 1
        check_parameters ""${1:-}""
        [[ -n ""${PARAM_ALIAS:-}"" ]] && _exiterr ""Alias can only be specified once!""
        PARAM_ALIAS=""${1}""
        ;;

      # PARAM_Usage: --keep-going (-g)
      # PARAM_Description: Keep going after encountering an error while creating/renewing multiple certificates in cron mode
      --keep-going|-g)
        PARAM_KEEP_GOING=""yes""
        ;;

      # PARAM_Usage: --force (-x)
      # PARAM_Description: Force renew of certificate even if it is longer valid than value in RENEW_DAYS
      --force|-x)
        PARAM_FORCE=""yes""
        ;;

      # PARAM_Usage: --force-validation
      # PARAM_Description: Force revalidation of domain names (used in combination with --force)
      --force-validation)
        PARAM_FORCE_VALIDATION=""yes""
        ;;

      # PARAM_Usage: --no-lock (-n)
      # PARAM_Description: Don't use lockfile (potentially dangerous!)
      --no-lock|-n)
        PARAM_NO_LOCK=""yes""
        ;;

      # PARAM_Usage: --lock-suffix example.com
      # PARAM_Description: Suffix lockfile name with a string (useful for with -d)
      --lock-suffix)
        shift 1
        check_parameters ""${1:-}""
        PARAM_LOCKFILE_SUFFIX=""${1}""
        ;;

      # PARAM_Usage: --ocsp
      # PARAM_Description: Sets option in CSR indicating OCSP stapling to be mandatory
      --ocsp)
        PARAM_OCSP_MUST_STAPLE=""yes""
        ;;

      # PARAM_Usage: --privkey (-p) path/to/key.pem
      # PARAM_Description: Use specified private key instead of account key (useful for revocation)
      --privkey|-p)
        shift 1
        check_parameters ""${1:-}""
        PARAM_ACCOUNT_KEY=""${1}""
        ;;

      # PARAM_Usage: --domains-txt path/to/domains.txt
      # PARAM_Description: Use specified domains.txt instead of default/configured one
      --domains-txt)
        shift 1
        check_parameters ""${1:-}""
        PARAM_DOMAINS_TXT=""${1}""
        ;;

      # PARAM_Usage: --config (-f) path/to/config
      # PARAM_Description: Use specified config file
      --config|-f)
        shift 1
        check_parameters ""${1:-}""
        CONFIG=""${1}""
        ;;

      # PARAM_Usage: --hook (-k) path/to/hook.sh
      # PARAM_Description: Use specified script for hooks
      --hook|-k)
        shift 1
        check_parameters ""${1:-}""
        PARAM_HOOK=""${1}""
        ;;

      # PARAM_Usage: --preferred-chain issuer-cn
      # PARAM_Description: Use alternative certificate chain identified by issuer CN
      --preferred-chain)
        shift 1
        check_parameters ""${1:-}""
        PARAM_PREFERRED_CHAIN=""${1}""
        ;;

      # PARAM_Usage: --out (-o) certs/directory
      # PARAM_Description: Output certificates into the specified directory
      --out|-o)
        shift 1
        check_parameters ""${1:-}""
        PARAM_CERTDIR=""${1}""
        ;;

      # PARAM_Usage: --alpn alpn-certs/directory
      # PARAM_Description: Output alpn verification certificates into the specified directory
      --alpn)
        shift 1
        check_parameters ""${1:-}""
        PARAM_ALPNCERTDIR=""${1}""
        ;;

      # PARAM_Usage: --challenge (-t) http-01|dns-01|tls-alpn-01
      # PARAM_Description: Which challenge should be used? Currently http-01, dns-01, and tls-alpn-01 are supported
      --challenge|-t)
        shift 1
        check_parameters ""${1:-}""
        PARAM_CHALLENGETYPE=""${1}""
        ;;

      # PARAM_Usage: --algo (-a) rsa|prime256v1|secp384r1
      # PARAM_Description: Which public key algorithm should be used? Supported: rsa, prime256v1 and secp384r1
      --algo|-a)
        shift 1
        check_parameters ""${1:-}""
        PARAM_KEY_ALGO=""${1}""
        ;;
      *)
        echo ""Unknown parameter detected: ${1}"" >&2
        echo >&2
        command_help >&2
        exit 1
        ;;
    esac

    shift 1
  done

  case ""${COMMAND}"" in
    env) command_env;;
    sign_domains) command_sign_domains;;
    register) command_register;;
    account) command_account;;
    sign_csr) command_sign_csr ""${PARAM_CSR}"";;
    revoke) command_revoke ""${PARAM_REVOKECERT}"";;
    deactivate) command_deactivate;;
    cleanup) command_cleanup;;
    terms) command_terms;;
    cleanupdelete) command_cleanupdelete;;
    version) command_version;;
    *) command_help; exit 1;;
  esac

  exit ""${exit_with_errorcode}""
}

# Determine OS type
OSTYPE=""$(uname)""

if [[ ! ""${DEHYDRATED_NOOP:-}"" = ""NOOP"" ]]; then
  # Run script
  main ""${@:-}""
fi

# vi: expandtab sw=2 ts=2"
welder,"#!/bin/sh

[ -n ""$DEBUG"" ] && set -x
set -eu

info() {
  printf ""[ \033[00;34m..\033[0m ] %s"" ""$1""
}

success() {
  printf ""\r\033[2K[ \033[00;32mOK\033[0m ] %s\n"" ""$1""
}

fail() {
  printf ""\r\033[2K  [\033[0;31mFAIL\033[0m] %s\n"" ""$1""
  echo ''
  exit 1
}

help() {
  echo ""Usage:""
  echo ""    welder run <playbook> <ssh-url>""
  echo """"
  echo ""Example:""
  echo ""    welder run playbook.conf user@example.com""
  exit 1
}

if ! command -v rsync > /dev/null; then
  fail ""Please install rsync first""
fi

[ $# -lt 3 ] && help

command=$1
case $command in
""-h"" | ""--help"")
  help
  ;;
*)

  if [ ""$1"" != ""run"" ]; then
    help
  fi
  ;;
esac
shift 1

playbook_file=$1
ssh_url=$2
config_file=""config.conf""

[ ! -f ""$playbook_file"" ] && fail ""Playbook file $playbook_file not found""
[ ! -f ""$config_file"" ]   && fail ""Config file $config_file not found""

WELDER_ROOT=""$( cd -- ""$(dirname ""$0"")"" >/dev/null 2>&1 && pwd -P )""

output_dir=""welder-cache""
mkdir -p $output_dir
cp -p ""$WELDER_ROOT""/setup $output_dir

# Clean up playbook file (comments, empty lines)
grep -v -s -e '^#' -e '^$' ""$playbook_file"" > ""$output_dir/$playbook_file""

# Clean up config: remove comments, empty lines and spaces around =
grep -v -s -e '^#' -e '^$' ""$config_file"" \
  | sed -e 's/[[:space:]]=[[:space:]]/=/' > ""$output_dir/$config_file""

# Prepare config for *.template files, turn it into a sed command file
# First sed escapes variables so they can be used as... a sed pattern
# Source: https://stackoverflow.com/a/2705678
#
# Turns FOO=""BAR"" into s/FOO/BAR/g
sed -e 's/[]\/$*.^[]/\\&/g'  \
  -e 's/=""/=/;s/""$//' \
  -e 's/^/s\/{{ /' \
  -e 's/=/ }}\//' \
  -e 's/$/\/g/' ""$output_dir/$config_file"" > ""$output_dir/templates-$config_file""

# Go through all modules listed in $playbook_file, copy them to $output_dir
while read -r module; do
  cp -R ""$module"" ""$output_dir""
done < ""$output_dir/$playbook_file""

# Interpolate templates
find $output_dir -type f -name ""*.template"" | while IFS= read -r template; do
  template_output=${template%.*}
  sed -f ""$output_dir/templates-$config_file"" ""$template"" > ""$template_output""
  rm ""$template""
done

# Copy files to the server and run everything
rsync -a --delete --ignore-times --quiet ""$output_dir""/ ""$ssh_url"":""$output_dir""
ssh -t ""$ssh_url"" ""cd $output_dir && ./setup $playbook_file && cd .. && rm -r $output_dir""

success ""All done!"""
virtualhost,"#!/bin/bash
### Set Language
TEXTDOMAIN=virtualhost

### Set default parameters
action=$1
domain=$2
rootDir=$3
owner=$(who am i | awk '{print $1}')
apacheUser=$(ps -ef | egrep '(httpd|apache2|apache)' | grep -v root | head -n1 | awk '{print $1}')
email='webmaster@localhost'
sitesEnabled='/etc/apache2/sites-enabled/'
sitesAvailable='/etc/apache2/sites-available/'
userDir='/var/www/'
sitesAvailabledomain=$sitesAvailable$domain.conf

### don't modify from here unless you know what you are doing ####

if [ ""$(whoami)"" != 'root' ]; then
	echo $""You have no permission to run $0 as non-root user. Use sudo""
		exit 1;
fi

if [ ""$action"" != 'create' ] && [ ""$action"" != 'delete' ]
	then
		echo $""You need to prompt for action (create or delete) -- Lower-case only""
		exit 1;
fi

while [ ""$domain"" == """" ]
do
	echo -e $""Please provide domain. e.g.dev,staging""
	read domain
done

if [ ""$rootDir"" == """" ]; then
	rootDir=${domain//./}
fi

### if root dir starts with '/', don't use /var/www as default starting point
if [[ ""$rootDir"" =~ ^/ ]]; then
	userDir=''
fi

rootDir=$userDir$rootDir

if [ ""$action"" == 'create' ]
	then
		### check if domain already exists
		if [ -e $sitesAvailabledomain ]; then
			echo -e $""This domain already exists.\nPlease Try Another one""
			exit;
		fi

		### check if directory exists or not
		if ! [ -d $rootDir ]; then
			### create the directory
			mkdir $rootDir
			### give permission to root dir
			chmod 755 $rootDir
			### write test file in the new domain dir
			if ! echo ""<?php echo phpinfo(); ?>"" > $rootDir/phpinfo.php
			then
				echo $""ERROR: Not able to write in file $rootDir/phpinfo.php. Please check permissions""
				exit;
			else
				echo $""Added content to $rootDir/phpinfo.php""
			fi
		fi

		### create virtual host rules file
		if ! echo ""
		<VirtualHost *:80>
			ServerAdmin $email
			ServerName $domain
			ServerAlias $domain
			DocumentRoot $rootDir
			<Directory />
				AllowOverride All
			</Directory>
			<Directory $rootDir>
				Options Indexes FollowSymLinks MultiViews
				AllowOverride all
				Require all granted
			</Directory>
			ErrorLog /var/log/apache2/$domain-error.log
			LogLevel error
			CustomLog /var/log/apache2/$domain-access.log combined
		</VirtualHost>"" > $sitesAvailabledomain
		then
			echo -e $""There is an ERROR creating $domain file""
			exit;
		else
			echo -e $""\nNew Virtual Host Created\n""
		fi

		### Add domain in /etc/hosts
		if ! echo ""127.0.0.1	$domain"" >> /etc/hosts
		then
			echo $""ERROR: Not able to write in /etc/hosts""
			exit;
		else
			echo -e $""Host added to /etc/hosts file \n""
		fi

		### Add domain in /mnt/c/Windows/System32/drivers/etc/hosts (Windows Subsytem for Linux)
		if [ -e /mnt/c/Windows/System32/drivers/etc/hosts ]
		then
			if ! echo -e ""\r127.0.0.1       $domain"" >> /mnt/c/Windows/System32/drivers/etc/hosts
			then
				echo $""ERROR: Not able to write in /mnt/c/Windows/System32/drivers/etc/hosts (Hint: Try running Bash as administrator)""
			else
				echo -e $""Host added to /mnt/c/Windows/System32/drivers/etc/hosts file \n""
			fi
		fi

		if [ ""$owner"" == """" ]; then
			iam=$(whoami)
			if [ ""$iam"" == ""root"" ]; then
				chown -R $apacheUser:$apacheUser $rootDir
			else
				chown -R $iam:$iam $rootDir
			fi
		else
			chown -R $owner:$owner $rootDir
		fi

		### enable website
		a2ensite $domain

		### restart Apache
		/etc/init.d/apache2 reload

		### show the finished message
		echo -e $""Complete! \nYou now have a new Virtual Host \nYour new host is: http://$domain \nAnd its located at $rootDir""
		exit;
	else
		### check whether domain already exists
		if ! [ -e $sitesAvailabledomain ]; then
			echo -e $""This domain does not exist.\nPlease try another one""
			exit;
		else
			### Delete domain in /etc/hosts
			newhost=${domain//./\\.}
			sed -i ""/$newhost/d"" /etc/hosts

			### Delete domain in /mnt/c/Windows/System32/drivers/etc/hosts (Windows Subsytem for Linux)
			if [ -e /mnt/c/Windows/System32/drivers/etc/hosts ]
			then
				newhost=${domain//./\\.}
				sed -i ""/$newhost/d"" /mnt/c/Windows/System32/drivers/etc/hosts
			fi

			### disable website
			a2dissite $domain

			### restart Apache
			/etc/init.d/apache2 reload

			### Delete virtual host rules files
			rm $sitesAvailabledomain
		fi

		### check if directory exists or not
		if [ -d $rootDir ]; then
			echo -e $""Delete host root directory ? (y/n)""
			read deldir

			if [ ""$deldir"" == 'y' -o ""$deldir"" == 'Y' ]; then
				### Delete the directory
				rm -rf $rootDir
				echo -e $""Directory deleted""
			else
				echo -e $""Host directory conserved""
			fi
		else
			echo -e $""Host directory not found. Ignored""
		fi

		### show the finished message
		echo -e $""Complete!\nYou just removed Virtual Host $domain""
		exit 0;
fi"